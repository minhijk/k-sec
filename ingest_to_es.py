# ingest_to_es.py - Elasticsearchì— ë°ì´í„° ìƒ‰ì¸ ìŠ¤í¬ë¦½íŠ¸

import json
from langchain_core.documents import Document
from langchain_elasticsearch import ElasticsearchStore
from langchain_huggingface import HuggingFaceEmbeddings
import os
# elasticsearch í´ë¼ì´ì–¸íŠ¸ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì„í¬íŠ¸
from elasticsearch import Elasticsearch

# --- ì„¤ì • ë³€ìˆ˜ ---
# ... (ê¸°ì¡´ê³¼ ë™ì¼) ...
ELASTIC_URL = "http://localhost:9200"
INDEX_NAME = "k8s_security_documents"
MODEL_NAME = "jhgan/ko-sroberta-multitask"
SOURCE_JSON_PATH = "structured_all.json" 

def ingest_data_to_es():
    # ... (1, 2, 3ë²ˆ ê³¼ì •ì€ ê¸°ì¡´ê³¼ ë™ì¼) ...
    # 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    print("ğŸš€ 1. ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    try:
        embedding_model = HuggingFaceEmbeddings(model_name=MODEL_NAME)
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 2. ì†ŒìŠ¤ JSON íŒŒì¼ ë¡œë“œ
    if not os.path.exists(SOURCE_JSON_PATH):
        print(f"âŒ íŒŒì¼ ì—†ìŒ: '{SOURCE_JSON_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    print(f"ğŸ“„ 2. '{SOURCE_JSON_PATH}' íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
    with open(SOURCE_JSON_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # 3. LangChain Document ê°ì²´ë¡œ ë³€í™˜
    documents = []
    for item in data:
        page_content = f"Title: {item.get('title', '')}\nDescription: {item.get('content_description', '')}\nRemediation: {item.get('content_remediation', '')}"
        metadata = {
            "id": item.get("id"), "source": item.get("source"),
            "category_l1": item.get("category_l1"), "category_l2": item.get("category_l2"),
            "title": item.get("title")
        }
        documents.append(Document(page_content=page_content, metadata=metadata))
    print(f"âœ… {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ LangChain Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.")

    # ------------------ (ì—¬ê¸°ê°€ ìˆ˜ì •/ì¶”ê°€ëœ ë¶€ë¶„) ------------------
    # 4. Elasticsearch í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
    print(f"ğŸ” 4. ê¸°ì¡´ '{INDEX_NAME}' ì¸ë±ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤...")
    try:
        es_client = Elasticsearch(ELASTIC_URL)
        if es_client.indices.exists(index=INDEX_NAME):
            print(f"ğŸ—‘ï¸ ê¸°ì¡´ '{INDEX_NAME}' ì¸ë±ìŠ¤ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
            es_client.indices.delete(index=INDEX_NAME)
            print(f"âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ ì™„ë£Œ.")
    except Exception as e:
        print(f"\nâŒ Elasticsearch ì—°ê²° ë˜ëŠ” ì¸ë±ìŠ¤ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("   Dockerë¡œ Elasticsearch ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    # -----------------------------------------------------------------
    
    # 5. Elasticsearchì— ë°ì´í„° ìƒ‰ì¸ (Ingest) - (ê¸°ì¡´ 4ë²ˆ ê³¼ì •)
    print(f"ğŸšš 5. Elasticsearchì— ë°ì´í„° ìƒ‰ì¸ì„ ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤...")
    try:
        db = ElasticsearchStore.from_documents(
            documents,
            embedding_model,
            es_url=ELASTIC_URL,
            index_name=INDEX_NAME,
            strategy=ElasticsearchStore.ApproxRetrievalStrategy()
        )
        if not db.client.indices.exists(index=INDEX_NAME):
            raise Exception("ì¸ë±ìŠ¤ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print(f"\nğŸ‰ ì„±ê³µ! '{INDEX_NAME}' ì¸ë±ìŠ¤ì— {len(documents)}ê°œì˜ ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒ‰ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ Elasticsearch ìƒ‰ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    ingest_data_to_es()