import json
import re

def _clean_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì •ì œ: ë¶ˆí•„ìš”í•œ ë¬¸êµ¬, í˜ì´ì§€ ë²ˆí˜¸, ê³µë°± ì œê±°"""
    if not text:
        return ""
    text = re.sub(r"(?i)TECHNICAL IMPLEMENTATION GUIDANCE", "", text)
    text = re.sub(r"(?i)ENISA|June\s+\d{4}|version\s*\d+\.\d+", "", text)
    text = re.sub(r"Page\s*\d+", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def get_cis_categories(cis_id: str):
    """CIS IDì— ë”°ë¼ category_l1, category_l2 ìë™ ë§¤í•‘"""
    mappings = {
        "1": ("Control Plane Components", "API Server Configuration"),
        "2": ("Control Plane Components", "Scheduler / Controller Manager"),
        "3": ("Control Plane Components", "etcd Configuration"),
        "4": ("Worker Node Security", "Kubelet Configuration"),
        "5": ("Pod Security Policies", "Service Account Management"),
        "6": ("Network Policies", "CNI Plugin & Networking"),
        "7": ("Logging and Auditing", "Audit & Log Configuration"),
        "8": ("Configuration Files", "File Ownership & Permissions"),
        "9": ("RBAC and Authentication", "Access Control Enforcement"),
        "10": ("Pod Security Admission", "Policy Configuration")
    }
    prefix = cis_id.split('.')[0]
    return mappings.get(prefix, ("CIS Benchmark Recommendations", ""))

def normalize_cis(item):
    """CIS ë°ì´í„°ë¥¼ NIST í¬ë§·ìœ¼ë¡œ ë³€í™˜ + ì¹´í…Œê³ ë¦¬ ë³´ê°•"""
    cat1, cat2 = get_cis_categories(item.get("id", ""))
    details = {
        "rationale": item.get("rationale", ""),
        "impact": item.get("impact", ""),
        "audit": item.get("audit", ""),
        "default_value": item.get("default_value", ""),
        "references": item.get("references", ""),
        "cis_controls": item.get("cis_controls", "")
    }
    return {
        "id": f"CIS-{item.get('id', '')}",
        "source": item.get("source", "cis_benchmark.pdf"),
        "category_l1": cat1,
        "category_l2": cat2,
        "title": item.get("title", ""),
        "content_description": _clean_text(item.get("description", "")),
        "content_remediation": _clean_text(item.get("remediation", "")),
        "details": details
    }

def normalize_enisa(item):
    """ENISA ë°ì´í„°ë¥¼ NIST í¬ë§·ì— ë§ê²Œ ë³€í™˜ + í…ìŠ¤íŠ¸ ì •ì œ ê°•í™”"""
    details = {
        "evidence": _clean_text(item.get("evidence", "")),
        "tips": _clean_text(item.get("tips", ""))
    }
    return {
        "id": f"ENISA-{item.get('id', '')}",
        "source": item.get("source", "enisa_tig.pdf"),
        "category_l1": _clean_text(item.get("chapter_title", "ENISA Guidance")),
        "category_l2": _clean_text(item.get("section_title", "")),
        "title": _clean_text(item.get("section_title", "")),
        "content_description": _clean_text(item.get("requirement_text", "")),
        "content_remediation": _clean_text(" ".join(filter(None, [item.get("guidance", ""), item.get("tips", "")]))),
        "details": details
    }

def normalize_nist(item):
    """NISTëŠ” ì´ë¯¸ í†µì¼ëœ êµ¬ì¡°ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜"""
    return item

def unify_json(nist_path, cis_path, enisa_path, output_path):
    def load_json(path):
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)

    nist_data = load_json(nist_path)
    cis_data = load_json(cis_path)
    enisa_data = load_json(enisa_path)

    unified = []
    unified.extend([normalize_nist(i) for i in nist_data])
    unified.extend([normalize_cis(i) for i in cis_data])
    unified.extend([normalize_enisa(i) for i in enisa_data])

    print(f"âœ… í†µí•© ì™„ë£Œ: NIST={len(nist_data)}, CIS={len(cis_data)}, ENISA={len(enisa_data)} â†’ ì´ {len(unified)} í•­ëª©")

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(unified, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ ê²°ê³¼ ì €ì¥ë¨: {output_path}")

if __name__ == "__main__":
    # ë°±ìŠ¬ë˜ì‹œ(\)ë¥¼ ìŠ¬ë˜ì‹œ(/)ë¡œ ë³€ê²½
    unify_json(
        nist_path="parser/parsers_output/structured_nist.json",
        cis_path="parser/parsers_output/structured_cis.json",
        enisa_path="parser/parsers_output/structured_enisa.json",
        output_path="structured_all.json"
    )