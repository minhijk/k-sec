[
  {
    "page_content": "Title: Image vulnerabilities\nDescription: Because images are effectively static archive files that include all the components used to run a given app, components within an image may be missing critical security updates or are otherwise outdated. An image created with fully up-to-date components may be free of known vulnerabilities for days or weeks after its creation, but at some time vulnerabilities will be discovered in one or more image components, and thus the image will no longer be up-to-date. Unlike traditional operational patterns in which deployed software is updated ‘in the field’ on the hosts it runs on, with containers these updates must be made upstream in the images themselves, which are then redeployed. Thus, a common risk in containerized environments is deployed containers having vulnerabilities because the version of the image used to generate the containers has vulnerabilities.\nRationale: N/A\nAudit: N/A\nRemediation: There is a need for container technology-specific vulnerability management tools and processes. Traditional vulnerability management tools make many assumptions about host durability and app update mechanisms and frequencies that are fundamentally misaligned with a containerized model. These tools are often unable to detect vulnerabilities within containers, leading to a false sense of safety. Organizations should use tools that take the pipeline-based build approach and immutable nature of containers and images into their design to provide more actionable and reliable results. Key aspects of effective tools and processes include: 1. Integration with the entire lifecycle of images, from the beginning of the build process, to whatever registries the organization is using, to runtime. 2. Visibility into vulnerabilities at all layers of the image, not just the base layer of the image but also application frameworks and custom software the organization is using. Visibility should be centralized across the organization and provide flexible reporting and monitoring views aligned with organizations’ business processes. 3. Policy-driven enforcement; organizations should be able to create “quality gates” at each stage of the build and deployment process to ensure that only images that meet the organization’s vulnerability and configuration policies are allowed to progress. For example, organizations should be able to configure a rule in the build process to prevent the progression of images that include vulnerabilities with Common Vulnerability Scoring System (CVSS) [18] ratings above a selected threshold.",
    "metadata": {
      "id": "NIST-3.1.1",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Image Risks"
    }
  },
  {
    "page_content": "Title: Image configuration defects\nDescription: In addition to software defects, images may also have configuration defects. For example, an image may not be configured with a specific user account to “run as” and thus run with greater privileges than needed. As another example, an image may include an SSH daemon, which exposes the container to unnecessary network risk. Much like in a traditional server or VM, where a poor configuration can still expose a fully up-to-date system to attack, so too can a poorly configured image increase risk even if all the included components are up-to-date.\nRationale: N/A\nAudit: N/A\nRemediation: Organizations should adopt tools and processes to validate and enforce compliance with secure configuration best practices. For example, images should be configured to run as non-privileged users. Tools and processes that should be adopted include: 1. Validation of image configuration settings, including vendor recommendations and third- party best practices. 2. Ongoing, continuously updated, centralized reporting and monitoring of image compliance state to identify weaknesses and risks at the organizational level. 3. Enforcement of compliance requirements by optionally preventing the running of non- compliant images. 4. Use of base layers from trusted sources only, frequent updates of base layers, and selection of base layers from minimalistic technologies like Alpine Linux and Windows Nano Server to reduce attack surface areas.",
    "metadata": {
      "id": "NIST-3.1.2",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Image Risks"
    }
  },
  {
    "page_content": "Title: Embedded malware\nDescription: Because images are just collections of files packaged together, malicious files could be included intentionally or inadvertently within them. Such malware would have the same capabilities as any other component within the image and thus could be used to attack other containers or hosts within the environment. A possible source of embedded malware is the use of base layers and other images provided by third parties of which the full provenance is not known.\nRationale: N/A\nAudit: N/A\nRemediation: Organizations should continuously monitor all images for embedded malware. The monitoring processes should include the use of malware signature sets and behavioral detection heuristics based largely on actual “in the wild” attacks.",
    "metadata": {
      "id": "NIST-3.1.3",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Image Risks"
    }
  },
  {
    "page_content": "Title: Embedded clear text secrets\nDescription: Many apps require secrets to enable secure communication between components. For example, a web app may need a username and password to connect to a backend database. Other examples of embedded secrets include connection strings, SSH private keys, and X.509 private keys. When an app is packaged into an image, these secrets can be embedded directly into the image file system. However, this practice creates a security risk because anyone with access to the image can easily parse it to learn these secrets.\nRationale: N/A\nAudit: N/A\nRemediation: Secrets should be stored outside of images and provided dynamically at runtime as needed. Most orchestrators, such as Docker Swarm and Kubernetes, include native management of secrets. These orchestrators not only provide secure storage of secrets and ‘just in time’ injection to containers, but also make it much simpler to integrate secret management into the build and deployment processes. For example, an organization could use these tools to securely provision the database connection string into a web application container. The orchestrator can ensure that only the web application container had access to this secret, that it is not persisted to disk, and that anytime the web app is deployed, the secret is provisioned into it. Organizations may also integrate their container deployments with existing enterprise secret management systems that are already in use for storing secrets in non-container environments. These tools typically provide APIs to retrieve secrets securely as containers are deployed, which eliminates the need to persist them within images. Regardless of the tool chosen, organizations should ensure that secrets are only provided to the specific containers that require them, based on a pre-defined and administrator-controlled setting, and that secrets are always encrypted at rest and in transit using Federal Information Processing Standard (FIPS) 140 approved cryptographic algorithms5 contained in validated cryptographic modules.",
    "metadata": {
      "id": "NIST-3.1.4",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Image Risks"
    }
  },
  {
    "page_content": "Title: Use of untrusted images\nDescription: One of the most common high-risk scenarios in any environment is the execution of untrusted software. The portability and ease of reuse of containers increase the temptation for teams to run images from external sources that may not be well validated or trustworthy. For example, when troubleshooting a problem with a web app, a user may find another version of that app available in an image provided by a third party. Using this externally provided image results in the same types of risks that external software traditionally has, such as introducing malware, leaking data, or including components with vulnerabilities. 3.2 Registry Risks\nRationale: N/A\nAudit: N/A\nRemediation: Organizations should maintain a set of trusted images and registries and ensure that only images from this set are allowed to run in their environment, thus mitigating the risk of untrusted or malicious components being deployed. To mitigate these risks, organizations should take a multilayered approach that includes: For more information on NIST-validated cryptographic implementations, see the Cryptographic Module Validation Program (CMVP) page at https://csrc.nist.gov/groups/STM/cmvp/.",
    "metadata": {
      "id": "NIST-3.1.5",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Image Risks"
    }
  },
  {
    "page_content": "Title: Insecure connections to registries\nDescription: Images often contain sensitive components like an organization’s proprietary software and embedded secrets. If connections to registries are performed over insecure channels, the contents of images are subject to the same confidentiality risks as any other data transmitted in the clear. There is also an increased risk of man-in-the-middle attacks that could intercept network traffic intended for registries and steal developer or administrator credentials within that traffic, provide fraudulent or outdated images to orchestrators, etc.\nRationale: N/A\nAudit: N/A\nRemediation: Organizations should configure their development tools, orchestrators, and container runtimes to only connect to registries over encrypted channels. The specific steps vary between tools, but the key goal is to ensure that all data pushed to and pulled from a registry occurs between trusted endpoints and is encrypted in transit.",
    "metadata": {
      "id": "NIST-3.2.1",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Registry Risks"
    }
  },
  {
    "page_content": "Title: Stale images in registries\nDescription: Because registries are typically the source location for all the images an organization deploys, over time the set of images they store can include many vulnerable, out-of-date versions. While these vulnerable images do not directly pose a threat simply by being stored in the registry, they increase the likelihood of accidental deployment of a known-vulnerable version.\nRationale: N/A\nAudit: N/A\nRemediation: The risk of using stale images can be mitigated through two primary methods. First, organizations can prune registries of unsafe, vulnerable images that should no longer be used. This process can be automated based on time triggers and labels associated with images. Second, operational practices should emphasize accessing images using immutable names that specify discrete versions of images to be used. For example, rather than configuring a deployment job to use the image called my-app, configure it to deploy specific versions of the image, such as my-app:2.3 and my-app:2.4 to ensure that specific, known good instances of images are deployed as part of each job. Another option is using a “latest” tag for images and referencing this tag in deployment automation. However, because this tag is only a label attached to the image and not a guarantee of freshness, organizations should be cautious to not overly trust it. Regardless of whether an organization chooses to use discrete names or to use a “latest” tag, it is critical that processes be put in place to ensure that either the automation is using the most recent unique name or the images tagged “latest” actually do represent the most up-to-date versions.",
    "metadata": {
      "id": "NIST-3.2.2",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Registry Risks"
    }
  },
  {
    "page_content": "Title: Insufficient authentication and authorization restrictions\nDescription: Because registries may contain images used to run sensitive or proprietary apps and to access sensitive data, insufficient authentication and authorization requirements can lead to intellectual\nRationale: N/A\nAudit: N/A\nRemediation: All access to registries that contain proprietary or sensitive images should require authentication. Any write access to a registry should require authentication to ensure that only images from trusted entities can be added to it. For example, only allow developers to push images to the specific repositories they are responsible for, rather than being able to update any repository. For more information on NIST-validated cryptographic implementations, see the Cryptographic Module Validation Program (CMVP) page at https://csrc.nist.gov/projects/cryptographic-module-validation-program.",
    "metadata": {
      "id": "NIST-3.2.3",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Registry Risks"
    }
  },
  {
    "page_content": "Title: Unbounded administrative access\nDescription: Historically, many orchestrators were designed with the assumption that all users interacting with them would be administrators and those administrators should have environment-wide control. However, in many cases, a single orchestrator may run many different apps, each managed by different teams, and with different sensitivity levels. If the access provided to users and groups is not scoped to their specific needs, a malicious or careless user could affect or subvert the operation of other containers managed by the orchestrator.\nRationale: N/A\nAudit: N/A\nRemediation: Especially because of their wide-ranging span of control, orchestrators should use a least privilege access model in which users are only granted the ability to perform the specific actions on the specific hosts, containers, and images their job roles require. For example, members of the test team should only be given access to the images used in testing and the hosts used for running them, and should only be able to manipulate the containers they created. Test team members should have limited or no access to containers used in production.",
    "metadata": {
      "id": "NIST-3.3.1",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Orchestrator Risks"
    }
  },
  {
    "page_content": "Title: Unauthorized access\nDescription: Orchestrators often include their own authentication directory service, which may be separate from the typical directories already in use within an organization. This can lead to weaker account management practices and ‘orphaned’ accounts in the orchestrator because these systems are less rigorously managed. Because many of these accounts are highly privileged within the orchestrator, compromise of them can lead to systemwide compromise. Containers typically use data storage volumes that are managed by the orchestration tool and are not host specific. Because a container may run on any given node within a cluster, the data required by the app within the container must be available to the container regardless of which host it is running on. At the same time, many organizations manage data that must be encrypted at rest to prevent unauthorized access.\nRationale: N/A\nAudit: N/A\nRemediation: Access to cluster-wide administrative accounts should be tightly controlled as these accounts provide ability to affect all resources in the environment. Organizations should use strong authentication methods, such as requiring multifactor authentication instead of just a password. Organizations should implement single sign-on to existing directory systems where applicable. Single sign-on simplifies the orchestrator authentication experience, makes it easier for users to use strong authentication credentials, and centralizes auditing of access, making anomaly detection more effective. Traditional approaches for data at rest encryption often involve the use of host-based capabilities that may be incompatible with containers. Thus, organizations should use tools for encrypting data used with containers that allow the data to be accessed properly from containers regardless of the node they are running on. Such encryption tools should provide the same barriers to unauthorized access and tampering, using the same cryptographic approaches as those defined in NIST SP 800-111 [19].",
    "metadata": {
      "id": "NIST-3.3.2",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Orchestrator Risks"
    }
  },
  {
    "page_content": "Title: Poorly separated inter-container network traffic\nDescription: In most containerized environments, traffic between individual nodes is routed over a virtual overlay network. This overlay network is typically managed by the orchestrator and is often opaque to existing network security and management tools. For example, instead of seeing database queries being sent from a web server container to a database container on another host, traditional network filters would only see encrypted packets flowing between two hosts, with no visibility into the actual container endpoints, nor the traffic being sent. Although an encrypted overlay network provides many operational and security benefits, it can also create a security ‘blindness’ scenario in which organizations are unable to effectively monitor traffic within their own networks. Potentially even more critical is the risk of traffic from different apps sharing the same virtual networks. If apps of different sensitivity levels, such as a public-facing web site and an internal treasury management app, are using the same virtual network, sensitive internal apps may be exposed to greater risk from network attack. For example, if the public-facing web site is compromised, attackers may be able to use shared networks to attack the treasury app.\nRationale: N/A\nAudit: N/A\nRemediation: Orchestrators should be configured to separate network traffic into discrete virtual networks by sensitivity level. While per-app segmentation is also possible, for most organizations and use cases, simply defining networks by sensitivity level provides sufficient mitigation of risk with a manageable degree of complexity. For example, public-facing apps can share a virtual network,",
    "metadata": {
      "id": "NIST-3.3.3",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Orchestrator Risks"
    }
  },
  {
    "page_content": "Title: Mixing of workload sensitivity levels\nDescription: Orchestrators are typically focused primarily on driving the scale and density of workloads. This means that, by default, they can place workloads of differing sensitivity levels on the same host. For example, in a default configuration, an orchestrator may place a container running a public- facing web server on the same host as one processing sensitive financial data, simply because that host happens to have the most available resources at the time of deployment. In the case of a critical vulnerability in the web server, this can put the container processing sensitive financial data at significantly greater risk of compromise.\nRationale: N/A\nAudit: N/A\nRemediation: Orchestrators should be configured to isolate deployments to specific sets of hosts by sensitivity levels. The particular approach for implementing this varies depending on the orchestrator in use, but the general model is to define rules that prevent high sensitivity workloads from being placed on the same host as those running lower sensitivity workloads. This can be accomplished through the use of host ‘pinning’ within the orchestrator or even simply by having separate, individually managed clusters for each sensitivity level. While most container runtime environments do an effective job of isolating containers from each other and from the host OS, in some cases it may be an unnecessary risk to run apps of different sensitivity levels together on the same host OS. Segmenting containers by purpose, sensitivity, and threat posture provides additional defense in depth. Concepts such as application tiering and network and host segmentation should be taken into consideration when planning app deployments. For example, suppose a host is running containers for both a financial database and a public-facing blog. While normally the container runtime will effectively isolate these environments from each other, there is also a shared responsibility amongst the DevOps teams for each app to operate them securely and eliminate unnecessary risk. If the blog app were to be compromised by an attacker, there would be far fewer layers of defense to protect the database if the two apps are running on the same host. Thus, a best practice is to group containers together by relative sensitivity and to ensure that a given host kernel only runs containers of a single sensitivity level. This segmentation may be provided by using multiple physical servers, but modern hypervisors also provide strong enough isolation to effectively mitigate these risks. From the previous example, this may mean that the organization has two sensitivity levels for their containers. One is for financial apps and the database is included in that group. The other is for web apps and the blog is included in that group. The organization would then have two pools of VMs that would each host containers of a single severity level. For example, the host called vm-financial may host the containers running the financial database as well as the tax reporting software, while a host called vm-web may host the blog and the public website. By segmenting containers in this manner, it will be much more difficult for an attacker who compromises one of the segments to expand that compromise to other segments. An attacker who compromises a single server would have limited capabilities to perform reconnaissance and attacks on other containers of a similar sensitivity level and not have any additional access beyond it. This approach also ensures that any residual data, such as caches or local volumes mounted for temp files, stays within the data’s security zone. From the previous example, this zoning would ensure that any financial data cached locally and residually after container termination would never be available on a host running an app at a lower sensitivity level. In larger-scale environments with hundreds of hosts and thousands of containers, this segmentation must be automated to be practical to operationalize. Fortunately, common orchestration platforms typically include some notion of being able to group apps together, and",
    "metadata": {
      "id": "NIST-3.3.4",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Orchestrator Risks"
    }
  },
  {
    "page_content": "Title: Orchestrator node trust\nDescription: Maintenance of trust between the nodes in the environment requires special care. The orchestrator is the most foundational node. Weak orchestrator configurations can expose the orchestrator and all other container technology components to increased risk. Examples of possible consequences include: • Unauthorized hosts joining the cluster and running containers • The compromise of a single cluster host implying compromise of the entire cluster—for example, if the same key pairs used for authentication are shared across all nodes • Communications between the orchestrator and DevOps personnel, administrators, and hosts being unencrypted and unauthenticated 3.4 Container Risks\nRationale: N/A\nAudit: N/A\nRemediation: Orchestration platforms should be configured to provide features that create a secure environment for all the apps they run. Orchestrators should ensure that nodes are securely introduced to the cluster, have a persistent identity throughout their lifecycle, and can also provide an accurate inventory of nodes and their connectivity states. Organizations should ensure that orchestration platforms are designed specifically to be resilient to compromise of individual nodes without compromising the overall security of the cluster. A compromised node must be able to be isolated and removed from the cluster without disrupting or degrading overall cluster operations. Finally, organizations should choose orchestrators that provide mutually authenticated network connections between cluster members and end-to-end encryption of intra- cluster traffic. Because of the portability of containers, many deployments may occur across networks organizations do not directly control, so a secure-by-default posture is particularly important for this scenario. 4.4 Container Countermeasures",
    "metadata": {
      "id": "NIST-3.3.5",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Orchestrator Risks"
    }
  },
  {
    "page_content": "Title: Vulnerabilities within the runtime software\nDescription: While relatively uncommon, vulnerabilities within the runtime software are particularly dangerous if they allow ‘container escape’ scenarios in which malicious software can attack resources in other containers and the host OS itself. An attacker may also be able to exploit vulnerabilities to compromise the runtime software itself, and then alter that software so it allows the attacker to access other containers, monitor container-to-container communications, etc.\nRationale: N/A\nAudit: N/A\nRemediation: The container runtime must be carefully monitored for vulnerabilities, and when problems are detected, they must be remediated quickly. A vulnerable runtime exposes all containers it supports, as well as the host itself, to potentially significant risk. Organizations should use tools to look for Common Vulnerabilities and Exposures (CVEs) vulnerabilities in the runtimes deployed, to upgrade any instances at risk, and to ensure that orchestrators only allow deployments to properly maintained runtimes.",
    "metadata": {
      "id": "NIST-3.4.1",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Container Risks"
    }
  },
  {
    "page_content": "Title: Unbounded network access from containers\nDescription: By default in most container runtimes, individual containers are able to access each other and the host OS over the network. If a container is compromised and acting maliciously, allowing this network traffic may expose other resources in the environment to risk. For example, a compromised container may be used to scan the network it is connected to in order to find other weaknesses for an attacker to exploit. This risk is related to that from poorly separated virtual networks, as discussed in Section 3.3.3, but different because it is focused more on flows from containers to any outbound destination, not on app “cross talk” scenarios. Egress network access is more complex to manage in a containerized environment because so much of the connection is virtualized between containers. Thus, traffic from one container to another may appear simply as encapsulated packets on the network without directly indicating the ultimate source, destination, or payload. Tools and operational processes that are not container aware are not able to inspect this traffic or determine whether it represents a threat.\nRationale: N/A\nAudit: N/A\nRemediation: Organizations should control the egress network traffic sent by containers. At minimum, these controls should be in place at network borders, ensuring containers are not able to send traffic across networks of differing sensitivity levels, such as from an environment hosting secure data to the internet, similar to the patterns used for traditional architectures. However, the virtualized networking model of inter-container traffic poses an additional challenge. Because containers deployed across multiple hosts typically communicate over a virtual, encrypted network, traditional network devices are often blind to this traffic. Additionally, containers are typically assigned dynamic IP addresses automatically when deployed by orchestrators, and these addresses change continuously as the app is scaled and load balanced. Thus, ideally, organizations should use a combination of existing network level devices and more app-aware network filtering. App-aware tools should be able to not just see the inter- container traffic, but also to dynamically generate the rules used to filter this traffic based on the",
    "metadata": {
      "id": "NIST-3.4.2",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Container Risks"
    }
  },
  {
    "page_content": "Title: Insecure container runtime configurations\nDescription: Container runtimes typically expose many configurable options to administrators. Setting them improperly can lower the relative security of the system. For example, on Linux container hosts, the set of allowed system calls is often limited by default to only those required for safe operation of containers. If this list is widened, it may expose containers and the host OS to increased risk from a compromised container. Similarly, if a container is run in privileged mode, it has access to all the devices on the host, thus allowing it to essentially act as part of the host OS and impact all other containers running on it. Another example of an insecure runtime configuration is allowing containers to mount sensitive directories on the host. Containers should rarely make changes to the host OS file system and should almost never make changes to locations that control the basic functionality of the host OS (e.g., /boot or /etc for Linux containers, C:\\Windows for Windows containers). If a compromised container is allowed to make changes to these paths, it could be used to elevate privileges and attack the host itself as well as other containers running on the host.\nRationale: N/A\nAudit: N/A\nRemediation: Organizations should automate compliance with container runtime configuration standards. Documented technical implementation guidance, such as the Center for Internet Security Docker Benchmark [20], provides details on options and recommended settings, but operationalizing this guidance depends on automation. Organizations can use a variety of tools to “scan” and assess their compliance at a point in time, but such approaches do not scale. Instead, organizations should use tools or processes that continuously assess configuration settings across the environment and actively enforce them. Additionally, mandatory access control (MAC) technologies like SELinux [21] and AppArmor [22] provide enhanced control and isolation for containers running Linux OSs. For example, these technologies can be used to provide additional segmentation and assurance that containers should only be able to access specific file paths, processes, and network sockets, further constraining the ability of even a compromised container to impact the host or other containers. MAC technologies provide protection at the host OS layer, ensuring that only specific files, paths, and processes are accessible to containerized apps. Organizations are encouraged to use the MAC technologies provided by their host OSs in all container deployments. Secure computing (seccomp)7 profiles are another mechanism that can be used to constrain the system-level capabilities containers are allocated at runtime. Common container runtimes like Docker include default seccomp profiles that drop system calls that are unsafe and typically unnecessary for container operation. Additionally, custom profiles can be created and passed to container runtimes to further limit their capabilities. At a minimum, organizations should ensure that containers are run with the default profiles provided by their runtime and should consider using additional profiles for high-risk apps.",
    "metadata": {
      "id": "NIST-3.4.3",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Container Risks"
    }
  },
  {
    "page_content": "Title: App vulnerabilities\nDescription: Even when organizations are taking the precautions recommended in this guide, containers may still be compromised due to flaws in the apps they run. This is not a problem with containers themselves, but instead is just the manifestation of typical software flaws within a container environment. For example, a containerized web app may be vulnerable to cross-site scripting vulnerabilities, and a database front end container may be subject to Structured Query Language (SQL) injection. When a container is compromised, it can be misused in many ways, such as granting unauthorized access to sensitive information or enabling attacks against other containers or the host OS.\nRationale: N/A\nAudit: N/A\nRemediation: Existing host-based intrusion detection processes and tools are often unable to detect and prevent attacks within containers due to the differing technical architecture and operational practices For more information on seccomp, see https://www.kernel.org/doc/Documentation/prctl/seccomp_filter.txt.",
    "metadata": {
      "id": "NIST-3.4.4",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Container Risks"
    }
  },
  {
    "page_content": "Title: Rogue containers\nDescription: Rogue containers are unplanned or unsanctioned containers in an environment. This can be a common occurrence, especially in development environments, where app developers may launch containers as a means of testing their code. If these containers are not put through the rigors of vulnerability scanning and proper configuration, they may be more susceptible to exploits. Rogue containers therefore pose additional risk to the organization, especially when they persist in the environment without the awareness of development teams and security administrators. 3.5 Host OS Risks\nRationale: N/A\nAudit: N/A\nRemediation: Organizations should institute separate environments for development, test, production, and other scenarios, each with specific controls to provide role-based access control for container deployment and management activities. All container creation should be associated with individual user identities and logged to provide a clear audit trail of activity. Further, organizations are encouraged to use security tools that can enforce baseline requirements for vulnerability management and compliance prior to allowing an image to be run. 4.5 Host OS Countermeasures",
    "metadata": {
      "id": "NIST-3.4.5",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Container Risks"
    }
  },
  {
    "page_content": "Title: Large attack surface\nDescription: Every host OS has an attack surface, which is the collection of all ways attackers can attempt to access and exploit the host OS’s vulnerabilities. For example, any network-accessible service provides a potential entry point for attackers, adding to the attack surface. The larger the attack surface is, the better the odds are that an attacker can find and access a vulnerability, leading to a compromise of the host OS and the containers running on top of it.\nRationale: N/A\nAudit: N/A\nRemediation: For organizations using container-specific OSs, the threats are typically more minimal to start with since the OSs are specifically designed to host containers and have other services and functionality disabled. Further, because these optimized OSs are designed specifically for hosting containers, they typically feature read-only file systems and employ other hardening practices by default. Whenever possible, organizations should use these minimalistic OSs to reduce their attack surfaces and mitigate the typical risks and hardening activities associated with general-purpose OSs. Organizations that cannot use a container-specific OS should follow the guidance in NIST SP 800-123, Guide to General Server Security [23] to reduce the attack surface of their hosts as much as possible. For example, hosts that run containers should only run containers and not run other apps, like a web server or database, outside of containers. The host OS should not run unnecessary system services, such as a print spooler, that increase its attack and patching surface areas. Finally, hosts should be continuously scanned for vulnerabilities and updates applied",
    "metadata": {
      "id": "NIST-3.5.1",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Host OS Risks"
    }
  },
  {
    "page_content": "Title: Shared kernel\nDescription: Container-specific OSs have a much smaller attack surface than that of general-purpose OSs. For example, they do not contain libraries and package managers that enable a general-purpose OS to directly run database and web server apps. However, although containers provide strong software-level isolation of resources, the use of a shared kernel invariably results in a larger inter-object attack surface than seen with hypervisors, even for container-specific OSs. In other words, the level of isolation provided by container runtimes is not as high as that provided by hypervisors.\nRationale: N/A\nAudit: N/A\nRemediation: In addition to grouping container workloads onto hosts by sensitivity level, organizations should not mix containerized and non-containerized workloads on the same host instance. For example, if a host is running a web server container, it should not also run a web server (or any other app) as a regularly installed component directly within the host OS. Keeping containerized workloads isolated to container-specific hosts makes it simpler and safer to apply countermeasures and defenses that are optimized for protecting containers.",
    "metadata": {
      "id": "NIST-3.5.2",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Host OS Risks"
    }
  },
  {
    "page_content": "Title: Host OS component vulnerabilities\nDescription: All host OSs, even container-specific ones, provide foundational system components—for example, the cryptographic libraries used to authenticate remote connections and the kernel primitives used for general process invocation and management. Like any other software, these components can have vulnerabilities and, because they exist low in the container technology architecture, they can impact all the containers and apps that run on these hosts.\nRationale: N/A\nAudit: N/A\nRemediation: Organizations should implement management practices and tools to validate the versioning of components provided for base OS management and functionality. Even though container- specific OSs have a much more minimal set of components than general-purpose OSs, they still do have vulnerabilities and still require remediation. Organizations should use tools provided by the OS vendor or other trusted organizations to regularly check for and apply updates to all software components used within the OS. The OS should be kept up to date not only with security updates, but also the latest component updates recommended by the vendor. This is particularly important for the kernel and container runtime components as newer releases of these components often add additional security protections and capabilities beyond simply correcting vulnerabilities. Some organizations may choose to simply redeploy new OS instances with the necessary updates, rather than updating existing systems. This approach is also valid, although it often requires more sophisticated operational practices. Host OSs should be operated in an immutable manner with no data or state stored uniquely and persistently on the host and no application-level dependencies provided by the host. Instead, all app components and dependencies should be packaged and deployed in containers. This enables the host to be operated in a nearly stateless manner with a greatly reduced attack surface. Additionally, it provides a more trustworthy way to identify anomalies and configuration drift.",
    "metadata": {
      "id": "NIST-3.5.3",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Host OS Risks"
    }
  },
  {
    "page_content": "Title: Improper user access rights\nDescription: Container-specific OSs are typically not optimized to support multiuser scenarios since interactive user logon should be rare. Organizations are exposed to risk when users log on directly to hosts to manage containers, rather than going through an orchestration layer. Direct management enables wide-ranging changes to the system and all containers on it, and can potentially enable a user that only needs to manage a specific app’s containers to impact many others.\nRationale: N/A\nAudit: N/A\nRemediation: Though most container deployments rely on orchestrators to distribute jobs across hosts, organizations should still ensure that all authentication to the OS is audited, login anomalies are monitored, and any escalation to perform privileged operations is logged. This makes it possible to identify anomalous access patterns such as an individual logging on to a host directly and running privileged commands to manipulate containers.",
    "metadata": {
      "id": "NIST-3.5.4",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Host OS Risks"
    }
  },
  {
    "page_content": "Title: Host OS file system tampering\nDescription: Insecure container configurations can expose host volumes to greater risk of file tampering. For example, if a container is allowed to mount sensitive directories on the host OS, that container can then change files in those directories. These changes could impact the stability and security of the host and all other containers running on it.\nRationale: N/A\nAudit: N/A\nRemediation: Ensure that containers are run with the minimal set of file system permissions required. Very rarely should containers mount local file systems on a host. Instead, any file changes that containers need to persist to disk should be made within storage volumes specifically allocated for this purpose. In no case should containers be able to mount sensitive directories on a host’s file system, especially those containing configuration settings for the operating system.",
    "metadata": {
      "id": "NIST-3.5.5",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Major Risks and Countermeasures",
      "category_l2": "Host OS Risks"
    }
  },
  {
    "page_content": "Title: Exploit of a Vulnerability within an Image\nDescription: One of the most common threats to a containerized environment is application-level vulnerabilities in the software within containers. For example, an organization may build an image based on a common web app. If that app has a vulnerability, it may be used to subvert the app within the container. Once compromised, the attacker may be able to map other systems in the environment, attempt to elevate privileges within the compromised container, or abuse the container for use in attacks on other systems (such as acting as a file dropper or command and control endpoint). Organizations that adopt the recommended countermeasures would have multiple layers of defense in depth against such threats: 1. Detecting the vulnerable image early in the deployment process and having controls in place to prevent vulnerable images from being deployed would prevent the vulnerability from being introduced into production. 2. Container-aware network monitoring and filtering would detect anomalous connections to other containers during the attempt to map other systems. 3. Container-aware process monitoring and malware detection would detect the running of invalid or unexpected malicious processes and the data they introduce into the environment.\nRationale: N/A\nAudit: N/A\nRemediation:",
    "metadata": {
      "id": "NIST-5.1",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Container Threat Scenarios",
      "category_l2": "Exploit of a Vulnerability within an Image"
    }
  },
  {
    "page_content": "Title: Exploit of the Container Runtime\nDescription: While an uncommon occurrence, if a container runtime were compromised, an attacker could utilize this access to attack all the containers on the host and even the host itself.\nRationale: N/A\nAudit: N/A\nRemediation: Relevant mitigations for this threat scenario include: 1. The usage of mandatory access control capabilities can provide additional barriers to ensure that process and file system activity is still segmented within the defined boundaries. 2. Segmentation of workloads ensures that the scope of the compromise would be limited to apps of a common sensitivity level that are sharing the host. For example, a compromised runtime on a host only running web apps would not impact runtimes on other hosts running containers for financial apps. 3. Security tools that can report on the vulnerability state of runtimes and prevent the deployment of images to vulnerable runtimes can prevent workloads from running there.",
    "metadata": {
      "id": "NIST-5.2",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Container Threat Scenarios",
      "category_l2": "Exploit of the Container Runtime"
    }
  },
  {
    "page_content": "Title: Running a Poisoned Image\nDescription: Because images are easily sourced from public locations, often with unknown provenance, an attacker may embed malicious software within images known to be used by a target. For 31 example, if an attacker determines that a target is active on a discussion board about a particular project and uses images provided by that project’s web site, the attacker may seek to craft malicious versions of these images for use in an attack.\nRationale: N/A\nAudit: N/A\nRemediation: Relevant mitigations include: 1. Ensuring that only vetted, tested, validated, and digitally signed images are allowed to be uploaded to an organization’s registries. 2. Ensuring that only trusted images are allowed to run, which will prevent images from external, unvetted sources from being used. 3. Automatically scanning images for vulnerabilities and malware, which may detect malicious code such as rootkits embedded within an image. 4. Implementing runtime controls that limit the container's ability to abuse resources, escalate privileges, and run executables. 5. Using container-level network segmentation to limit the “blast radius” of what the poisoned image might do. 6. Validating a container runtime operates following least-privilege and least-access principles. 7. Building a threat profile of the container's runtime. This includes, but is not limited to, processes, network calls, and filesystem changes. 8. Validating the integrity of images before runtime by leveraging hashes and digital signatures. 9. Restrict images from being run based on rules establishing acceptable vulnerability severity levels. For example, prevent images with vulnerabilities that have a Moderate or higher CVSS rating from being run.",
    "metadata": {
      "id": "NIST-5.3",
      "source": "NIST.SP.800-190.pdf",
      "category_l1": "Container Threat Scenarios",
      "category_l2": "Running a Poisoned Image"
    }
  },
  {
    "page_content": "Title: 1.1.1 Ensure that the API server pod specification file permissions are set to 600 or more restrictive (Automated)\nDescription: Ensure that the API server pod specification file has permissions of 600 or more restrictive.\nRationale: The API server pod specification file controls various parameters that set the behavior of the API server. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %a /etc/kubernetes/manifests/kube-apiserver.yaml Verify that the permissions are 600 or more restrictive.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/manifests/kube-apiserver.yaml",
    "metadata": {
      "id": "CIS-1.1.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, the kube-apiserver.yaml file has permissions of 640.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.2 Ensure that the API server pod specification file ownership is set to root:root (Automated)\nDescription: Ensure that the API server pod specification file ownership is set to root:root.\nRationale: The API server pod specification file controls various parameters that set the behavior of the API server. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %U:%G /etc/kubernetes/manifests/kube-apiserver.yaml Verify that the ownership is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/manifests/kube-apiserver.yaml",
    "metadata": {
      "id": "CIS-1.1.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, the kube-apiserver.yaml file ownership is set to root:root.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.3 Ensure that the controller manager pod specification file permissions are set to 600 or more restrictive (Automated)\nDescription: Ensure that the controller manager pod specification file has permissions of 600 or more restrictive.\nRationale: The controller manager pod specification file controls various parameters that set the behavior of the Controller Manager on the master node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %a /etc/kubernetes/manifests/kube-controller-manager.yaml Verify that the permissions are 600 or more restrictive.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/manifests/kube-controller-manager.yaml",
    "metadata": {
      "id": "CIS-1.1.3",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, the kube-controller-manager.yaml file has permissions of 640.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root (Automated)\nDescription: Ensure that the controller manager pod specification file ownership is set to root:root.\nRationale: The controller manager pod specification file controls various parameters that set the behavior of various components of the master node. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %U:%G /etc/kubernetes/manifests/kube-controller-manager.yaml Verify that the ownership is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/manifests/kube-controller-manager.yaml",
    "metadata": {
      "id": "CIS-1.1.4",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, kube-controller-manager.yaml file ownership is set to root:root.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.5 Ensure that the scheduler pod specification file permissions are set to 600 or more restrictive (Automated)\nDescription: Ensure that the scheduler pod specification file has permissions of 600 or more restrictive.\nRationale: The scheduler pod specification file controls various parameters that set the behavior of the Scheduler service in the master node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %a /etc/kubernetes/manifests/kube-scheduler.yaml Verify that the permissions are 600 or more restrictive.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/manifests/kube-scheduler.yaml",
    "metadata": {
      "id": "CIS-1.1.5",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, kube-scheduler.yaml file has permissions of 640.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root (Automated)\nDescription: Ensure that the scheduler pod specification file ownership is set to root:root.\nRationale: The scheduler pod specification file controls various parameters that set the behavior of the kube-scheduler service in the master node. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %U:%G /etc/kubernetes/manifests/kube-scheduler.yaml Verify that the ownership is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/manifests/kube-scheduler.yaml",
    "metadata": {
      "id": "CIS-1.1.6",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, kube-scheduler.yaml file ownership is set to root:root.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.7 Ensure that the etcd pod specification file permissions are set to 600 or more restrictive (Automated)\nDescription: Ensure that the /etc/kubernetes/manifests/etcd.yaml file has permissions of 600 or more restrictive.\nRationale: The etcd pod specification file /etc/kubernetes/manifests/etcd.yaml controls various parameters that set the behavior of the etcd service in the master node. etcd is a highly-available key-value store which Kubernetes uses for persistent storage of all of its REST API object. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %a /etc/kubernetes/manifests/etcd.yaml Verify that the permissions are 600 or more restrictive.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/manifests/etcd.yaml",
    "metadata": {
      "id": "CIS-1.1.7",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, /etc/kubernetes/manifests/etcd.yaml file has permissions of 640.",
      "references": [
        "https://coreos.com/etcd",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root (Automated)\nDescription: Ensure that the /etc/kubernetes/manifests/etcd.yaml file ownership is set to root:root.\nRationale: The etcd pod specification file /etc/kubernetes/manifests/etcd.yaml controls various parameters that set the behavior of the etcd service in the master node. etcd is a highly-available key-value store which Kubernetes uses for persistent storage of all of its REST API object. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %U:%G /etc/kubernetes/manifests/etcd.yaml Verify that the ownership is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/manifests/etcd.yaml",
    "metadata": {
      "id": "CIS-1.1.8",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, /etc/kubernetes/manifests/etcd.yaml file ownership is set to root:root.",
      "references": [
        "https://coreos.com/etcd",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.9 Ensure that the Container Network Interface file permissions are set to 600 or more restrictive (Manual)\nDescription: Ensure that the Container Network Interface files have permissions of 600 or more restrictive.\nRationale: Container Network Interface provides various networking options for overlay networking. You should consult their documentation and restrict their respective file permissions to maintain the integrity of those files. Those files should be writable by only the administrators on the system.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %a <path/to/cni/files> Verify that the permissions are 600 or more restrictive.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 <path/to/cni/files>",
    "metadata": {
      "id": "CIS-1.1.9",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "NA",
      "references": [
        "https://kubernetes.io/docs/concepts/cluster-administration/networking/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.10 Ensure that the Container Network Interface file ownership is set to root:root (Manual)\nDescription: Ensure that the Container Network Interface files have ownership set to root:root.\nRationale: Container Network Interface provides various networking options for overlay networking. You should consult their documentation and restrict their respective file permissions to maintain the integrity of those files. Those files should be owned by root:root.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %U:%G <path/to/cni/files> Verify that the ownership is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root <path/to/cni/files>",
    "metadata": {
      "id": "CIS-1.1.10",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "NA",
      "references": [
        "https://kubernetes.io/docs/concepts/cluster-administration/networking/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.11 Ensure that the etcd data directory permissions are set to 700 or more restrictive (Automated)\nDescription: Ensure that the etcd data directory has permissions of 700 or more restrictive.\nRationale: etcd is a highly-available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. This data directory should be protected from any unauthorized reads or writes. It should not be readable or writable by any group members or the world.\nAudit: On the etcd server node, get the etcd data directory, passed as an argument --data- dir, from the below command: ps -ef | grep etcd Run the below command (based on the etcd data directory found above). For example, stat -c %a /var/lib/etcd Verify that the permissions are 700 or more restrictive.\nRemediation: On the etcd server node, get the etcd data directory, passed as an argument --data- dir, from the below command: ps -ef | grep etcd Run the below command (based on the etcd data directory found above). For example, chmod 700 /var/lib/etcd",
    "metadata": {
      "id": "CIS-1.1.11",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, etcd data directory has permissions of 755.",
      "references": [
        "https://coreos.com/etcd/docs/latest/op-guide/configuration.html#data-dir",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.12 Ensure that the etcd data directory ownership is set to etcd:etcd (Automated)\nDescription: Ensure that the etcd data directory ownership is set to etcd:etcd.\nRationale: etcd is a highly-available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. This data directory should be protected from any unauthorized reads or writes. It should be owned by etcd:etcd.\nAudit: On the etcd server node, get the etcd data directory, passed as an argument --data- dir, from the below command: ps -ef | grep etcd Run the below command (based on the etcd data directory found above). For example, stat -c %U:%G /var/lib/etcd Verify that the ownership is set to etcd:etcd.\nRemediation: On the etcd server node, get the etcd data directory, passed as an argument --data- dir, from the below command: ps -ef | grep etcd Run the below command (based on the etcd data directory found above). For example, chown etcd:etcd /var/lib/etcd",
    "metadata": {
      "id": "CIS-1.1.12",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, etcd data directory ownership is set to etcd:etcd.",
      "references": [
        "https://coreos.com/etcd/docs/latest/op-guide/configuration.html#data-dir",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.13 Ensure that the default administrative credential file permissions are set to 600 (Automated)\nDescription: Ensure that the admin.conf file (and super-admin.conf file, where it exists) have permissions of 600.\nRationale: As part of initial cluster setup, default kubeconfig files are created to be used by the administrator of the cluster. These files contain private keys and certificates which allow for privileged access to the cluster. You should restrict their file permissions to maintain the integrity and confidentiality of the file(s). The file(s) should be readable and writable by only the administrators on the system.\nAudit: Run the following command (based on the file location on your system) on the Control Plane node. For example, stat -c %a /etc/kubernetes/admin.conf On Kubernetes version 1.29 and higher run the following command as well :- stat -c %a /etc/kubernetes/super-admin.conf Verify that the permissions are 600 or more restrictive.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/admin.conf On Kubernetes 1.29+ the super-admin.conf file should also be modified, if present. For example, chmod 600 /etc/kubernetes/super-admin.conf",
    "metadata": {
      "id": "CIS-1.1.13",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None.",
      "default_value": "By default, admin.conf and super-admin.conf have permissions of 600. Page 44 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/",
        "https://raesene.github.io/blog/2024/01/06/when-is-admin-not-admin/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.14 Ensure that the default administrative credential file ownership is set to root:root (Automated)\nDescription: Ensure that the admin.conf (and super-admin.conf file, where it exists) file ownership is set to root:root.\nRationale: As part of initial cluster setup, default kubeconfig files are created to be used by the administrator of the cluster. These files contain private keys and certificates which allow for privileged access to the cluster. You should set their file ownership to maintain the integrity and confidentiality of the file. The file(s) should be owned by root:root.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %U:%G /etc/kubernetes/admin.conf On Kubernetes version 1.29 and higher run the following command as well :- stat -c %U:%G /etc/kubernetes/super-admin.conf Verify that the ownership is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/admin.conf On Kubernetes 1.29+ the super-admin.conf file should also be modified, if present. For example, chown root:root /etc/kubernetes/super-admin.conf",
    "metadata": {
      "id": "CIS-1.1.14",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None.",
      "default_value": "By default, admin.conf and super-admin.conf file ownership is set to root:root. Page 46 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://raesene.github.io/blog/2024/01/06/when-is-admin-not-admin/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.15 Ensure that the scheduler.conf file permissions are set to 600 or more restrictive (Automated)\nDescription: Ensure that the scheduler.conf file has permissions of 600 or more restrictive.\nRationale: The scheduler.conf file is the kubeconfig file for the Scheduler. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\nAudit: Run the following command (based on the file location on your system) on the Control Plane node. For example, stat -c %a /etc/kubernetes/scheduler.conf Verify that the permissions are 600 or more restrictive.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/scheduler.conf",
    "metadata": {
      "id": "CIS-1.1.15",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, scheduler.conf has permissions of 640.",
      "references": [
        "https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.16 Ensure that the scheduler.conf file ownership is set to root:root (Automated)\nDescription: Ensure that the scheduler.conf file ownership is set to root:root.\nRationale: The scheduler.conf file is the kubeconfig file for the Scheduler. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %U:%G /etc/kubernetes/scheduler.conf Verify that the ownership is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/scheduler.conf",
    "metadata": {
      "id": "CIS-1.1.16",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, scheduler.conf file ownership is set to root:root.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.17 Ensure that the controller-manager.conf file permissions are set to 600 or more restrictive (Automated)\nDescription: Ensure that the controller-manager.conf file has permissions of 600 or more restrictive.\nRationale: The controller-manager.conf file is the kubeconfig file for the Controller Manager. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\nAudit: Run the following command (based on the file location on your system) on the Control Plane node. For example, stat -c %a /etc/kubernetes/controller-manager.conf Verify that the permissions are 600 or more restrictive.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod 600 /etc/kubernetes/controller-manager.conf",
    "metadata": {
      "id": "CIS-1.1.17",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, controller-manager.conf has permissions of 640.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.18 Ensure that the controller-manager.conf file ownership is set to root:root (Automated)\nDescription: Ensure that the controller-manager.conf file ownership is set to root:root.\nRationale: The controller-manager.conf file is the kubeconfig file for the Controller Manager. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c %U:%G /etc/kubernetes/controller-manager.conf Verify that the ownership is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chown root:root /etc/kubernetes/controller-manager.conf",
    "metadata": {
      "id": "CIS-1.1.18",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, controller-manager.conf file ownership is set to root:root.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.19 Ensure that the Kubernetes PKI directory and file ownership is set to root:root (Automated)\nDescription: Ensure that the Kubernetes PKI directory and file ownership is set to root:root.\nRationale: Kubernetes makes use of a number of certificates as part of its operation. You should set the ownership of the directory containing the PKI information and all files in that directory to maintain their integrity. The directory and files should be owned by root:root.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, ls -laR /etc/kubernetes/pki/ Verify that the ownership of all files and directories in this hierarchy is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chown -R root:root /etc/kubernetes/pki/",
    "metadata": {
      "id": "CIS-1.1.19",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, the /etc/kubernetes/pki/ directory and all of the files and directories contained within it, are set to be owned by the root user.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.20 Ensure that the Kubernetes PKI certificate file permissions are set to 644 or more restrictive (Manual)\nDescription: Ensure that Kubernetes PKI certificate files have permissions of 644 or more restrictive.\nRationale: Kubernetes makes use of a number of certificate files as part of the operation of its components. The permissions on these files should be set to 644 or more restrictive to protect their integrity and confidentiality.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c '%a' /etc/kubernetes/pki/*.crt Verify that the permissions are 644 or more restrictive. or ls -l /etc/kubernetes/pki/*.crt Verify -rw------\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod -R 644 /etc/kubernetes/pki/*.crt",
    "metadata": {
      "id": "CIS-1.1.20",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, the certificates used by Kubernetes are set to have permissions of 644",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.1.21 Ensure that the Kubernetes PKI key file permissions are set to 600 (Manual)\nDescription: Ensure that Kubernetes PKI key files have permissions of 600.\nRationale: Kubernetes makes use of a number of key files as part of the operation of its components. The permissions on these files should be set to 600 to protect their integrity and confidentiality.\nAudit: Run the below command (based on the file location on your system) on the Control Plane node. For example, stat -c '%a' /etc/kubernetes/pki/*.key Verify that the permissions are 600 or more restrictive. or ls -l /etc/kubernetes/pki/*.key Verify that the permissions are -rw------\nRemediation: Run the below command (based on the file location on your system) on the Control Plane node. For example, chmod -R 600 /etc/kubernetes/pki/*.key",
    "metadata": {
      "id": "CIS-1.1.21",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, the keys used by Kubernetes are set to have permissions of 600",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.1 Ensure that the --anonymous-auth argument is set to false (Manual)\nDescription: Disable anonymous requests to the API server.\nRationale: When enabled, requests that are not rejected by other configured authentication methods are treated as anonymous requests. These requests are then served by the API server. You should rely on authentication to authorize access and disallow anonymous requests. If you are using RBAC authorization, it is generally considered reasonable to allow anonymous access to the API Server for health checks and discovery purposes, and hence this recommendation is not scored. However, you should consider whether anonymous discovery is an acceptable risk for your purposes.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --anonymous-auth argument is set to false. Alternative Audit kubectl get pod -nkube-system -lcomponent=kube-apiserver -o=jsonpath='{range .items[*]}{.spec.containers[*].command} {\"\\n\"}{end}' | grep '\\--anonymous- auth' | grep -i false If the exit code is '1', then the control isn't present / failed\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the below parameter. --anonymous-auth=false",
    "metadata": {
      "id": "CIS-1.2.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "Anonymous requests will be rejected.",
      "default_value": "By default, anonymous access is enabled. Page 63 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.2 Ensure that the --token-auth-file parameter is not set (Automated)\nDescription: Do not use token based authentication.\nRationale: The token-based authentication utilizes static tokens to authenticate requests to the apiserver. The tokens are stored in clear-text in a file on the apiserver, and cannot be revoked or rotated without restarting the apiserver. Hence, do not use static token- based authentication.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --token-auth-file argument does not exist. Alternative Audit Method kubectl get pod -nkube-system -lcomponent=kube-apiserver -o=jsonpath='{range .items[*]}{.spec.containers[*].command} {\"\\n\"}{end}' | grep '\\--token-auth- file' | grep -i false If the exit code is '1', then the control isn't present / failed\nRemediation: Follow the documentation and configure alternate mechanisms for authentication. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the master node and remove the --token-auth- file=<filename> parameter.",
    "metadata": {
      "id": "CIS-1.2.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "You will have to configure and use alternate authentication mechanisms such as certificates. Static token based authentication could not be used.",
      "default_value": "By default, --token-auth-file argument is not set. Page 65 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.3 Ensure that the DenyServiceExternalIPs is set (Manual)\nDescription: This admission controller rejects all net-new usage of the Service field externalIPs.\nRationale: Most users do not need the ability to set the externalIPs field for a Service at all, and cluster admins should consider disabling this functionality by enabling the DenyServiceExternalIPs admission controller. Clusters that do need to allow this functionality should consider using some custom policy to manage its usage.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the `DenyServiceExternalIPs' argument exist as a string value in --enable- admission-plugins.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the master node and append the Kubernetes API server flag -- enable-admission-plugins with the DenyServiceExternalIPs plugin. Note, the Kubernetes API server flag --enable-admission-plugins takes a comma-delimited list of admission control plugins to be enabled, even if they are in the list of plugins enabled by default. kube-apiserver --enable-admission-plugins=DenyServiceExternalIPs",
    "metadata": {
      "id": "CIS-1.2.3",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "When enabled, users of the cluster may not create new Services which use externalIPs and may not add new values to externalIPs on existing Service objects.",
      "default_value": "By default, --enable-admission-plugins=DenyServiceExternalIP argument is not set, and the use of externalIPs is authorized.",
      "references": [
        "https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.4 Ensure that the --kubelet-client-certificate and --kubelet- client-key arguments are set as appropriate (Automated)\nDescription: Enable certificate based kubelet authentication.\nRationale: The apiserver, by default, does not authenticate itself to the kubelet's HTTPS endpoints. The requests from the apiserver are treated anonymously. You should set up certificate- based kubelet authentication to ensure that the apiserver authenticates itself to kubelets when submitting requests.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --kubelet-client-certificate and --kubelet-client-key arguments exist and they are set as appropriate. Alternative Audit kubectl get pod -nkube-system -lcomponent=kube-apiserver -o=jsonpath='{range .items[]}{.spec.containers[].command} {\"\\n\"}{end}' | grep '--kubelet-client- certificate' | grep -i false If the exit code is '1', then the control isn't present / failed\nRemediation: Follow the Kubernetes documentation and set up the TLS connection between the apiserver and kubelets. Then, edit API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the kubelet client certificate and key parameters as below. --kubelet-client-certificate=<path/to/client-certificate-file> --kubelet-client-key=<path/to/client-key-file>",
    "metadata": {
      "id": "CIS-1.2.4",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "You require TLS to be configured on apiserver as well as kubelets.",
      "default_value": "By default, certificate-based kubelet authentication is not set. Page 69 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.5 Ensure that the --kubelet-certificate-authority argument is set as appropriate (Automated)\nDescription: Verify kubelet's certificate before establishing connection.\nRationale: The connections from the apiserver to the kubelet are used for fetching logs for pods, attaching (through kubectl) to running pods, and using the kubelet’s port-forwarding functionality. These connections terminate at the kubelet’s HTTPS endpoint. By default, the apiserver does not verify the kubelet’s serving certificate, which makes the connection subject to man-in-the-middle attacks, and unsafe to run over untrusted and/or public networks.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --kubelet-certificate-authority argument exists and is set as appropriate. Alternative Audit kubectl get pod -nkube-system -lcomponent=kube-apiserver -o=jsonpath='{range .items[]}{.spec.containers[].command} {\"\\n\"}{end}' | grep '--kubelet- certificate-Authority' | grep -i false If the exit code is '1', then the control isn't present / failed\nRemediation: Follow the Kubernetes documentation and setup the TLS connection between the apiserver and kubelets. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --kubelet-certificate-authority parameter to the path to the cert file for the certificate authority. Internal Only - General --kubelet-certificate-authority=<ca-string>",
    "metadata": {
      "id": "CIS-1.2.5",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "You require TLS to be configured on apiserver as well as kubelets.",
      "default_value": "By default, --kubelet-certificate-authority argument is not set.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.6 Ensure that the --authorization-mode argument is not set to AlwaysAllow (Automated)\nDescription: Do not always authorize all requests.\nRationale: The API Server, can be configured to allow all requests. This mode should not be used on any production cluster.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --authorization-mode argument exists and is not set to AlwaysAllow.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the --authorization-mode parameter to values other than AlwaysAllow. One such example could be as below. --authorization-mode=RBAC",
    "metadata": {
      "id": "CIS-1.2.6",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "Only authorized requests will be served.",
      "default_value": "By default, AlwaysAllow is not enabled.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.7 Ensure that the --authorization-mode argument includes Node (Automated)\nDescription: Restrict kubelet nodes to reading only objects associated with them.\nRationale: The Node authorization mode only allows kubelets to read Secret, ConfigMap, PersistentVolume, and PersistentVolumeClaim objects associated with their nodes.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --authorization-mode argument exists and is set to a value to include Node.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the --authorization-mode parameter to a value that includes Node. --authorization-mode=Node,RBAC",
    "metadata": {
      "id": "CIS-1.2.7",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, Node authorization is not enabled.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/kubernetes/pull/46076",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.8 Ensure that the --authorization-mode argument includes RBAC (Automated)\nDescription: Turn on Role Based Access Control.\nRationale: Role Based Access Control (RBAC) allows fine-grained control over the operations that different entities can perform on different objects in the cluster. It is recommended to use the RBAC authorization mode.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --authorization-mode argument exists and is set to a value to include RBAC.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the --authorization-mode parameter to a value that includes RBAC, for example: --authorization-mode=Node,RBAC",
    "metadata": {
      "id": "CIS-1.2.8",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "When RBAC is enabled you will need to ensure that appropriate RBAC settings (including Roles, RoleBindings and ClusterRoleBindings) are configured to allow appropriate access.",
      "default_value": "By default, RBAC authorization is not enabled.",
      "references": [
        "https://kubernetes.io/docs/reference/access-authn-authz/rbac/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.9 Ensure that the admission control plugin EventRateLimit is set (Manual)\nDescription: Limit the rate at which the API server accepts requests.\nRationale: Using EventRateLimit admission control enforces a limit on the number of events that the API Server will accept in a given time slice. A misbehaving workload could overwhelm and DoS the API Server, making it unavailable. This particularly applies to a multi-tenant cluster, where there might be a small percentage of misbehaving tenants which could have a significant impact on the performance of the cluster overall. Hence, it is recommended to limit the rate of events that the API server will accept.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --enable-admission-plugins argument is set to a value that includes EventRateLimit.\nRemediation: Follow the Kubernetes documentation and set the desired limits in a configuration file. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml and set the below parameters. --enable-admission-plugins=...,EventRateLimit,... --admission-control-config-file=<path/to/configuration/file>",
    "metadata": {
      "id": "CIS-1.2.9",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "You need to carefully tune in limits as per your environment.",
      "default_value": "By default, EventRateLimit is not set.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://github.com/staebler/community/blob/9873b632f4d99b5d99c38c9b15fe2f8"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.10 Ensure that the admission control plugin AlwaysAdmit is not set (Automated)\nDescription: Do not allow all requests.\nRationale: Setting admission control plugin AlwaysAdmit allows all requests and do not filter any requests. The AlwaysAdmit admission controller was deprecated in Kubernetes v1.13. Its behavior was equivalent to turning off all admission controllers.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that if the --enable-admission-plugins argument is set, its value does not include AlwaysAdmit.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and either remove the --enable- admission-plugins parameter, or set it to a value that does not include AlwaysAdmit.",
    "metadata": {
      "id": "CIS-1.2.10",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "Only requests explicitly allowed by the admissions control plugins would be served.",
      "default_value": "AlwaysAdmit is not in the list of default admission plugins.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.11 Ensure that the admission control plugin AlwaysPullImages is set (Manual)\nDescription: Always pull images.\nRationale: Setting admission control policy to AlwaysPullImages forces every new pod to pull the required images every time. In a multi-tenant cluster users can be assured that their private images can only be used by those who have the credentials to pull them. Without this admission control policy, once an image has been pulled to a node, any pod from any user can use it simply by knowing the image’s name, without any authorization check against the image ownership. When this plug-in is enabled, images are always pulled prior to starting containers, which means valid credentials are required.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --enable-admission-plugins argument is set to a value that includes AlwaysPullImages.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the --enable-admission- plugins parameter to include AlwaysPullImages. --enable-admission-plugins=...,AlwaysPullImages,...",
    "metadata": {
      "id": "CIS-1.2.11",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "Credentials would be required to pull the private images every time. Also, in trusted environments, this might increases load on network, registry, and decreases speed. This setting could impact offline or isolated clusters, which have images preloaded and do not have access to a registry to pull in-use images. This setting is not appropriate for clusters which use this configuration.",
      "default_value": "By default, AlwaysPullImages is not set. Page 83 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.12 Ensure that the admission control plugin ServiceAccount is set (Automated)\nDescription: Automate service accounts management.\nRationale: When you create a pod, if you do not specify a service account, it is automatically assigned the default service account in the same namespace. You should create your own service account and let the API server manage its security tokens.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --disable-admission-plugins argument is set to a value that does not includes ServiceAccount.\nRemediation: Follow the documentation and create ServiceAccount objects as per your environment. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and ensure that the --disable-admission-plugins parameter is set to a value that does not include ServiceAccount.",
    "metadata": {
      "id": "CIS-1.2.12",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None.",
      "default_value": "By default, ServiceAccount is set.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.13 Ensure that the admission control plugin NamespaceLifecycle is set (Automated)\nDescription: Reject creating objects in a namespace that is undergoing termination.\nRationale: Setting admission control policy to NamespaceLifecycle ensures that objects cannot be created in non-existent namespaces, and that namespaces undergoing termination are not used for creating the new objects. This is recommended to enforce the integrity of the namespace termination process and also for the availability of the newer objects.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --disable-admission-plugins argument is set to a value that does not include NamespaceLifecycle.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the --disable-admission- plugins parameter to ensure it does not include NamespaceLifecycle.",
    "metadata": {
      "id": "CIS-1.2.13",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, NamespaceLifecycle is set.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.14 Ensure that the admission control plugin NodeRestriction is set (Automated)\nDescription: Limit the Node and Pod objects that a kubelet could modify.\nRationale: Using the NodeRestriction plug-in ensures that the kubelet is restricted to the Node and Pod objects that it could modify as defined. Such kubelets will only be allowed to modify their own Node API object, and only modify Pod API objects that are bound to their node.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --enable-admission-plugins argument is set to a value that includes NodeRestriction.\nRemediation: Follow the Kubernetes documentation and configure NodeRestriction plug-in on kubelets. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the --enable-admission-plugins parameter to a value that includes NodeRestriction. --enable-admission-plugins=...,NodeRestriction,...",
    "metadata": {
      "id": "CIS-1.2.14",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, NodeRestriction is not set.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/reference/access-authn-authz/node/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.15 Ensure that the --profiling argument is set to false (Automated)\nDescription: Disable profiling, if not needed.\nRationale: Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --profiling argument is set to false.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the below parameter. --profiling=false",
    "metadata": {
      "id": "CIS-1.2.15",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "Profiling information would not be available.",
      "default_value": "By default, profiling is enabled.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.16 Ensure that the --audit-log-path argument is set (Automated)\nDescription: Enable auditing on the Kubernetes API Server and set the desired audit log path.\nRationale: Auditing the Kubernetes API Server provides a security-relevant chronological set of records documenting the sequence of activities that have affected system by individual users, administrators or other components of the system. Even though currently, Kubernetes provides only basic audit capabilities, it should be enabled. You can enable it by setting an appropriate audit log path.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --audit-log-path argument is set as appropriate.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the --audit-log-path parameter to a suitable path and file where you would like audit logs to be written, for example: --audit-log-path=/var/log/apiserver/audit.log",
    "metadata": {
      "id": "CIS-1.2.16",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, auditing is not enabled.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/",
        "https://github.com/kubernetes/enhancements/issues/22"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.17 Ensure that the --audit-log-maxage argument is set to 30 or as appropriate (Automated)\nDescription: Retain the logs for at least 30 days or as appropriate.\nRationale: Retaining logs for at least 30 days ensures that you can go back in time and investigate or correlate any events. Set your audit log retention period to 30 days or as per your business requirements.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --audit-log-maxage argument is set to 30 or as appropriate.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the --audit-log-maxage parameter to 30 or as an appropriate number of days: --audit-log-maxage=30",
    "metadata": {
      "id": "CIS-1.2.17",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, auditing is not enabled.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/",
        "https://github.com/kubernetes/enhancements/issues/22"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.18 Ensure that the --audit-log-maxbackup argument is set to 10 or as appropriate (Automated)\nDescription: Retain 10 or an appropriate number of old log files.\nRationale: Kubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. For example, if you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --audit-log-maxbackup argument is set to 10 or as appropriate.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the --audit-log-maxbackup parameter to 10 or to an appropriate value. --audit-log-maxbackup=10",
    "metadata": {
      "id": "CIS-1.2.18",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, auditing is not enabled.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/",
        "https://github.com/kubernetes/enhancements/issues/22"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.19 Ensure that the --audit-log-maxsize argument is set to 100 or as appropriate (Automated)\nDescription: Rotate log files on reaching 100 MB or as appropriate.\nRationale: Kubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. If you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --audit-log-maxsize argument is set to 100 or as appropriate.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the --audit-log-maxsize parameter to an appropriate size in MB. For example, to set it as 100 MB: --audit-log-maxsize=100",
    "metadata": {
      "id": "CIS-1.2.19",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, auditing is not enabled.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/",
        "https://github.com/kubernetes/enhancements/issues/22"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.20 Ensure that the --request-timeout argument is set as appropriate (Manual)\nDescription: Set global request timeout for API server requests as appropriate.\nRationale: Setting global request timeout allows extending the API server request timeout limit to a duration appropriate to the user's connection speed. By default, it is set to 60 seconds which might be problematic on slower connections making cluster resources inaccessible once the data volume for requests exceeds what can be transmitted in 60 seconds. But, setting this timeout limit to be too large can exhaust the API server resources making it prone to Denial-of-Service attack. Hence, it is recommended to set this limit as appropriate and change the default limit of 60 seconds only if needed.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --request-timeout argument is either not set or set to an appropriate value.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml and set the below parameter as appropriate and if needed. For example, --request-timeout=300s",
    "metadata": {
      "id": "CIS-1.2.20",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, --request-timeout is set to 60 seconds.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/kubernetes/pull/51415"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.21 Ensure that the --service-account-lookup argument is set to true (Automated)\nDescription: Validate service account before validating token.\nRationale: If --service-account-lookup is not enabled, the apiserver only verifies that the authentication token is valid, and does not validate that the service account token mentioned in the request is actually present in etcd. This allows using a service account token even after the corresponding service account is deleted. This is an example of time of check to time of use security issue.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that if the --service-account-lookup argument exists it is set to true.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the below parameter. --service-account-lookup=true Alternatively, you can delete the --service-account-lookup parameter from this file so that the default takes effect.",
    "metadata": {
      "id": "CIS-1.2.21",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, --service-account-lookup argument is set to true.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/kubernetes/issues/24167",
        "https://en.wikipedia.org/wiki/Time-of-check_to_time-of-use"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.22 Ensure that the --service-account-key-file argument is set as appropriate (Automated)\nDescription: Explicitly set a service account public key file for service accounts on the apiserver.\nRationale: By default, if no --service-account-key-file is specified to the apiserver, it uses the private key from the TLS serving certificate to verify service account tokens. To ensure that the keys for service account tokens could be rotated as needed, a separate public/private key pair should be used for signing service account tokens. Hence, the public key should be specified to the apiserver with --service-account-key-file.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --service-account-key-file argument exists and is set as appropriate.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the Control Plane node and set the --service-account-key- file parameter to the public key file for service accounts: --service-account-key-file=<filename>",
    "metadata": {
      "id": "CIS-1.2.22",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "The corresponding private key must be provided to the controller manager. You would need to securely maintain the key file and rotate the keys based on your organization's key rotation policy.",
      "default_value": "By default, --service-account-key-file argument is not set.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/kubernetes/issues/24167"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.23 Ensure that the --etcd-certfile and --etcd-keyfile arguments are set as appropriate (Automated)\nDescription: etcd should be configured to make use of TLS encryption for client connections.\nRationale: etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be protected by client authentication. This requires the API server to identify itself to the etcd server using a client certificate and key.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --etcd-certfile and --etcd-keyfile arguments exist and they are set as appropriate.\nRemediation: Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the etcd certificate and key file parameters. --etcd-certfile=<path/to/client-certificate-file> --etcd-keyfile=<path/to/client-key-file>",
    "metadata": {
      "id": "CIS-1.2.23",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "TLS and client certificate authentication must be configured for etcd.",
      "default_value": "By default, --etcd-certfile and --etcd-keyfile arguments are not set",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.24 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Automated)\nDescription: Setup TLS connection on the API server.\nRationale: API server communication contains sensitive parameters that should remain encrypted in transit. Configure the API server to serve only HTTPS traffic.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --tls-cert-file and --tls-private-key-file arguments exist and they are set as appropriate.\nRemediation: Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the master node and set the TLS certificate and private key file parameters. --tls-cert-file=<path/to/tls-certificate-file> --tls-private-key-file=<path/to/tls-key-file>",
    "metadata": {
      "id": "CIS-1.2.24",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "TLS and client certificate authentication must be configured for your Kubernetes cluster deployment.",
      "default_value": "By default, --tls-cert-file and --tls-private-key-file are presented and created for use.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/kelseyhightower/docker-kubernetes-tls-guide"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.25 Ensure that the --client-ca-file argument is set as appropriate (Automated)\nDescription: Setup TLS connection on the API server.\nRationale: API server communication contains sensitive parameters that should remain encrypted in transit. Configure the API server to serve only HTTPS traffic. If --client-ca-file argument is set, any request presenting a client certificate signed by one of the authorities in the client-ca-file is authenticated with an identity corresponding to the CommonName of the client certificate.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --client-ca-file argument exists and it is set as appropriate.\nRemediation: Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the master node and set the client certificate authority file. --client-ca-file=<path/to/client-ca-file>",
    "metadata": {
      "id": "CIS-1.2.25",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "TLS and client certificate authentication must be configured for your Kubernetes cluster deployment.",
      "default_value": "By default, --client-ca-file argument is not set.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/kelseyhightower/docker-kubernetes-tls-guide"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.26 Ensure that the --etcd-cafile argument is set as appropriate (Automated)\nDescription: etcd should be configured to make use of TLS encryption for client connections.\nRationale: etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be protected by client authentication. This requires the API server to identify itself to the etcd server using a SSL Certificate Authority file.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --etcd-cafile argument exists and it is set as appropriate.\nRemediation: Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the etcd certificate authority file parameter. --etcd-cafile=<path/to/ca-file>",
    "metadata": {
      "id": "CIS-1.2.26",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "TLS and client certificate authentication must be configured for etcd.",
      "default_value": "By default, --etcd-cafile is not set.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.27 Ensure that the --encryption-provider-config argument is set as appropriate (Manual)\nDescription: Encrypt etcd key-value store.\nRationale: etcd is a highly available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted at rest to avoid any disclosures.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --encryption-provider-config argument is set to a EncryptionConfig file. Additionally, ensure that the EncryptionConfig file has all the desired resources covered especially any secrets.\nRemediation: Follow the Kubernetes documentation and configure a EncryptionConfig file. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube- apiserver.yaml on the master node and set the --encryption-provider-config parameter to the path of that file: --encryption-provider-config=</path/to/EncryptionConfig/File>",
    "metadata": {
      "id": "CIS-1.2.27",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, --encryption-provider-config is not set.",
      "references": [
        "https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/enhancements/issues/92"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.28 Ensure that encryption providers are appropriately configured (Manual)\nDescription: Where etcd encryption is used, appropriate providers should be configured.\nRationale: Where etcd encryption is used, it is important to ensure that the appropriate set of encryption providers is used. Currently, the aescbc, kms, and secretbox are likely to be appropriate options.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Get the EncryptionConfig file set for --encryption-provider-config argument. Verify that aescbc, kms, or secretbox is set as the encryption provider for all the desired resources.\nRemediation: Follow the Kubernetes documentation and configure a EncryptionConfig file. In this file, choose aescbc, kms, or secretbox as the encryption provider.",
    "metadata": {
      "id": "CIS-1.2.28",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, no encryption provider is set.",
      "references": [
        "https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/enhancements/issues/92",
        "https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/#providers"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.29 Ensure that the API Server only makes use of Strong Cryptographic Ciphers (Manual)\nDescription: Ensure that the API server is configured to only use strong cryptographic ciphers.\nRationale: TLS ciphers have had a number of known vulnerabilities and weaknesses, which can reduce the protection provided by them. By default Kubernetes supports a number of TLS cipher suites including some that have security concerns, weakening the protection provided.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --tls-cipher-suites argument is set as outlined in the remediation procedure below.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the below parameter. --tls-cipher- suites=TLS_AES_128_GCM_SHA256,TLS_AES_256_GCM_SHA384,TLS_CHACHA20_POLY1305_SH A256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM _SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_ POLY1305_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_ 256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA 20_POLY1305_SHA256",
    "metadata": {
      "id": "CIS-1.2.29",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "API server clients that cannot support modern cryptographic ciphers will not be able to make connections to the API server.",
      "default_value": "By default the Kubernetes API server supports a wide range of TLS ciphers Page 119 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/ssllabs/research/wiki/SSL-and-TLS-Deployment-Best-"
      ]
    }
  },
  {
    "page_content": "Title: 1.2.30 Ensure that the --service-account-extend-token-expiration parameter is set to false (Automated)\nDescription: By default Kubernetes extends service account token lifetimes to one year to aid in transition from the legacy token settings.\nRationale: This default setting is not ideal for security as it ignores other settings related to maximum token lifetime and means that a lost or stolen credential could be valid for an extended period of time.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-apiserver Verify that the --service-account-extend-token-expiration argument is set to false.\nRemediation: Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --service-account-extend-token-expiration parameter to false. --service-account-extend-token-expiration=false",
    "metadata": {
      "id": "CIS-1.2.30",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "Disabling this setting means that the service account token expiry set in the cluster will be enforced, and service account tokens will expire at the end of that time frame.",
      "default_value": "By default, this parameter is set to true",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.3.1 Ensure that the --terminated-pod-gc-threshold argument is set as appropriate (Manual)\nDescription: Activate garbage collector on pod termination, as appropriate.\nRationale: Garbage collection is important to ensure sufficient resource availability and avoiding degraded performance and availability. In the worst case, the system might crash or just be unusable for a long period of time. The current setting for garbage collection is 12,500 terminated pods which might be too high for your system to sustain. Based on your system resources and tests, choose an appropriate threshold value to activate garbage collection.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-controller-manager Verify that the --terminated-pod-gc-threshold argument is set as appropriate.\nRemediation: Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube- controller-manager.yaml on the Control Plane node and set the --terminated- pod-gc-threshold to an appropriate threshold, for example: --terminated-pod-gc-threshold=10",
    "metadata": {
      "id": "CIS-1.3.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, --terminated-pod-gc-threshold is set to 12500.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/kubernetes/issues/28484"
      ]
    }
  },
  {
    "page_content": "Title: 1.3.2 Ensure that the --profiling argument is set to false (Automated)\nDescription: Disable profiling, if not needed.\nRationale: Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-controller-manager Verify that the --profiling argument is set to false.\nRemediation: Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube- controller-manager.yaml on the Control Plane node and set the below parameter. --profiling=false",
    "metadata": {
      "id": "CIS-1.3.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "Profiling information would not be available.",
      "default_value": "By default, profiling is enabled.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.3.3 Ensure that the --use-service-account-credentials argument is set to true (Automated)\nDescription: Use individual service account credentials for each controller.\nRationale: The controller manager creates a service account per controller in the kube-system namespace, generates a credential for it, and builds a dedicated API client with that service account credential for each controller loop to use. Setting the --use-service- account-credentials to true runs each control loop within the controller manager using a separate service account credential. When used in combination with RBAC, this ensures that the control loops run with the minimum permissions required to perform their intended tasks.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-controller-manager Verify that the --use-service-account-credentials argument is set to true.\nRemediation: Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube- controller-manager.yaml on the Control Plane node to set the below parameter. Internal Only - General --use-service-account-credentials=true",
    "metadata": {
      "id": "CIS-1.3.3",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "Whatever authorizer is configured for the cluster, it must grant sufficient permissions to the service accounts to perform their intended tasks. When using the RBAC authorizer, those roles are created and bound to the appropriate service accounts in the kube- system namespace automatically with default roles and rolebindings that are auto- reconciled on startup. If using other authorization methods (ABAC, Webhook, etc), the cluster deployer is responsible for granting appropriate permissions to the service accounts (the required permissions can be seen by inspecting the controller-roles.yaml and controller- role-bindings.yaml files for the RBAC roles.",
      "default_value": "By default, --use-service-account-credentials is set to false.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.3.4 Ensure that the --service-account-private-key-file argument is set as appropriate (Automated)\nDescription: Explicitly set a service account private key file for service accounts on the controller manager.\nRationale: To ensure that keys for service account tokens can be rotated as needed, a separate public/private key pair should be used for signing service account tokens. The private key should be specified to the controller manager with --service-account-private- key-file as appropriate.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-controller-manager Verify that the --service-account-private-key-file argument is set as appropriate.\nRemediation: Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube- controller-manager.yaml on the Control Plane node and set the --service- account-private-key-file parameter to the private key file for service accounts. --service-account-private-key-file=<filename>",
    "metadata": {
      "id": "CIS-1.3.4",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "You would need to securely maintain the key file and rotate the keys based on your organization's key rotation policy.",
      "default_value": "By default, --service-account-private-key-file it not set.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.3.5 Ensure that the --root-ca-file argument is set as appropriate (Automated)\nDescription: Allow pods to verify the API server's serving certificate before establishing connections.\nRationale: Processes running within pods that need to contact the API server must verify the API server's serving certificate. Failing to do so could be a subject to man-in-the-middle attacks. Providing the root certificate for the API server's serving certificate to the controller manager with the --root-ca-file argument allows the controller manager to inject the trusted bundle into pods so that they can verify TLS connections to the API server.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-controller-manager Verify that the --root-ca-file argument exists and is set to a certificate bundle file containing the root certificate for the API server's serving certificate.\nRemediation: Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube- controller-manager.yaml on the Control Plane node and set the --root-ca-file parameter to the certificate bundle file`. --root-ca-file=<path/to/file>",
    "metadata": {
      "id": "CIS-1.3.5",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "You need to setup and maintain root certificate authority file.",
      "default_value": "By default, --root-ca-file is not set.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/kubernetes/issues/11000"
      ]
    }
  },
  {
    "page_content": "Title: 1.3.6 Ensure that the RotateKubeletServerCertificate argument is set to true (Automated)\nDescription: Enable kubelet server certificate rotation on controller-manager.\nRationale: RotateKubeletServerCertificate causes the kubelet to both request a serving certificate after bootstrapping its client credentials and rotate the certificate as its existing credentials expire. This automated periodic rotation ensures that the there are no downtimes due to expired certificates and thus addressing availability in the CIA security triad. Note: This recommendation only applies if you let kubelets get their certificates from the API server. In case your kubelet certificates come from an outside authority/tool (e.g. Vault) then you need to take care of rotation yourself.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-controller-manager Verify that RotateKubeletServerCertificate argument exists and is set to true.\nRemediation: Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube- controller-manager.yaml on the Control Plane node and set the --feature-gates parameter to include RotateKubeletServerCertificate=true. --feature-gates=RotateKubeletServerCertificate=true",
    "metadata": {
      "id": "CIS-1.3.6",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, RotateKubeletServerCertificate is set to \"true\" this recommendation verifies that it has not been disabled.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/kubernetes/pull/45059",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.3.7 Ensure that the --bind-address argument is set to 127.0.0.1 (Automated)\nDescription: Do not bind the Controller Manager service to non-loopback insecure addresses.\nRationale: The Controller Manager API service which runs on port 10252/TCP by default is used for health and metrics information and is available without authentication or encryption. As such it should only be bound to a localhost interface, to minimize the cluster's attack surface\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-controller-manager Verify that the --bind-address argument is set to 127.0.0.1\nRemediation: Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube- controller-manager.yaml on the Control Plane node and ensure the correct value for the --bind-address parameter",
    "metadata": {
      "id": "CIS-1.3.7",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "None",
      "default_value": "By default, the --bind-address parameter is set to 0.0.0.0",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.4.1 Ensure that the --profiling argument is set to false (Automated)\nDescription: Disable profiling, if not needed.\nRationale: Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.\nAudit: Run the following command on the Control Plane node: ps -ef | grep kube-scheduler Verify that the --profiling argument is set to false.\nRemediation: Edit the Scheduler pod specification file /etc/kubernetes/manifests/kube- scheduler.yaml file on the Control Plane node and set the below parameter. --profiling=false",
    "metadata": {
      "id": "CIS-1.4.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "Profiling information would not be available.",
      "default_value": "By default, profiling is enabled.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 1.4.2 Ensure that the --bind-address argument is set to 127.0.0.1 (Automated)\nDescription: Use a different certificate authority for etcd from the one used for Kubernetes.\nRationale: etcd is a highly available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. Its access should be restricted to specifically designated clients and peers only. Authentication to etcd is based on whether the certificate presented was issued by a trusted certificate authority. There is no checking of certificate attributes such as common name or subject alternative name. As such, if any attackers were able to gain access to any certificate issued by the trusted certificate authority, they would be able to gain full access to the etcd database.\nAudit: Review the CA used by the etcd environment and ensure that it does not match the CA certificate file used for the management of the overall Kubernetes cluster. Run the following command on the master node: ps -ef | grep etcd Note the file referenced by the --trusted-ca-file argument. Run the following command on the master node: ps -ef | grep apiserver Verify that the file referenced by the --client-ca-file for apiserver is different from the --trusted-ca-file used by etcd.\nRemediation: Follow the etcd documentation and create a dedicated certificate authority setup for the etcd service. Internal Only - General Then, edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameter. --trusted-ca-file=</path/to/ca-file>",
    "metadata": {
      "id": "CIS-1.4.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration",
      "impact": "Additional management of the certificates and keys for the dedicated certificate authority will be required.",
      "default_value": "By default, no etcd certificate is created and used.",
      "references": [
        "https://coreos.com/etcd/docs/latest/op-guide/security.html"
      ]
    }
  },
  {
    "page_content": "Title: 3.1.1 Client certificate authentication should not be used for users (Manual)\nDescription: Kubernetes provides the option to use client certificates for user authentication. However as there is no way to revoke these certificates when a user leaves an organization or loses their credential, they are not suitable for this purpose. It is not possible to fully disable client certificate use within a cluster as it is used for component to component authentication.\nRationale: With any authentication mechanism the ability to revoke credentials if they are compromised or no longer required, is a key control. Kubernetes client certificate authentication does not allow for this due to a lack of support for certificate revocation.\nAudit: Review user access to the cluster and ensure that users are not making use of Kubernetes client certificate authentication.\nRemediation: Alternative mechanisms provided by Kubernetes such as the use of OIDC should be implemented in place of client certificates.",
    "metadata": {
      "id": "CIS-3.1.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "etcd Configuration",
      "impact": "External mechanisms for authentication generally require additional software to be deployed.",
      "default_value": "Client certificate authentication is enabled by default. Additional Information: The lack of certificate revocation was flagged up as a high risk issue in the recent Kubernetes security audit. Without this feature, client certificate authentication is not suitable for end users. Page 159 Internal Only - General"
    }
  },
  {
    "page_content": "Title: 3.1.2 Service account token authentication should not be used for users (Manual)\nDescription: Kubernetes provides service account tokens which are intended for use by workloads running in the Kubernetes cluster, for authentication to the API server. These tokens are not designed for use by end-users and do not provide for features such as revocation or expiry, making them insecure. A newer version of the feature (Bound service account token volumes) does introduce expiry but still does not allow for specific revocation.\nRationale: With any authentication mechanism the ability to revoke credentials if they are compromised or no longer required, is a key control. Service account token authentication does not allow for this due to the use of JWT tokens as an underlying technology.\nAudit: Review user access to the cluster and ensure that users are not making use of service account token authentication.\nRemediation: Alternative mechanisms provided by Kubernetes such as the use of OIDC should be implemented in place of service account tokens.",
    "metadata": {
      "id": "CIS-3.1.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "etcd Configuration",
      "impact": "External mechanisms for authentication generally require additional software to be deployed.",
      "default_value": "Service account token authentication is enabled by default. Page 161 Internal Only - General"
    }
  },
  {
    "page_content": "Title: 3.1.3 Bootstrap token authentication should not be used for users (Manual)\nDescription: Kubernetes provides bootstrap tokens which are intended for use by new nodes joining the cluster These tokens are not designed for use by end-users they are specifically designed for the purpose of bootstrapping new nodes and not for general authentication\nRationale: Bootstrap tokens are not intended for use as a general authentication mechanism and impose constraints on user and group naming that do not facilitate good RBAC design. They also cannot be used with MFA resulting in a weak authentication mechanism being available.\nAudit: Review user access to the cluster and ensure that users are not making use of bootstrap token authentication.\nRemediation: Alternative mechanisms provided by Kubernetes such as the use of OIDC should be implemented in place of bootstrap tokens.",
    "metadata": {
      "id": "CIS-3.1.3",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "etcd Configuration",
      "impact": "External mechanisms for authentication generally require additional software to be deployed.",
      "default_value": "Bootstrap token authentication is not enabled by default and requires an API server parameter to be set. Page 163 Internal Only - General"
    }
  },
  {
    "page_content": "Title: 3.2.1 Ensure that a minimal audit policy is created (Manual)\nDescription: Kubernetes can audit the details of requests made to the API server. The --audit- policy-file flag must be set for this logging to be enabled.\nRationale: Logging is an important detective control for all systems, to detect potential unauthorised access.\nAudit: Run the following command on one of the cluster master nodes: ps -ef | grep kube-apiserver Verify that the --audit-policy-file is set. Review the contents of the file specified and ensure that it contains a valid audit policy.\nRemediation: Create an audit policy file for your cluster.",
    "metadata": {
      "id": "CIS-3.2.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "etcd Configuration",
      "impact": "Audit logs will be created on the master nodes, which will consume disk space. Care should be taken to avoid generating too large volumes of log information as this could impact the available of the cluster nodes.",
      "default_value": "Unless the --audit-policy-file flag is specified, no auditing will be carried out.",
      "references": [
        "https://kubernetes.io/docs/tasks/debug-application-cluster/audit/"
      ]
    }
  },
  {
    "page_content": "Title: 3.2.2 Ensure that the audit policy covers key security concerns (Manual)\nDescription: Ensure that the audit policy created for the cluster covers key security concerns.\nRationale: Security audit logs should cover access and modification of key resources in the cluster, to enable them to form an effective part of a security environment.\nAudit: Review the audit policy provided for the cluster and ensure that it covers at least the following areas :- • Access to Secrets managed by the cluster. Care should be taken to only log Metadata for requests to Secrets, ConfigMaps, and TokenReviews, in order to avoid the risk of logging sensitive data. • Modification of pod and deployment objects. • Use of pods/exec, pods/portforward, pods/proxy and services/proxy. For most requests, minimally logging at the Metadata level is recommended (the most basic level of logging).\nRemediation: Consider modification of the audit policy in use on the cluster to include these items, at a minimum.",
    "metadata": {
      "id": "CIS-3.2.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "etcd Configuration",
      "impact": "Increasing audit logging will consume resources on the nodes or other log destination.",
      "default_value": "By default Kubernetes clusters do not log audit information.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/tasks/debug-application-cluster/audit/#audit-policy",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.1.1 Ensure that the kubelet service file permissions are set to 600 or more restrictive (Automated)\nDescription: Ensure that the kubelet service file has permissions of 600 or more restrictive.\nRationale: The kubelet service file controls various parameters that set the behavior of the kubelet service in the worker node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\nAudit: Automated AAC auditing has been modified to allow CIS-CAT to input a variable for the <PATH>/<FILENAME> of the kubelet service config file. Please set $kubelet_service_config=<PATH> based on the file location on your system for example: export kubelet_service_config=/etc/systemd/system/kubelet.service.d/kubeadm.conf To perform the audit manually: Run the below command (based on the file location on your system) on the each worker node. For example, stat -c %a /etc/systemd/system/kubelet.service.d/10-kubeadm.conf Verify that the permissions are 600 or more restrictive.\nRemediation: Run the below command (based on the file location on your system) on the each worker node. For example, chmod 600 /etc/systemd/system/kubelet.service.d/kubeadm.conf",
    "metadata": {
      "id": "CIS-4.1.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default, the kubelet service file has permissions of 640. Page 171 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#44-",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.1.2 Ensure that the kubelet service file ownership is set to root:root (Automated)\nDescription: Ensure that the kubelet service file ownership is set to root:root.\nRationale: The kubelet service file controls various parameters that set the behavior of the kubelet service in the worker node. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\nAudit: Automated AAC auditing has been modified to allow CIS-CAT to input a variable for the <PATH>/<FILENAME> of the kubelet service config file. Please set $kubelet_service_config=<PATH> based on the file location on your system for example: export kubelet_service_config=/etc/systemd/system/kubelet.service.d/kubeadm.conf To perform the audit manually: Run the below command (based on the file location on your system) on the each worker node. For example, stat -c %U:%G /etc/systemd/system/kubelet.service.d/10-kubeadm.conf Verify that the ownership is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the each worker node. For example, chown root:root /etc/systemd/system/kubelet.service.d/kubeadm.conf",
    "metadata": {
      "id": "CIS-4.1.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default, kubelet service file ownership is set to root:root. Page 173 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#44-",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.1.3 If proxy kubeconfig file exists ensure permissions are set to 600 or more restrictive (Manual)\nDescription: If kube-proxy is running, and if it is using a file-based kubeconfig file, ensure that the proxy kubeconfig file has permissions of 600 or more restrictive.\nRationale: The kube-proxy kubeconfig file controls various parameters of the kube-proxy service in the worker node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system. It is possible to run kube-proxy with the kubeconfig parameters configured as a Kubernetes ConfigMap instead of a file. In this case, there is no proxy kubeconfig file.\nAudit: Find the kubeconfig file being used by kube-proxy by running the following command: ps -ef | grep kube-proxy If kube-proxy is running, get the kubeconfig file location from the --kubeconfig parameter. To perform the audit: Run the below command (based on the file location on your system) on the each worker node. For example, stat -c %a <path><filename> Verify that a file is specified and it exists with permissions are 600 or more restrictive.\nRemediation: Run the below command (based on the file location on your system) on the each worker node. For example, chmod 600 <proxy kubeconfig file>",
    "metadata": {
      "id": "CIS-4.1.3",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default, proxy file has permissions of 640. Page 175 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.1.4 If proxy kubeconfig file exists ensure ownership is set to root:root (Manual)\nDescription: If kube-proxy is running, ensure that the file ownership of its kubeconfig file is set to root:root.\nRationale: The kubeconfig file for kube-proxy controls various parameters for the kube-proxy service in the worker node. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\nAudit: Find the kubeconfig file being used by kube-proxy by running the following command: ps -ef | grep kube-proxy If kube-proxy is running, get the kubeconfig file location from the --kubeconfig parameter. To perform the audit: Run the below command (based on the file location on your system) on the each worker node. For example, stat -c %U:%G <path><filename> Verify that the ownership is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the each worker node. For example, chown root:root <proxy kubeconfig file>",
    "metadata": {
      "id": "CIS-4.1.4",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default, proxy file ownership is set to root:root. Page 177 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.1.5 Ensure that the --kubeconfig kubelet.conf file permissions are set to 600 or more restrictive (Automated)\nDescription: Ensure that the kubelet.conf file has permissions of 600 or more restrictive.\nRationale: The kubelet.conf file is the kubeconfig file for the node, and controls various parameters that set the behavior and identity of the worker node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\nAudit: Automated AAC auditing has been modified to allow CIS-CAT to input a variable for the <PATH>/<FILENAME> of the kubelet config file. Please set $kubelet_config=<PATH> based on the file location on your system for example: export kubelet_config=/etc/kubernetes/kubelet.conf To perform the audit manually: Run the below command (based on the file location on your system) on the each worker node. For example, stat -c %a /etc/kubernetes/kubelet.conf Verify that the ownership is set to root:root.Verify that the permissions are 600 or more restrictive.\nRemediation: Run the below command (based on the file location on your system) on the each worker node. For example, chmod 600 /etc/kubernetes/kubelet.conf",
    "metadata": {
      "id": "CIS-4.1.5",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default, kubelet.conf file has permissions of 600. Page 179 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.1.6 Ensure that the --kubeconfig kubelet.conf file ownership is set to root:root (Automated)\nDescription: Ensure that the kubelet.conf file ownership is set to root:root.\nRationale: The kubelet.conf file is the kubeconfig file for the node, and controls various parameters that set the behavior and identity of the worker node. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\nAudit: Automated AAC auditing has been modified to allow CIS-CAT to input a variable for the <PATH>/<FILENAME> of the kubelet config file. Please set $kubelet_config=<PATH> based on the file location on your system for example: export kubelet_config=/etc/kubernetes/kubelet.conf To perform the audit manually: Run the below command (based on the file location on your system) on the each worker node. For example, stat -c %U:%G /etc/kubernetes/kubelet.conf Verify that the ownership is set to root:root.\nRemediation: Run the below command (based on the file location on your system) on the each worker node. For example, chown root:root /etc/kubernetes/kubelet.conf",
    "metadata": {
      "id": "CIS-4.1.6",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default, kubelet.conf file ownership is set to root:root.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.1.7 Ensure that the certificate authorities file permissions are set to 644 or more restrictive (Manual)\nDescription: Ensure that the certificate authorities file has permissions of 644 or more restrictive.\nRationale: The certificate authorities file controls the authorities used to validate API requests. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\nAudit: Run the following command: ps -ef | grep kubelet Find the file specified by the --client-ca-file argument. Run the following command: stat -c %a <filename> Verify that the permissions are 644 or more restrictive.\nRemediation: Run the following command to modify the file permissions of the --client-ca-file chmod 644 <filename>",
    "metadata": {
      "id": "CIS-4.1.7",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default no --client-ca-file is specified.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.1.8 Ensure that the client certificate authorities file ownership is set to root:root (Manual)\nDescription: Ensure that the certificate authorities file ownership is set to root:root.\nRationale: The certificate authorities file controls the authorities used to validate API requests. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\nAudit: Run the following command: ps -ef | grep kubelet Find the file specified by the --client-ca-file argument. Run the following command: stat -c %U:%G <filename> Verify that the ownership is set to root:root.\nRemediation: Run the following command to modify the ownership of the --client-ca-file. chown root:root <filename>",
    "metadata": {
      "id": "CIS-4.1.8",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default no --client-ca-file is specified.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.1.9 If the kubelet config.yaml configuration file is being used validate permissions set to 600 or more restrictive (Automated)\nDescription: Ensure that if the kubelet refers to a configuration file with the --config argument, that file has permissions of 600 or more restrictive.\nRationale: The kubelet reads various parameters, including security settings, from a config file specified by the --config argument. If this file is specified you should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\nAudit: Automated AAC auditing has been modified to allow CIS-CAT to input a variable for the <PATH>/<FILENAME> of the kubelet config yaml file. Please set $kubelet_config_yaml=<PATH> based on the file location on your system for example: export kubelet_config_yaml=/var/lib/kubelet/config.yaml To perform the audit manually: Run the below command (based on the file location on your system) on the each worker node. For example, stat -c %a /var/lib/kubelet/config.yaml Verify that the permissions are 600 or more restrictive.\nRemediation: Run the following command (using the config file location identified in the Audit step) chmod 600 /var/lib/kubelet/config.yaml",
    "metadata": {
      "id": "CIS-4.1.9",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default, the /var/lib/kubelet/config.yaml file as set up by kubeadm has permissions of 600. Page 187 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/"
      ]
    }
  },
  {
    "page_content": "Title: 4.1.10 If the kubelet config.yaml configuration file is being used validate file ownership is set to root:root (Automated)\nDescription: Ensure that if the kubelet refers to a configuration file with the --config argument, that file is owned by root:root.\nRationale: The kubelet reads various parameters, including security settings, from a config file specified by the --config argument. If this file is specified you should restrict its file permissions to maintain the integrity of the file. The file should be owned by root:root.\nAudit: Automated AAC auditing has been modified to allow CIS-CAT to input a variable for the <PATH>/<FILENAME> of the kubelet config yaml file. Please set $kubelet_config_yaml=<PATH> based on the file location on your system for example: export kubelet_config_yaml=/var/lib/kubelet/config.yaml To perform the audit manually: Run the below command (based on the file location on your system) on the each worker node. For example, stat -c %U:%G /var/lib/kubelet/config.yaml ```Verify that the ownership is set to `root:root`.\nRemediation: Run the following command (using the config file location identied in the Audit step) chown root:root /etc/kubernetes/kubelet.conf",
    "metadata": {
      "id": "CIS-4.1.10",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default, /var/lib/kubelet/config.yaml file as set up by kubeadm is owned by root:root. Page 189 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.1 Ensure that the --anonymous-auth argument is set to false (Automated)\nDescription: Disable anonymous requests to the Kubelet server.\nRationale: When enabled, requests that are not rejected by other configured authentication methods are treated as anonymous requests. These requests are then served by the Kubelet server. You should rely on authentication to authorize access and disallow anonymous requests.\nAudit: If using a Kubelet configuration file, check that there is an entry for authentication: anonymous: enabled set to false. Run the following command on each node: ps -ef | grep kubelet Verify that the --anonymous-auth argument is set to false. This executable argument may be omitted, provided there is a corresponding entry set to false in the Kubelet config file.\nRemediation: If using a Kubelet config file, edit the file to set authentication: anonymous: enabled to false. If using executable arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. --anonymous-auth=false Based on your system, restart the kubelet service. For example: Internal Only - General systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "Anonymous requests will be rejected.",
      "default_value": "By default, anonymous access is enabled.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.2 Ensure that the --authorization-mode argument is not set to AlwaysAllow (Automated)\nDescription: Do not allow all requests. Enable explicit authorization.\nRationale: Kubelets, by default, allow all authenticated requests (even anonymous ones) without needing explicit authorization checks from the apiserver. You should restrict this behavior and only allow explicitly authorized requests.\nAudit: Run the following command on each node: ps -ef | grep kubelet If the --authorization-mode argument is present check that it is not set to AlwaysAllow. If it is not present check that there is a Kubelet config file specified by -- config, and that file sets authorization: mode to something other than AlwaysAllow. It is also possible to review the running configuration of a Kubelet via the /configz endpoint on the Kubelet API port (typically 10250/TCP). Accessing these with appropriate credentials will provide details of the Kubelet's configuration.\nRemediation: If using a Kubelet config file, edit the file to set authorization: mode to Webhook. If using executable arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker node and set the below parameter in KUBELET_AUTHZ_ARGS variable. --authorization-mode=Webhook Based on your system, restart the kubelet service. For example: Internal Only - General systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "Unauthorized requests will be denied.",
      "default_value": "By default, --authorization-mode argument is set to AlwaysAllow.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.3 Ensure that the --client-ca-file argument is set as appropriate (Automated)\nDescription: Enable Kubelet authentication using certificates.\nRationale: The connections from the apiserver to the kubelet are used for fetching logs for pods, attaching (through kubectl) to running pods, and using the kubelet’s port-forwarding functionality. These connections terminate at the kubelet’s HTTPS endpoint. By default, the apiserver does not verify the kubelet’s serving certificate, which makes the connection subject to man-in-the-middle attacks, and unsafe to run over untrusted and/or public networks. Enabling Kubelet certificate authentication ensures that the apiserver could authenticate the Kubelet before submitting any requests.\nAudit: Run the following command on each node: ps -ef | grep kubelet Verify that the --client-ca-file argument exists and is set to the location of the client certificate authority file. If the --client-ca-file argument is not present, check that there is a Kubelet config file specified by --config, and that the file sets authentication: x509: clientCAFile to the location of the client certificate authority file.\nRemediation: If using a Kubelet config file, edit the file to set authentication: x509: clientCAFile to the location of the client CA file. If using command line arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker node and set the below parameter in KUBELET_AUTHZ_ARGS variable. --client-ca-file=<path/to/client-ca-file> Based on your system, restart the kubelet service. For example: Internal Only - General systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.3",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "You require TLS to be configured on apiserver as well as kubelets.",
      "default_value": "By default, --client-ca-file argument is not set.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.4 Verify that if defined, readOnlyPort is set to 0 (Manual)\nDescription: Disable the read-only port.\nRationale: The Kubelet process provides a read-only API in addition to the main Kubelet API. Unauthenticated access is provided to this read-only API which could possibly retrieve potentially sensitive information about the cluster.\nAudit: Run the following command on each node: ps -ef | grep kubelet Verify that the --read-only-port argument exists and is set to 0. If the --read-only-port argument is not present, check that there is a Kubelet config file specified by --config. Check that if there is a readOnlyPort entry in the file, it is set to 0.\nRemediation: If using a Kubelet config file, edit the file to set readOnlyPort to 0. If using command line arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. --read-only-port=0 Based on your system, restart the kubelet service. For example: systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.4",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "Removal of the read-only port will require that any service which made use of it will need to be re-configured to use the main Kubelet API.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/kubernetes/blob/6cedc0853faa118df0ba3d41b48b",
        "https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.5 Ensure that the --streaming-connection-idle-timeout argument is not set to 0 (Manual)\nDescription: Do not disable timeouts on streaming connections.\nRationale: Setting idle timeouts ensures that you are protected against Denial-of-Service attacks, inactive connections and running out of ephemeral ports. Note: By default, --streaming-connection-idle-timeout is set to 4 hours which might be too high for your environment. Setting this as appropriate would additionally ensure that such streaming connections are timed out after serving legitimate use cases.\nAudit: Run the following command on each node: ps -ef | grep kubelet Verify that the --streaming-connection-idle-timeout argument is not set to 0. If the argument is not present, and there is a Kubelet config file specified by --config, check that it does not set streamingConnectionIdleTimeout to 0.\nRemediation: If using a Kubelet config file, edit the file to set streamingConnectionIdleTimeout to a value other than 0. If using command line arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. --streaming-connection-idle-timeout=5m Based on your system, restart the kubelet service. For example: Internal Only - General systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.5",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "Long-lived connections could be interrupted.",
      "default_value": "By default, --streaming-connection-idle-timeout is set to 4 hours.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/kubernetes/pull/18552"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.6 Ensure that the --make-iptables-util-chains argument is set to true (Automated)\nDescription: Allow Kubelet to manage iptables.\nRationale: Kubelets can automatically manage the required changes to iptables based on how you choose your networking options for the pods. It is recommended to let kubelets manage the changes to iptables. This ensures that the iptables configuration remains in sync with pods networking configuration. Manually configuring iptables with dynamic pod network configuration changes might hamper the communication between pods/containers and to the outside world. You might have iptables rules too restrictive or too open.\nAudit: Run the following command on each node: ps -ef | grep kubelet Verify that if the --make-iptables-util-chains argument exists then it is set to true. If the --make-iptables-util-chains argument does not exist, and there is a Kubelet config file specified by --config, verify that the file does not set makeIPTablesUtilChains to false.\nRemediation: If using a Kubelet config file, edit the file to set makeIPTablesUtilChains: true. If using command line arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker node and remove the --make- iptables-util-chains argument from the KUBELET_SYSTEM_PODS_ARGS variable. Based on your system, restart the kubelet service. For example: Internal Only - General systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.6",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "Kubelet would manage the iptables on the system and keep it in sync. If you are using any other iptables management solution, then there might be some conflicts.",
      "default_value": "By default, --make-iptables-util-chains argument is set to true.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.7 Ensure that the --hostname-override argument is not set (Manual)\nDescription: Do not override node hostnames.\nRationale: Overriding hostnames could potentially break TLS setup between the kubelet and the apiserver. Additionally, with overridden hostnames, it becomes increasingly difficult to associate logs with a particular node and process them for security analytics. Hence, you should setup your kubelet nodes with resolvable FQDNs and avoid overriding the hostnames with IPs.\nAudit: Run the following command on each node: ps -ef | grep kubelet Verify that --hostname-override argument does not exist. Note This setting is not configurable via the Kubelet config file.\nRemediation: Edit the kubelet service file /etc/systemd/system/kubelet.service.d/10- kubeadm.conf on each worker node and remove the --hostname-override argument from the KUBELET_SYSTEM_PODS_ARGS variable. Based on your system, restart the kubelet service. For example: systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.7",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "Some cloud providers may require this flag to ensure that hostname matches names issued by the cloud provider. In these environments, this recommendation should not apply.",
      "default_value": "By default, --hostname-override argument is not set. Page 204 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/kubernetes/issues/22063"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.8 Ensure that the eventRecordQPS argument is set to a level which ensures appropriate event capture (Manual)\nDescription: Security relevant information should be captured. The eventRecordQPS on the Kubelet configuration can be used to limit the rate at which events are gathered and sets the maximum event creations per second. Setting this too low could result in relevant events not being logged, however the unlimited setting of 0 could result in a denial of service on the kubelet.\nRationale: It is important to capture all events and not restrict event creation. Events are an important source of security information and analytics that ensure that your environment is consistently monitored using the event data.\nAudit: Run the following command on each node: sudo grep \"eventRecordQPS\" /etc/systemd/system/kubelet.service.d/10- kubeadm.conf or If using command line arguments, kubelet service file is located /etc/systemd/system/kubelet.service.d/10-kubelet-args.conf sudo grep \"eventRecordQPS\" /etc/systemd/system/kubelet.service.d/10-kubelet- args.conf Review the value set for the argument and determine whether this has been set to an appropriate level for the cluster. If the argument does not exist, check that there is a Kubelet config file specified by -- config and review the value in this location. If using command line arguments\nRemediation: If using a Kubelet config file, edit the file to set eventRecordQPS: to an appropriate level. Internal Only - General If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_ARGS variable. Based on your system, restart the kubelet service. For example: systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.8",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "Setting this parameter to 0 could result in a denial of service condition due to excessive events being created. The cluster's event processing and storage systems should be scaled to handle expected event loads.",
      "default_value": "By default, eventRecordQPS argument is set to 5.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.9 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Manual)\nDescription: Setup TLS connection on the Kubelets.\nRationale: The connections from the apiserver to the kubelet are used for fetching logs for pods, attaching (through kubectl) to running pods, and using the kubelet’s port-forwarding functionality. These connections terminate at the kubelet’s HTTPS endpoint. By default, the apiserver does not verify the kubelet’s serving certificate, which makes the connection subject to man-in-the-middle attacks, and unsafe to run over untrusted and/or public networks.\nAudit: Run the following command on each node: ps -ef | grep kubelet Verify that the --tls-cert-file and --tls-private-key-file arguments exist and they are set as appropriate. If these arguments are not present, check that there is a Kubelet config specified by -- config and that it contains appropriate settings for tlsCertFile and tlsPrivateKeyFile.\nRemediation: If using a Kubelet config file, edit the file to set tlsCertFile to the location of the certificate file to use to identify this Kubelet, and tlsPrivateKeyFile to the location of the corresponding private key file. If using command line arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker node and set the below parameters in KUBELET_CERTIFICATE_ARGS variable. --tls-cert-file=<path/to/tls-certificate-file> --tls-private-key-file=<path/to/tls-key-file> Based on your system, restart the kubelet service. For example: Internal Only - General systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.9",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration"
    }
  },
  {
    "page_content": "Title: 4.2.10 Ensure that the --rotate-certificates argument is not set to false (Automated)\nDescription: Enable kubelet client certificate rotation.\nRationale: The --rotate-certificates setting causes the kubelet to rotate its client certificates by creating new CSRs as its existing credentials expire. This automated periodic rotation ensures that the there is no downtime due to expired certificates and thus addressing availability in the CIA security triad. Note: This recommendation only applies if you let kubelets get their certificates from the API server. In case your kubelet certificates come from an outside authority/tool (e.g. Vault) then you need to take care of rotation yourself. Note: This feature also require the RotateKubeletClientCertificate feature gate to be enabled (which is the default since Kubernetes v1.7)\nAudit: Run the following command on each node: ps -ef | grep kubelet Verify that the RotateKubeletServerCertificate argument is not present, or is set to true. If the RotateKubeletServerCertificate argument is not present, verify that if there is a Kubelet config file specified by --config, that file does not contain RotateKubeletServerCertificate: false.\nRemediation: If using a Kubelet config file, edit the file to add the line rotateCertificates: true or remove it altogether to use the default value. If using command line arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker node and remove --rotate- certificates=false argument from the KUBELET_CERTIFICATE_ARGS variable or set - -rotate-certificates=true . Internal Only - General Based on your system, restart the kubelet service. For example: systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.10",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default, kubelet client certificate rotation is enabled.",
      "references": [
        "https://github.com/kubernetes/kubernetes/pull/41912",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.11 Verify that the RotateKubeletServerCertificate argument is set to true (Manual)\nDescription: Enable kubelet server certificate rotation.\nRationale: RotateKubeletServerCertificate causes the kubelet to both request a serving certificate after bootstrapping its client credentials and rotate the certificate as its existing credentials expire. This automated periodic rotation ensures that the there are no downtimes due to expired certificates and thus addressing availability in the CIA security triad. Note: This recommendation only applies if you let kubelets get their certificates from the API server. In case your kubelet certificates come from an outside authority/tool (e.g. Vault) then you need to take care of rotation yourself.\nAudit: Ignore this check if serverTLSBootstrap is true in the kubelet config file or if the --rotate- server-certificates parameter is set on kubelet Run the following command on each node: ps -ef | grep kubelet Verify that RotateKubeletServerCertificate argument exists and is set to true.\nRemediation: Edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker node and set the below parameter in KUBELET_CERTIFICATE_ARGS variable. --feature-gates=RotateKubeletServerCertificate=true Based on your system, restart the kubelet service. For example: systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.11",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "None",
      "default_value": "By default, kubelet server certificate rotation is enabled. Page 212 Internal Only - General",
      "references": [
        "https://github.com/kubernetes/kubernetes/pull/45059",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.12 Ensure that the Kubelet only makes use of Strong Cryptographic Ciphers (Manual)\nDescription: Ensure that the Kubelet is configured to only use strong cryptographic ciphers.\nRationale: TLS ciphers have had a number of known vulnerabilities and weaknesses, which can reduce the protection provided by them. By default Kubernetes supports a number of TLS ciphersuites including some that have security concerns, weakening the protection provided.\nAudit: The set of cryptographic ciphers currently considered secure is the following: • TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 • TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 • TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305 • TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 • TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 • TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 Run the following command on each node: ps -ef | grep kubelet If the --tls-cipher-suites argument is present, ensure it only contains values included in this set. If it is not present check that there is a Kubelet config file specified by --config, and that file sets tlsCipherSuites: to only include values from this set. Page 214 Internal Only - General\nRemediation: If using a Kubelet config file, edit the file to set tlsCipherSuites: to TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM _SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_ 256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WI TH_AES_256_GCM_SHA384 or to a subset of these values. If using executable arguments, edit the kubelet service file /etc/kubernetes/kubelet.conf on each worker node and set the --tls-cipher- suites parameter as follows, or to a subset of these values. --tls-cipher- suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM _SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM _SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM _SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256 Based on your system, restart the kubelet service. For example: systemctl daemon-reload systemctl restart kubelet.service",
    "metadata": {
      "id": "CIS-4.2.12",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "Kubelet clients that cannot support modern cryptographic ciphers will not be able to make connections to the Kubelet API.",
      "default_value": "By default the Kubernetes API server supports a wide range of TLS ciphers Additional Information: The list chosen above should be fine for modern clients. It's essentially the list from the Mozilla \"Modern cipher\" option with the ciphersuites supporting CBC mode removed, as CBC has traditionally had a lot of issues"
    }
  },
  {
    "page_content": "Title: 4.2.13 Ensure that a limit is set on pod PIDs (Manual)\nDescription: Ensure that the Kubelet sets limits on the number of PIDs that can be created by pods running on the node.\nRationale: By default pods running in a cluster can consume any number of PIDs, potentially exhausting the resources available on the node. Setting an appropriate limit reduces the risk of a denial of service attack on cluster nodes.\nAudit: Review the Kubelet's start-up parameters for the value of --pod-max-pids, and check the Kubelet configuration file for the PodPidsLimit . If neither of these values is set, then there is no limit in place.\nRemediation: Decide on an appropriate level for this parameter and set it, either via the --pod-max- pids command line parameter or the PodPidsLimit configuration file setting.",
    "metadata": {
      "id": "CIS-4.2.13",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "Setting this value will restrict the number of processes per pod. If this limit is lower than the number of PIDs required by a pod it will not operate.",
      "default_value": "By default the number of PIDs is not limited.",
      "references": [
        "https://kubernetes.io/docs/concepts/policy/pid-limiting/#pod-pid-limits"
      ]
    }
  },
  {
    "page_content": "Title: 4.2.14 Ensure that the --seccomp-default parameter is set to true (Manual)\nDescription: Ensure that the Kubelet enforces the use of the RuntimeDefault seccomp profile\nRationale: By default, Kubernetes disables the seccomp profile which ships with most container runtimes. Setting this parameter will ensure workloads running on the node are protected by the runtime's seccomp profile.\nAudit: Review the Kubelet's start-up parameters for the value of --seccomp-default, and check the Kubelet configuration file for the seccompDefault . If neither of these values is set, then the seccomp profile is not in use.\nRemediation: Set the parameter, either via the --seccomp-default command line parameter or the seccompDefault configuration file setting.",
    "metadata": {
      "id": "CIS-4.2.14",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "Setting this will remove some rights from pods running on the node.",
      "default_value": "By default the seccomp profile is not enabled.",
      "references": [
        "https://kubernetes.io/docs/tutorials/security/seccomp/#enable-the-use-of-"
      ]
    }
  },
  {
    "page_content": "Title: 4.3.1 Ensure that the kube-proxy metrics service is bound to localhost (Manual)\nDescription: Do not bind the kube-proxy metrics port to non-loopback addresses.\nRationale: kube-proxy has two APIs which provided access to information about the service and can be bound to network ports. The metrics API service includes endpoints (/metrics and /configz) which disclose information about the configuration and operation of kube-proxy. These endpoints should not be exposed to untrusted networks as they do not support encryption or authentication to restrict access to the data they provide.\nAudit: review the start-up flags provided to kube proxy Run the following command on each node: ps -ef | grep -i kube-proxy Ensure that the --metrics-bind-address parameter is not set to a value other than 127.0.0.1. From the output of this command gather the location specified in the -- config parameter. Review any file stored at that location and ensure that it does not specify a value other than 127.0.0.1 for metricsBindAddress.\nRemediation: Modify or remove any values which bind the metrics service to a non-localhost address",
    "metadata": {
      "id": "CIS-4.3.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Worker Node Security",
      "category_l2": "Kubelet Configuration",
      "impact": "3rd party services which try to access metrics or configuration information related to kube-proxy will require access to the localhost interface of the node.",
      "default_value": "The default value is 127.0.0.1:10249",
      "references": [
        "https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/"
      ]
    }
  },
  {
    "page_content": "Title: 5.1.1 Ensure that the cluster-admin role is only used where required (Manual)\nDescription: The RBAC role cluster-admin provides wide-ranging powers over the environment and should be used only where and when needed.\nRationale: Kubernetes provides a set of default roles where RBAC is used. Some of these roles such as cluster-admin provide wide-ranging privileges which should only be applied where absolutely necessary. Roles such as cluster-admin allow super-user access to perform any action on any resource. When used in a ClusterRoleBinding, it gives full control over every resource in the cluster and in all namespaces. When used in a RoleBinding, it gives full control over every resource in the rolebinding's namespace, including the namespace itself.\nAudit: Obtain a list of the principals who have access to the cluster-admin role by reviewing the clusterrolebinding output for each role binding that has access to the cluster- admin role. kubectl get clusterrolebindings -o=custom- columns=NAME:.metadata.name,ROLE:.roleRef.name,SUBJECT:.subjects[*].name Review each principal listed and ensure that cluster-admin privilege is required for it.\nRemediation: Identify all clusterrolebindings to the cluster-admin role. Check if they are used and if they need this role or if they could use a role with fewer privileges. Where possible, first bind users to a lower privileged role and then remove the clusterrolebinding to the cluster-admin role : Internal Only - General kubectl delete clusterrolebinding [name]",
    "metadata": {
      "id": "CIS-5.1.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Care should be taken before removing any clusterrolebindings from the environment to ensure they were not required for operation of the cluster. Specifically, modifications should not be made to clusterrolebindings with the system: prefix as they are required for the operation of system components.",
      "default_value": "By default a single clusterrolebinding called cluster-admin is provided with the system:masters group as its principal.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 5.1.2 Minimize access to secrets (Manual)\nDescription: The Kubernetes API stores secrets, which may be service account tokens for the Kubernetes API or credentials used by workloads in the cluster. Access to these secrets should be restricted to the smallest possible group of users to reduce the risk of privilege escalation.\nRationale: Inappropriate access to secrets stored within the Kubernetes cluster can allow for an attacker to gain additional access to the Kubernetes cluster or external resources whose credentials are stored as secrets.\nAudit: Review the users who have get, list, or watch access to secrets objects in the Kubernetes API.\nRemediation: Where possible, restrict access to secret objects in the cluster by removing get, list, and watch permissions.",
    "metadata": {
      "id": "CIS-5.1.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Care should be taken not to remove access to secrets to system components which require this for their operation",
      "default_value": "By default in a kubeadm cluster the following list of principals have get privileges on secret objects Page 226 Internal Only - General CLUSTERROLEBINDING SUBJECT TYPE SA-NAMESPACE cluster-admin system:masters Group system:controller:clusterrole-aggregation-controller clusterrole- aggregation-controller ServiceAccount kube-system system:controller:expand-controller expand-controller ServiceAccount kube-system system:controller:generic-garbage-collector generic-garbage- collector ServiceAccount kube-system system:controller:namespace-controller namespace-controller ServiceAccount kube-system system:controller:persistent-volume-binder persistent-volume- binder ServiceAccount kube-system system:kube-controller-manager system:kube-controller- manager User"
    }
  },
  {
    "page_content": "Title: 5.1.3 Minimize wildcard use in Roles and ClusterRoles (Manual)\nDescription: Kubernetes Roles and ClusterRoles provide access to resources based on sets of objects and actions that can be taken on those objects. It is possible to set either of these to be the wildcard \"*\" which matches all items. Use of wildcards is not optimal from a security perspective as it may allow for inadvertent access to be granted when new resources are added to the Kubernetes API either as CRDs or in later versions of the product.\nRationale: The principle of least privilege recommends that users are provided only the access required for their role and nothing more. The use of wildcard rights grants is likely to provide excessive rights to the Kubernetes API.\nAudit: Retrieve the roles defined across each namespaces in the cluster and review for wildcards kubectl get roles --all-namespaces -o yaml Retrieve the cluster roles defined in the cluster and review for wildcards kubectl get clusterroles -o yaml\nRemediation: Where possible replace any use of wildcards in ClusterRoles and Roles with specific objects or actions.",
    "metadata": {
      "id": "CIS-5.1.3",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management"
    }
  },
  {
    "page_content": "Title: 5.1.4 Minimize access to create pods (Manual)\nDescription: The ability to create pods in a namespace can provide a number of opportunities for privilege escalation, such as assigning privileged service accounts to these pods or mounting hostPaths with access to sensitive data (unless Pod Security Policies are implemented to restrict this access) As such, access to create new pods should be restricted to the smallest possible group of users.\nRationale: The ability to create pods in a cluster opens up possibilities for privilege escalation and should be restricted, where possible.\nAudit: Review the users who have create access to pod objects in the Kubernetes API.\nRemediation: Where possible, remove create access to pod objects in the cluster.",
    "metadata": {
      "id": "CIS-5.1.4",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Care should be taken not to remove access to pods to system components which require this for their operation",
      "default_value": "By default in a kubeadm cluster the following list of principals have create privileges on pod objects Page 230 Internal Only - General CLUSTERROLEBINDING SUBJECT TYPE SA-NAMESPACE cluster-admin system:masters Group system:controller:clusterrole-aggregation-controller clusterrole- aggregation-controller ServiceAccount kube-system system:controller:daemon-set-controller daemon-set-controller ServiceAccount kube-system system:controller:job-controller job-controller ServiceAccount kube-system system:controller:persistent-volume-binder persistent-volume- binder ServiceAccount kube-system system:controller:replicaset-controller replicaset-controller ServiceAccount kube-system system:controller:replication-controller replication-controller ServiceAccount kube-system system:controller:statefulset-controller statefulset-controller ServiceAccount kube-system"
    }
  },
  {
    "page_content": "Title: 5.1.5 Ensure that default service accounts are not actively used. (Manual)\nDescription: The default service account should not be used to ensure that rights granted to applications can be more easily audited and reviewed.\nRationale: Kubernetes provides a default service account which is used by cluster workloads where no specific service account is assigned to the pod. Where access to the Kubernetes API from a pod is required, a specific service account should be created for that pod, and rights granted to that service account. The default service account should be configured to ensure that it does not automatically provide a service account token, and it must not have any non-default role bindings or custom role assignments\nAudit: For each namespace in the cluster, review the rights assigned to the default service account and ensure that it has no roles or cluster roles bound to it apart from the defaults. Additionally ensure that the automountServiceAccountToken: false setting is in place for each default service account.\nRemediation: Create explicit service accounts wherever a Kubernetes workload requires specific access to the Kubernetes API server. Modify the configuration of each default service account to include this value automountServiceAccountToken: false",
    "metadata": {
      "id": "CIS-5.1.5",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "All workloads which require access to the Kubernetes API will require an explicit service account to be created.",
      "default_value": "By default the default service account allows for its service account token to be mounted in pods in its namespace. Page 232 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 5.1.6 Ensure that Service Account Tokens are only mounted where necessary (Manual)\nDescription: Service accounts tokens should not be mounted in pods except where the workload running in the pod explicitly needs to communicate with the API server\nRationale: Mounting service account tokens inside pods can provide an avenue for privilege escalation attacks where an attacker is able to compromise a single pod in the cluster. Avoiding mounting these tokens removes this attack avenue.\nAudit: Review pod and service account objects in the cluster and ensure that the option below is set, unless the resource explicitly requires this access. automountServiceAccountToken: false\nRemediation: Modify the definition of pods and service accounts which do not need to mount service account tokens to disable it.",
    "metadata": {
      "id": "CIS-5.1.6",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods mounted without service account tokens will not be able to communicate with the API server, except where the resource is available to unauthenticated principals.",
      "default_value": "By default, all pods get a service account token mounted in them.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 5.1.7 Avoid use of system:masters group (Manual)\nDescription: The special group system:masters should not be used to grant permissions to any user or service account, except where strictly necessary (e.g. bootstrapping access prior to RBAC being fully available)\nRationale: The system:masters group has unrestricted access to the Kubernetes API hard-coded into the API server source code. An authenticated user who is a member of this group cannot have their access reduced, even if all bindings and cluster role bindings which mention it, are removed. When combined with client certificate authentication, use of this group can allow for irrevocable cluster-admin level credentials to exist for a cluster.\nAudit: Review a list of all credentials which have access to the cluster and ensure that the group system:masters is not used.\nRemediation: Remove the system:masters group from all users in the cluster.",
    "metadata": {
      "id": "CIS-5.1.7",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Once the RBAC system is operational in a cluster system:masters should not be specifically required, as ordinary bindings from principals to the cluster-admin cluster role can be made where unrestricted access is required.",
      "default_value": "By default some clusters will create a \"break glass\" client certificate which is a member of this group. Access to this client certificate should be carefully controlled and it should not be used for general cluster operations.",
      "references": [
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 5.1.8 Limit use of the Bind, Impersonate and Escalate permissions in the Kubernetes cluster (Manual)\nDescription: Cluster roles and roles with the impersonate, bind or escalate permissions should not be granted unless strictly required. Each of these permissions allow a particular subject to escalate their privileges beyond those explicitly granted by cluster administrators\nRationale: The impersonate privilege allows a subject to impersonate other users gaining their rights to the cluster. The bind privilege allows the subject to add a binding to a cluster role or role which escalates their effective permissions in the cluster. The escalate privilege allows a subject to modify cluster roles to which they are bound, increasing their rights to that level. Each of these permissions has the potential to allow for privilege escalation to cluster- admin level.\nAudit: Review the users who have access to cluster roles or roles which provide the impersonate, bind, or escalate privileges.\nRemediation: Where possible, remove the impersonate, bind, and escalate rights from subjects.",
    "metadata": {
      "id": "CIS-5.1.8",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "There are some cases where these permissions are required for cluster service operation, and care should be taken before removing these permissions from system service accounts.",
      "default_value": "In a default kubeadm cluster, the system:masters group and clusterrole-aggregation- controller service account have access to the escalate privilege. The system:masters group also has access to bind and impersonate.",
      "references": [
        "https://raesene.github.io/blog/2020/12/12/Escalating_Away/",
        "https://raesene.github.io/blog/2021/01/16/Getting-Into-A-Bind-with-Kubernetes/"
      ]
    }
  },
  {
    "page_content": "Title: 5.1.9 Minimize access to create persistent volumes (Manual)\nDescription: The ability to create persistent volumes in a cluster can provide an opportunity for privilege escalation, via the creation of hostPath volumes. As persistent volumes are not covered by Pod Security Admission, a user with access to create persistent volumes may be able to get access to sensitive files from the underlying host even where restrictive Pod Security Admission policies are in place.\nRationale: The ability to create persistent volumes in a cluster opens up possibilities for privilege escalation and should be restricted, where possible.\nAudit: Review the users who have create access to PersistentVolume objects in the Kubernetes API.\nRemediation: Where possible, remove create access to PersistentVolume objects in the cluster.",
    "metadata": {
      "id": "CIS-5.1.9",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "references": [
        "https://kubernetes.io/docs/concepts/security/rbac-good-practices/#persistent-"
      ]
    }
  },
  {
    "page_content": "Title: 5.1.10 Minimize access to the proxy sub-resource of nodes (Manual)\nDescription: Users with access to the Proxy sub-resource of Node objects automatically have permissions to use the kubelet API, which may allow for privilege escalation or bypass cluster security controls such as audit logs. The kubelet provides an API which includes rights to execute commands in any container running on the node. Access to this API is covered by permissions to the main Kubernetes API via the node object. The proxy sub-resource specifically allows wide ranging access to the kubelet API. Direct access to the kubelet API bypasses controls like audit logging (there is no audit log of kubelet API access) and admission control.\nRationale: The ability to use the proxy sub-resource of node objects opens up possibilities for privilege escalation and should be restricted, where possible.\nAudit: Review the users who have access to the proxy sub-resource of node objects in the Kubernetes API.\nRemediation: Where possible, remove access to the proxy sub-resource of node objects.",
    "metadata": {
      "id": "CIS-5.1.10",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "references": [
        "https://kubernetes.io/docs/concepts/security/rbac-good-practices/#access-to-",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 5.1.11 Minimize access to the approval sub-resource of certificatesigningrequests objects (Manual)\nDescription: Users with access to the update the approval sub-resource of CertificateSigningRequests objects can approve new client certificates for the Kubernetes API effectively allowing them to create new high-privileged user accounts. This can allow for privilege escalation to full cluster administrator, depending on users configured in the cluster\nRationale: The ability to update certificate signing requests should be limited.\nAudit: Review the users who have access to update the approval sub-resource of CertificateSigningRequests objects in the Kubernetes API.\nRemediation: Where possible, remove access to the approval sub-resource of CertificateSigningRequests objects.",
    "metadata": {
      "id": "CIS-5.1.11",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "references": [
        "https://kubernetes.io/docs/concepts/security/rbac-good-practices/#csrs-and-"
      ]
    }
  },
  {
    "page_content": "Title: 5.1.12 Minimize access to webhook configuration objects (Manual)\nDescription: Users with rights to create/modify/delete validatingwebhookconfigurations or mutatingwebhookconfigurations can control webhooks that can read any object admitted to the cluster, and in the case of mutating webhooks, also mutate admitted objects. This could allow for privilege escalation or disruption of the operation of the cluster.\nRationale: The ability to manage webhook configuration should be limited\nAudit: Review the users who have access to validatingwebhookconfigurations or mutatingwebhookconfigurations objects in the Kubernetes API.\nRemediation: Where possible, remove access to the validatingwebhookconfigurations or mutatingwebhookconfigurations objects",
    "metadata": {
      "id": "CIS-5.1.12",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "references": [
        "https://kubernetes.io/docs/concepts/security/rbac-good-practices/#control-"
      ]
    }
  },
  {
    "page_content": "Title: 5.1.13 Minimize access to the service account token creation (Manual)\nDescription: Users with rights to create new service account tokens at a cluster level, can create long-lived privileged credentials in the cluster. This could allow for privilege escalation and persistent access to the cluster, even if the users account has been revoked.\nRationale: The ability to create service account tokens should be limited.\nAudit: Review the users who have access to create the token sub-resource of serviceaccount objects in the Kubernetes API.\nRemediation: Where possible, remove access to the token sub-resource of serviceaccount objects.",
    "metadata": {
      "id": "CIS-5.1.13",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "references": [
        "https://kubernetes.io/docs/concepts/security/rbac-good-practices/#token-request"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.1 Ensure that the cluster has at least one active policy control mechanism in place (Manual)\nDescription: Every Kubernetes cluster should have at least one policy control mechanism in place to enforce the other requirements in this section. This could be the in-built Pod Security Admission controller, or a third party policy control system.\nRationale: Without an active policy control mechanism, it is not possible to limit the use of containers with access to underlying cluster nodes, via mechanisms like privileged containers, or the use of hostPath volume mounts.\nAudit: Review the workloads deployed to the cluster to understand if Pod Security Admission or external admission control systems are in place.\nRemediation: Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.",
    "metadata": {
      "id": "CIS-5.2.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Where policy control systems are in place, there is a risk that workloads required for the operation of the cluster may be stopped from running. Care is required when implementing admission control policies to ensure that this does not occur.",
      "default_value": "By default, Pod Security Admission is enabled but no policies are in place.",
      "references": [
        "https://kubernetes.io/docs/concepts/security/pod-security-admission"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.2 Minimize the admission of privileged containers (Manual)\nDescription: Do not generally permit containers to be run with the securityContext.privileged flag set to true.\nRationale: Privileged containers have access to all Linux Kernel capabilities and devices. A container running with full privileges can do almost everything that the host can do. This flag exists to allow special use-cases, like manipulating the network stack and accessing devices. There should be at least one admission control policy defined which does not permit privileged containers. If you need to run privileged containers, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\nAudit: Run the following command: get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: {@..securityContext}\\n{end}' It will produce an inventory of all the privileged use on the cluster, if any (please, refer to a sample below). Further grepping can be done to automate each specific violation detection. calico-kube-controllers-57b57c56f-jtmk4: {} << No Elevated Privileges calico-node- c4xv4: {} {\"privileged\":true} {\"privileged\":true} {\"privileged\":true} {\"privileged\":true} << Violates 5.2.2 dashboard-metrics-scraper-7bc864c59-2m2xw: {\"seccompProfile\":{\"type\":\"RuntimeDefault\"}} {\"allowPrivilegeEscalation\":false,\"readOnlyRootFilesystem\":true,\"runAsGroup\":2001,\"ru nAsUser\":1001} Page 250 Internal Only - General\nRemediation: Add policies to each namespace in the cluster which has user workloads to restrict the admission of privileged containers.",
    "metadata": {
      "id": "CIS-5.2.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods defined with spec.containers[].securityContext.privileged: true, spec.initContainers[].securityContext.privileged: true and spec.ephemeralContainers[].securityContext.privileged: true will not be permitted.",
      "default_value": "By default, there are no restrictions on the creation of privileged containers.",
      "references": [
        "https://kubernetes.io/docs/concepts/security/pod-security-standards/"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.3 Minimize the admission of containers wishing to share the host process ID namespace (Manual)\nDescription: Do not generally permit containers to be run with the hostPID flag set to true.\nRationale: A container running in the host's PID namespace can inspect processes running outside the container. If the container also has access to ptrace capabilities this can be used to escalate privileges outside of the container. There should be at least one admission control policy defined which does not permit containers to share the host PID namespace. If you need to run containers which require hostPID, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\nAudit: Fetch hostPID from each pod with get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: {@.spec.hostPID}\\n{end}'\nRemediation: Configure the Admission Controller to restrict the admission of hostPID containers.",
    "metadata": {
      "id": "CIS-5.2.3",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods defined with spec.hostPID: true will not be permitted unless they are run under a specific policy.",
      "default_value": "By default, there are no restrictions on the creation of hostPID containers.",
      "references": [
        "https://kubernetes.io/docs/concepts/security/pod-security-standards/"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.4 Minimize the admission of containers wishing to share the host IPC namespace (Manual)\nDescription: Do not generally permit containers to be run with the hostIPC flag set to true.\nRationale: A container running in the host's IPC namespace can use IPC to interact with processes outside the container. There should be at least one admission control policy defined which does not permit containers to share the host IPC namespace. If you need to run containers which require hostIPC, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\nAudit: To fetch hostIPC from each pod. get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: {@.spec.hostIPC}\\n{end}'\nRemediation: Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostIPC containers.",
    "metadata": {
      "id": "CIS-5.2.4",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods defined with spec.hostIPC: true will not be permitted unless they are run under a specific policy.",
      "default_value": "By default, there are no restrictions on the creation of hostIPC containers.",
      "references": [
        "https://kubernetes.io/docs/concepts/security/pod-security-standards/"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.5 Minimize the admission of containers wishing to share the host network namespace (Manual)\nDescription: Do not generally permit containers to be run with the hostNetwork flag set to true.\nRationale: A container running in the host's network namespace could access the local loopback device, and could access network traffic to and from other pods. There should be at least one admission control policy defined which does not permit containers to share the host network namespace. If you need to run containers which require access to the host's network namespaces, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\nAudit: To fetch hostNetwork from each pod. get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: {@.spec.hostNetwork}\\n{end}'\nRemediation: Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostNetwork containers.",
    "metadata": {
      "id": "CIS-5.2.5",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods defined with spec.hostNetwork: true will not be permitted unless they are run under a specific policy.",
      "default_value": "By default, there are no restrictions on the creation of hostNetwork containers.",
      "references": [
        "https://kubernetes.io/docs/concepts/security/pod-security-standards/"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.6 Minimize the admission of containers with allowPrivilegeEscalation (Manual)\nDescription: Do not generally permit containers to be run with the allowPrivilegeEscalation flag set to true. Allowing this right can lead to a process running a container getting more rights than it started with. It's important to note that these rights are still constrained by the overall container sandbox, and this setting does not relate to the use of privileged containers.\nRationale: A container running with the allowPrivilegeEscalation flag set to true may have processes that can gain more privileges than their parent. There should be at least one admission control policy defined which does not permit containers to allow privilege escalation. The option exists (and is defaulted to true) to permit setuid binaries to run. If you have need to run containers which use setuid binaries or require privilege escalation, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\nAudit: List the policies in use for each namespace in the cluster, ensure that each policy disallows the admission of containers which allow privilege escalation. To fetch a list of pods which allowPrivilegeEscalation run this command :- get pods -A -o=jsonpath=$'{range .items[*]}{@.metadata.name}: {@..securityContext}\\n{end}'\nRemediation: Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers with securityContext: allowPrivilegeEscalation: true Internal Only - General",
    "metadata": {
      "id": "CIS-5.2.6",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods defined with securityContext: allowPrivilegeEscalation: true will not be permitted unless they are run under a specific policy.",
      "default_value": "By default, there are no restrictions on contained process ability to escalate privileges, within the context of the container.",
      "references": [
        "https://kubernetes.io/docs/concepts/security/pod-security-standards/"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.7 Minimize the admission of root containers (Manual)\nDescription: Do not generally permit containers to be run as the root user.\nRationale: Containers may run as any Linux user. Containers which run as the root user, whilst constrained by Container Runtime security features still have a escalated likelihood of container breakout. Ideally, all containers should run as a defined non-UID 0 user. There should be at least one admission control policy defined which does not permit root containers. If you need to run root containers, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\nAudit: List the policies in use for each namespace in the cluster, ensure that each policy restricts the use of root containers by setting MustRunAsNonRoot or MustRunAs with the range of UIDs not including 0.\nRemediation: Create a policy for each namespace in the cluster, ensuring that either MustRunAsNonRoot or MustRunAs with the range of UIDs not including 0, is set.",
    "metadata": {
      "id": "CIS-5.2.7",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods with containers which run as the root user will not be permitted.",
      "default_value": "By default, there are no restrictions on the use of root containers and if a User is not specified in the image, the container will run as root.",
      "references": [
        "https://kubernetes.io/docs/concepts/security/pod-security-standards/"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.8 Minimize the admission of containers with the NET_RAW capability (Manual)\nDescription: Do not generally permit containers with the potentially dangerous NET_RAW capability.\nRationale: Containers run with a default set of capabilities as assigned by the Container Runtime. By default this can include potentially dangerous capabilities. With Docker as the container runtime the NET_RAW capability is enabled which may be misused by malicious containers. Ideally, all containers should drop this capability. There should be at least one admission control policy defined which does not permit containers with the NET_RAW capability. If you need to run containers with this capability, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\nAudit: List the policies in use for each namespace in the cluster, ensure that at least one policy disallows the admission of containers with the NET_RAW capability.\nRemediation: Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers with the NET_RAW capability.",
    "metadata": {
      "id": "CIS-5.2.8",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods with containers which run with the NET_RAW capability will not be permitted.",
      "default_value": "By default, there are no restrictions on the creation of containers with the NET_RAW capability.",
      "references": [
        "https://kubernetes.io/docs/concepts/security/pod-security-standards/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.9 Minimize the admission of containers with capabilities assigned (Manual)\nDescription: Do not generally permit containers with capabilities\nRationale: Containers run with a default set of capabilities as assigned by the Container Runtime. Capabilities are parts of the rights generally granted on a Linux system to the root user. In many cases applications running in containers do not require any capabilities to operate, so from the perspective of the principal of least privilege use of capabilities should be minimized.\nAudit: List the policies in use for each namespace in the cluster, ensure that at least one policy requires that capabilities are dropped by all containers.\nRemediation: Review the use of capabilities in applications running on your cluster. Where a namespace contains applications which do not require any Linux capabilities to operate consider adding a policy which forbids the admission of containers which do not drop all capabilities.",
    "metadata": {
      "id": "CIS-5.2.9",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods with containers require capabilities to operate will not be permitted.",
      "default_value": "By default, there are no restrictions on the creation of containers with additional capabilities",
      "references": [
        "https://kubernetes.io/docs/concepts/security/pod-security-standards/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.10 Minimize the admission of Windows HostProcess Containers (Manual)\nDescription: Do not generally permit Windows containers to be run with the hostProcess flag set to true.\nRationale: A Windows container making use of the hostProcess flag can interact with the underlying Windows cluster node. As per the Kubernetes documentation, this provides \"privileged access\" to the Windows node. Where Windows containers are used inside a Kubernetes cluster, there should be at least one admission control policy which does not permit hostProcess Windows containers. If you need to run Windows containers which require hostProcess, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\nAudit: List the policies in use for each namespace in the cluster, ensure that each policy disallows the admission of hostProcess containers\nRemediation: Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostProcess containers.",
    "metadata": {
      "id": "CIS-5.2.10",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods defined with securityContext.windowsOptions.hostProcess: true will not be permitted unless they are run under a specific policy.",
      "default_value": "By default, there are no restrictions on the creation of hostProcess containers.",
      "references": [
        "https://kubernetes.io/docs/tasks/configure-pod-container/create-hostprocess-pod/",
        "https://kubernetes.io/docs/concepts/security/pod-security-standards/"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.11 Minimize the admission of HostPath volumes (Manual)\nDescription: Do not generally admit containers which make use of hostPath volumes.\nRationale: A container which mounts a hostPath volume as part of its specification will have access to the filesystem of the underlying cluster node. The use of hostPath volumes may allow containers access to privileged areas of the node filesystem. There should be at least one admission control policy defined which does not permit containers to mount hostPath volumes. If you need to run containers which require hostPath volumes, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\nAudit: List the policies in use for each namespace in the cluster, ensure that each policy disallows the admission of containers with hostPath volumes.\nRemediation: Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers which use hostPath volumes.",
    "metadata": {
      "id": "CIS-5.2.11",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods defined which make use of hostPath volumes will not be permitted unless they are run under a specific policy.",
      "default_value": "By default, there are no restrictions on the creation of hostPath volumes.",
      "references": [
        "https://kubernetes.io/docs/concepts/security/pod-security-standards/"
      ]
    }
  },
  {
    "page_content": "Title: 5.2.12 Minimize the admission of containers which use HostPorts (Manual)\nDescription: Do not generally permit containers which require the use of HostPorts.\nRationale: Host ports connect containers directly to the host's network. This can bypass controls such as network policy. There should be at least one admission control policy defined which does not permit containers which require the use of HostPorts. If you need to run containers which require HostPorts, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\nAudit: List the policies in use for each namespace in the cluster, ensure that each policy disallows the admission of containers which have hostPort sections.\nRemediation: Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers which use hostPort sections.",
    "metadata": {
      "id": "CIS-5.2.12",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Pods defined with hostPort settings in either the container, initContainer or ephemeralContainer sections will not be permitted unless they are run under a specific policy.",
      "default_value": "By default, there are no restrictions on the use of HostPorts.",
      "references": [
        "https://kubernetes.io/docs/concepts/security/pod-security-standards/"
      ]
    }
  },
  {
    "page_content": "Title: 5.3.1 Ensure that the CNI in use supports Network Policies (Manual)\nDescription: There are a variety of CNI plugins available for Kubernetes. If the CNI in use does not support Network Policies it may not be possible to effectively restrict traffic in the cluster.\nRationale: Kubernetes network policies are enforced by the CNI plugin in use. As such it is important to ensure that the CNI plugin supports both Ingress and Egress network policies.\nAudit: Review the documentation of CNI plugin in use by the cluster, and confirm that it supports Ingress and Egress network policies.\nRemediation: If the CNI plugin in use does not support network policies, consideration should be given to making use of a different plugin, or finding an alternate mechanism for restricting traffic in the Kubernetes cluster.",
    "metadata": {
      "id": "CIS-5.3.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "None",
      "default_value": "This will depend on the CNI plugin in use.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://github.com/coreos/flannel"
      ]
    }
  },
  {
    "page_content": "Title: 5.3.2 Ensure that all Namespaces have Network Policies defined (Manual)\nDescription: Use network policies to isolate traffic in your cluster network.\nRationale: Running different applications on the same Kubernetes cluster creates a risk of one compromised application attacking a neighboring application. Network segmentation is important to ensure that containers can communicate only with those they are supposed to. A network policy is a specification of how selections of pods are allowed to communicate with each other and other network endpoints. Network Policies are namespace scoped. When a network policy is introduced to a given namespace, all traffic not allowed by the policy is denied. However, if there are no network policies in a namespace all traffic will be allowed into and out of the pods in that namespace.\nAudit: Run the below command and review the NetworkPolicy objects created in the cluster. kubectl get networkpolicy --all-namespaces Ensure that each namespace defined in the cluster has at least one Network Policy.\nRemediation: Follow the documentation and create NetworkPolicy objects as you need them.",
    "metadata": {
      "id": "CIS-5.3.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Once network policies are in use within a given namespace, traffic not explicitly allowed by a network policy will be denied. As such it is important to ensure that, when introducing network policies, legitimate traffic is not blocked.",
      "default_value": "By default, network policies are not created.",
      "references": [
        "https://kubernetes.io/docs/concepts/services-networking/networkpolicies/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/tasks/configure-pod-container/declare-network-policy/"
      ]
    }
  },
  {
    "page_content": "Title: 5.4.1 Prefer using secrets as files over secrets as environment variables (Manual)\nDescription: Kubernetes supports mounting secrets as data volumes or as environment variables. Minimize the use of environment variable secrets.\nRationale: It is reasonably common for application code to log out its environment (particularly in the event of an error). This will include any secret values passed in as environment variables, so secrets can easily be exposed to any user or entity who has access to the logs.\nAudit: Run the following command to find references to objects which use environment variables defined from secrets. kubectl get all -o jsonpath='{range .items[?(@..secretKeyRef)]} {.kind} {.metadata.name} {\"\\n\"}{end}' -A\nRemediation: If possible, rewrite application code to read secrets from mounted secret files, rather than from environment variables.",
    "metadata": {
      "id": "CIS-5.4.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "Application code which expects to read secrets in the form of environment variables would need modification",
      "default_value": "By default, secrets are not defined",
      "references": [
        "https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets"
      ]
    }
  },
  {
    "page_content": "Title: 5.4.2 Consider external secret storage (Manual)\nDescription: Consider the use of an external secrets storage and management system, instead of using Kubernetes Secrets directly, if you have more complex secret management needs. Ensure the solution requires authentication to access secrets, has auditing of access to and use of secrets, and encrypts secrets. Some solutions also make it easier to rotate secrets.\nRationale: Kubernetes supports secrets as first-class objects, but care needs to be taken to ensure that access to secrets is carefully limited. Using an external secrets provider can ease the management of access to secrets, especially where secrests are used across both Kubernetes and non-Kubernetes environments.\nAudit: Review your secrets management implementation.\nRemediation: Refer to the secrets management options offered by your cloud provider or a third-party secrets management solution.",
    "metadata": {
      "id": "CIS-5.4.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "None",
      "default_value": "By default, no external secret management is configured."
    }
  },
  {
    "page_content": "Title: 5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller (Manual)\nDescription: Configure Image Provenance for your deployment.\nRationale: Kubernetes supports plugging in provenance rules to accept or reject the images in your deployments. You could configure such rules to ensure that only approved images are deployed in the cluster.\nAudit: Review the pod definitions in your cluster and verify that image provenance is configured as appropriate.\nRemediation: Follow the Kubernetes documentation and setup image provenance.",
    "metadata": {
      "id": "CIS-5.5.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "You need to regularly maintain your provenance configuration based on container image updates.",
      "default_value": "By default, image provenance is not set.",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://github.com/kubernetes/kubernetes/issues/22888"
      ]
    }
  },
  {
    "page_content": "Title: 5.6.1 Create administrative boundaries between resources using namespaces (Manual)\nDescription: Use namespaces to isolate your Kubernetes objects.\nRationale: Limiting the scope of user permissions can reduce the impact of mistakes or malicious activities. A Kubernetes namespace allows you to partition created resources into logically named groups. Resources created in one namespace can be hidden from other namespaces. By default, each resource created by a user in Kubernetes cluster runs in a default namespace, called default. You can create additional namespaces and attach resources and users to them. You can use Kubernetes Authorization plugins to create policies that segregate access to namespace resources between different users.\nAudit: Run the below command and review the namespaces created in the cluster. kubectl get namespaces Ensure that these namespaces are the ones you need and are adequately administered as per your requirements.\nRemediation: Follow the documentation and create namespaces for objects in your deployment as you need them.",
    "metadata": {
      "id": "CIS-5.6.1",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "You need to switch between namespaces for administration.",
      "default_value": "By default, Kubernetes starts with 4 initial namespaces: 1. default - The default namespace for objects with no other namespace 2. kube-system - The namespace for objects created by the Kubernetes system 3. kube-node-lease - Namespace used for node heartbeats 4. kube-public - Namespace used for public information in a cluster Page 285 Internal Only - General",
      "references": [
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/",
        "https://kubernetes.io/docs/home/"
      ]
    }
  },
  {
    "page_content": "Title: 5.6.2 Ensure that the seccomp profile is set to docker/default in your pod definitions (Manual)\nDescription: Enable docker/default seccomp profile in your pod definitions.\nRationale: Seccomp (secure computing mode) is used to restrict the set of system calls applications can make, allowing cluster administrators greater control over the security of workloads running in the cluster. Kubernetes disables seccomp profiles by default for historical reasons. You should enable it to ensure that the workloads have restricted actions available within the container.\nAudit: Review the pod definitions in your cluster. It should create a line as below: securityContext: seccompProfile: type: RuntimeDefault\nRemediation: Use security context to enable the docker/default seccomp profile in your pod definitions. An example is as below: securityContext: seccompProfile: type: RuntimeDefault",
    "metadata": {
      "id": "CIS-5.6.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "If the docker/default seccomp profile is too restrictive for you, you would have to create/manage your own seccomp profiles.",
      "default_value": "By default, seccomp profile is set to unconfined which means that no seccomp profiles are enabled.",
      "references": [
        "https://kubernetes.io/docs/tutorials/clusters/seccomp/",
        "https://docs.docker.com/engine/security/seccomp/"
      ]
    }
  },
  {
    "page_content": "Title: 5.6.3 Apply Security Context to Your Pods and Containers (Manual)\nDescription: Apply Security Context to Your Pods and Containers\nRationale: A security context defines the operating system security settings (uid, gid, capabilities, SELinux role, etc..) applied to a container. When designing your containers and pods, make sure that you configure the security context for your pods, containers, and volumes. A security context is a property defined in the deployment yaml. It controls the security parameters that will be assigned to the pod/container/volume. There are two levels of security context: pod level security context, and container level security context.\nAudit: Review the pod definitions in your cluster and verify that you have security contexts defined as appropriate.\nRemediation: Follow the Kubernetes documentation and apply security contexts to your pods. For a suggested list of security contexts, you may refer to the CIS Security Benchmark for Docker Containers.",
    "metadata": {
      "id": "CIS-5.6.3",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "If you incorrectly apply security contexts, you may have trouble running the pods.",
      "default_value": "By default, no security contexts are automatically applied to pods.",
      "references": [
        "https://kubernetes.io/docs/concepts/policy/security-context/",
        "https://learn.cisecurity.org/benchmarks"
      ]
    }
  },
  {
    "page_content": "Title: 5.6.4 The default namespace should not be used (Manual)\nDescription: Kubernetes provides a default namespace, where objects are placed if no namespace is specified for them. Placing objects in this namespace makes application of RBAC and other controls more difficult.\nRationale: Resources in a Kubernetes cluster should be segregated by namespace, to allow for security controls to be applied at that level and to make it easier to manage resources.\nAudit: Run this command to list objects in default namespace kubectl get $(kubectl api-resources --verbs=list --namespaced=true -o name | paste -sd, -) --ignore-not-found -n default The only entries there should be system managed resources such as the kubernetes service\nRemediation: Ensure that namespaces are created to allow for appropriate segregation of Kubernetes resources and that all new resources are created in a specific namespace.",
    "metadata": {
      "id": "CIS-5.6.4",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management",
      "impact": "None",
      "default_value": "Unless a namespace is specific on object creation, the default namespace will be used"
    }
  },
  {
    "page_content": "Title: 1.3.7 to use 127.0.0.1\nDescription: \nRationale: \nAudit: \nRemediation:",
    "metadata": {
      "id": "CIS-1.3.7",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration"
    }
  },
  {
    "page_content": "Title: 5.2.6 to reflect new verbiage\nDescription: \nRationale: \nAudit: \nRemediation:",
    "metadata": {
      "id": "CIS-5.2.6",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management"
    }
  },
  {
    "page_content": "Title: 1.1.19 to provide a\nDescription: \nRationale: \nAudit: \nRemediation:",
    "metadata": {
      "id": "CIS-1.1.19",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Control Plane Components",
      "category_l2": "API Server Configuration"
    }
  },
  {
    "page_content": "Title: 5.3.2 moved flags in audit\nDescription: \nRationale: \nAudit: \nRemediation:",
    "metadata": {
      "id": "CIS-5.3.2",
      "source": "CIS_Kubernetes_Benchmark_V1.12_PDF.pdf",
      "category_l1": "Pod Security Policies",
      "category_l2": "Service Account Management"
    }
  },
  {
    "page_content": "Title: POLICY ON THE SECURITY OF NETWORK AND INFORMATION SYSTEMS\nDescription: For the purpose of Article 21, point (a) of Directive (EU) 2022/2555, the policy on the security of network and information systems shall: (a) set out the relevant entities’ approach to managing the security of their network and information systems; (b) be appropriate to and complementary with the relevant entities’ business strategy and objectives; (c) set out network and information security objectives; (d) include a commitment to continual improvement of the security of network and information systems; (e) include a commitment to provide the appropriate resources needed for its implementation, including the necessary staff, financial resources, processes, tools and technologies; (f) be communicated to and acknowledged by relevant employees and relevant interested external parties; (g) lay down roles and responsibilities pursuant to point 1.2; (h) list the documentation to be kept and the duration of retention of the documentation; (i) list the topic-specific policies; (j) lay down indicators and measures to monitor its implementation and the current status of relevant entities’ maturity level of network and information security; (k) indicate the date of the formal approval by the management bodies of the relevant entities (the ‘management bodies’).\nRationale: N/A\nAudit: N/A\nRemediation: - Set a policy on the security of network and information systems, covering all systems, assets and procedures that fall within the scope of the policy. - Make sure that relevant personnel and relevant interested external parties, acknowledge the policy on the security of network and information systems, typically through a signed document or digital acknowledgement, where applicable. - Depending on the context, external parties may mean suppliers, service providers, shareholders, authorities, visitors, external interest groups or forums. - The acknowledgement may be included in other contracts, such as employment contracts or service provision contracts. - The policy should be communicated to relevant personnel and interested external parties in a form that is relevant, accessible and understandable to the intended reader. - Relevant personnel and relevant interested external parties may not be made aware of the full text of the policy. Depending on their role, an extract or a summary containing only relevant information should be communicated and acknowledged. If the policy is distributed outside the entity, care should be taken not to disclose confidential information. - For contractual requirements of direct suppliers and service providers, point 5.1.4 of the Annex to the regulation. - Make sure that personnel are aware of their responsibilities for the security of network and information systems. - Make sure that the policy on the security of network and information systems is approved by the management bodies. - Make sure that the topic-specific policies are approved by an appropriate level of management. - Make sure that the policy includes detailed on the procedures for managing policy exceptions.",
    "metadata": {
      "id": "ENISA-1.1.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 ROLES, RESPONSIBILITIES AND AUTHORITIES",
      "category_l2": "POLICY ON THE SECURITY OF NETWORK AND INFORMATION SYSTEMS"
    }
  },
  {
    "page_content": "Title: POLICY ON THE SECURITY OF NETWORK AND INFORMATION SYSTEMS\nDescription: The network and information system security policy shall be reviewed and, where appropriate, updated by management bodies at least annually and when significant incidents or significant changes to operations or risks occur. The result of the reviews shall be documented.\nRationale: N/A\nAudit: N/A\nRemediation: - Review the policy on the security of network and information systems at least annually, taking into account (indicative, non-exhaustive list): - updates to the risk assessment results and the risk treatment plan (Annex to the regulation, point 2.1.4); - relevant changes in legislation (laws, regulations and other measures imposed by national competent authorities); - recommendations provided by relevant authorities; - relevant changes in industry good practices; - feedback from interested parties; - findings of compliance monitoring (section 2.2) and of independent reviews (Annex to the regulation, point 2.3), including policy violations or policy exceptions; - incidents, even those affecting similar entities in the sector. - Update the policy on the security of network and information systems and topic-specific policies, in line with new findings that could affect the entity’s approach to managing information security, including: - updates to the risk assessment results and the risk treatment plan (Annex to the regulation, point 2.1.4); - changes to the network and information systems; - changes to the environment of operation; - problems identified during the implementation of the policy; - findings of compliance monitoring (Annex to the regulation, point 2.2.1) and of independent reviews (Annex to the regulation, point 2.3), including policy violations or policy exceptions; - the status of preventive and corrective actions; - trends related to threats and vulnerabilities; and - known reported security incidents. - All updates to the policy should be based on the covered entity's unique security risks identified through its risk assessment. - Obtain approval for the revised policy and the policy exceptions by the management bodies.",
    "metadata": {
      "id": "ENISA-1.1.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 ROLES, RESPONSIBILITIES AND AUTHORITIES",
      "category_l2": "POLICY ON THE SECURITY OF NETWORK AND INFORMATION SYSTEMS"
    }
  },
  {
    "page_content": "Title: ROLES, RESPONSIBILITIES AND AUTHORITIES\nDescription: As part of their policy on the security of network and information systems referred to in point 1.1, the relevant entities shall lay down responsibilities and authorities for network and information system security and assign them to roles, allocate them according to the relevant entities’ needs and communicate them to the management bodies.\nRationale: N/A\nAudit: N/A\nRemediation: - Write job descriptions in a way that clearly outlines rights and responsibilities. - Assign security roles and responsibilities to personnel and include these roles in the organisational chart. - Describe roles and assign corresponding responsibilities (e.g. chief information security officer), based on the of international frameworks and standards, including the European cybersecurity skills framework (ECSF). - Ensure that the roles allocated are suitable for the size and business needs of the entity. - Formally appoint competent personnel in security roles. Ensure that these assigned persons are competent on the basis of appropriate education, training or experience.",
    "metadata": {
      "id": "ENISA-1.2.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 ROLES, RESPONSIBILITIES AND AUTHORITIES",
      "category_l2": "ROLES, RESPONSIBILITIES AND AUTHORITIES"
    }
  },
  {
    "page_content": "Title: ROLES, RESPONSIBILITIES AND AUTHORITIES\nDescription: The relevant entities shall require all personnel and third parties to apply network and information system security in accordance with the established network and information security policy, topic-specific policies and procedures of the relevant entities.\nRationale: N/A\nAudit: N/A\nRemediation: - Make personnel aware of the security roles in the entity and when each role should be contacted. - Make personnel aware of their network and information system security obligations, according to their role. For the disciplinary process, see point 10.4 in the Annex to the regulation. - Make relevant interested external parties aware of their network and information system security - bligations. - For contractual requirements of direct suppliers and service providers, see point 5.1.4 in the Annex to the regulation. - Consider third parties, which means external entities or organisations not directly involved in the - perations of the entity in scope but that may still affect its network and information security. For examples of relevant interested external parties, consider the in section 1.1. - The requirement that all personnel and third parties apply network and information system security should be communicated in a form that is relevant, accessible and understandable to the intended reader. - The network and information security policy, topic-specific policies and procedures of the relevant entities do not necessarily need to be communicated in their entirety.",
    "metadata": {
      "id": "ENISA-1.2.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 ROLES, RESPONSIBILITIES AND AUTHORITIES",
      "category_l2": "ROLES, RESPONSIBILITIES AND AUTHORITIES"
    }
  },
  {
    "page_content": "Title: ROLES, RESPONSIBILITIES AND AUTHORITIES\nDescription: At least one person shall report directly to the management bodies on matters of network and information system security.\nRationale: N/A\nAudit: N/A\nRemediation: - Appoint a person (e.g. chief information security officer or information security manager) responsible for - verseeing network and information security matters. - Make sure that this role is recognized and duly authorized by management bodies.",
    "metadata": {
      "id": "ENISA-1.2.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 ROLES, RESPONSIBILITIES AND AUTHORITIES",
      "category_l2": "ROLES, RESPONSIBILITIES AND AUTHORITIES"
    }
  },
  {
    "page_content": "Title: ROLES, RESPONSIBILITIES AND AUTHORITIES\nDescription: Depending on the size of the relevant entities, network and information system security shall be covered by dedicated roles or duties carried out in addition to existing roles.\nRationale: N/A\nAudit: N/A\nRemediation: - It is often practical to have dedicated information security roles (e.g. a chief information security officer or security analysts) who focus solely on protecting the entity’s data and systems. - In entities with limited resources, information security responsibilities may be distributed among existing roles. For instance, information technology (IT) staff might take on security duties alongside their regular tasks. However, the persons assigned should have relevant experience and training to perform the roles and to exercise their responsibilities.",
    "metadata": {
      "id": "ENISA-1.2.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 ROLES, RESPONSIBILITIES AND AUTHORITIES",
      "category_l2": "ROLES, RESPONSIBILITIES AND AUTHORITIES"
    }
  },
  {
    "page_content": "Title: ROLES, RESPONSIBILITIES AND AUTHORITIES\nDescription: Conflicting duties and conflicting areas of responsibility shall be segregated, where applicable.\nRationale: N/A\nAudit: N/A\nRemediation: - Consider segregating conflicting duties and areas of responsibility to reduce opportunities for unauthorized - r unintentional modification or misuse of the entity’s asset. As a minimum, consider that the reviewer (auditor) must be different from the personnel or the line of authority of the area under review. - The results of the risk assessment or the business impact analysis (BIA) could be used to identify potential conflicting duties and areas of responsibility.",
    "metadata": {
      "id": "ENISA-1.2.5",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 ROLES, RESPONSIBILITIES AND AUTHORITIES",
      "category_l2": "ROLES, RESPONSIBILITIES AND AUTHORITIES"
    }
  },
  {
    "page_content": "Title: ROLES, RESPONSIBILITIES AND AUTHORITIES\nDescription: Roles, responsibilities and authorities shall be reviewed and, where appropriate, updated by management bodies at planned intervals and when significant incidents or significant changes to operations or risks occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Regularly review and revise the structure of security roles and responsibilities, based on (indicative, nonexhaustive list): - significant incidents, if any; - changes to the environment of operation, including changes to the network and information systems; - - rganisational changes. - Where appropriate, updates should be approved by management bodies.",
    "metadata": {
      "id": "ENISA-1.2.6",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 ROLES, RESPONSIBILITIES AND AUTHORITIES",
      "category_l2": "ROLES, RESPONSIBILITIES AND AUTHORITIES"
    }
  },
  {
    "page_content": "Title: RISK MANAGEMENT FRAMEWORK\nDescription: For the purpose of Article 21, point (a) of Directive (EU) 2022/2555, the relevant entities shall establish and maintain an appropriate risk management framework to identify and address the risks posed to the security of network and information systems. The relevant entities shall perform and document risk assessments and, based on the results, establish, implement and monitor a risk treatment plan. Risk assessment results and residual risks shall be accepted by management bodies or, where applicable, by persons who are accountable and have the authority to manage risks, provided that the relevant entities ensure adequate reporting to the management bodies.\nRationale: N/A\nAudit: N/A\nRemediation: - The entity can use its current risk management framework or adopt a new one. A risk management framework is the structured approach used by an entity to identify, assess, manage and mitigate its cybersecurity risks. - Create a risk treatment plan that associates the identified risks with assets and the measures mitigating the associated risks and takes into account, at least, elements (g) to (h) in point 2.1.2 of the Annex to the regulation. The plan should at least include: - a description of the identified risk and how it can negatively affect security objectives; - a risk treatment option (for example risk avoidance, risk mitigation, risk transfer or sharing or risk acceptance); - the assets associated with the risk; - the measures which mitigate the risk; - a procedure for assessing the effectiveness of implementation of the measure(s); - implementation timelines; and - responsible roles. - Consider residual risks from third parties, for example, data breaches, unaddressed vulnerabilities, regulatory non-compliance from the from the third-party side and over-reliance on a single third party. - Ensure residual risks are accepted by management bodies or, where applicable, persons who are accountable and have the authority to manage risks, in line with the acceptable residual risk levels of the entity. - Make sure that management bodies or, where applicable, persons who are accountable and have the authority to manage risks approve the risk-assessment results and risk-treatment plan.",
    "metadata": {
      "id": "ENISA-2.1.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY",
      "category_l2": "RISK MANAGEMENT FRAMEWORK"
    }
  },
  {
    "page_content": "Title: RISK MANAGEMENT FRAMEWORK\nDescription: For the purpose of point 2.1.1, the relevant entities shall establish procedures for identification, analysis, assessment and treatment of risks (‘cybersecurity risk management process’). The cybersecurity risk management process shall be an integral part of the relevant entities’ overall risk management process, where applicable. As part of the cybersecurity risk management process, the relevant entities shall: (a) follow a risk management methodology; (b) establish the risk tolerance level in accordance with the risk appetite of the relevant entities; (c) establish and maintain relevant risk criteria; (d) in line with an all-hazards approach, identify and document the risks posed to the security of network and information systems, in particular in relation to third parties and risks that could lead to disruptions in the availability, integrity, authenticity and confidentiality of the network and information systems, including the identification of single point of failures; (e) analyse the risks posed to the security of network and information systems, including threat, likelihood, impact and risk level, taking into account cyber threat intelligence and vulnerabilities; (f) evaluate the identified risks based on the risk criteria; (g) identify and prioritise appropriate risk treatment options and measures; (h) continuously monitor the implementation of the risk treatment measures; (i) identify who is responsible for implementing the risk treatment measures and when they should be implemented; (j) document the chosen risk treatment measures in a risk treatment plan and the reasons justifying the acceptance of residual risks in a comprehensible manner.\nRationale: N/A\nAudit: N/A\nRemediation: - Select a risk management methodology. - Establish the entity's risk appetite, that is the amount of risk that the entity is strategically willing to accept to achieve its objectives. Criteria may include (indicative, non-exhaustive list): - business strategic objectives; - stakeholder expectations; - regulatory requirements; and - - rganizational culture. - Define the risk tolerance level, which refers to the level of risk that an entity is willing to accept in pursuit - f its long-term objectives. Examples may include (indicative, non-exhaustive list): - acceptable downtime for systems for which criticality is high (e.g. up to two hours of downtime per month); - tolerance for data loss (e.g. loss of data with low criticality within a 24-hour window); - maximum financial loss that can be absorbed without jeopardizing operations (e.g. up to EUR 100,000 in recovery costs); There are many risk-management standards, frameworks and methodologies. A non-exhaustive list of them can be found in the publication Compendium of risk-managements frameworks with potential interoperability, - willingness to invest a certain percentage of revenue in measures (e.g. 5% of annual revenue); - adherence to regulatory obligations with specific penalties or fines influencing risk acceptance; - acceptable level of customer dissatisfaction or negative media exposure from a data breach (e.g. tolerating one major incident every few years); - acceptance of certain vulnerabilities based on risk mitigation measures in place (e.g. outdated software provided that it is monitored and patched regularly); - time frame for responding to and recovering from incidents (e.g. a maximum of 48 hours for containment); and - acceptance of minor incidents as part of normal operations while prioritizing major threats. - Define risk acceptance criteria, which may include (indicative, non-exhaustive list): - accepting risks categorized as low severity, such as minor data leaks that don't expose sensitive information; - accepting risks assessed as having a low likelihood of occurrence (e.g. certain rare types of cyberattacks); - accepting risks if the cost of mitigation exceeds the potential impact (e.g. not upgrading legacy systems if the upgrade cost is significantly higher than potential losses); - accepting specific compliance risks if there is a plan in place to address them within a defined timeframe (e.g. temporarily accepting minor non-compliance with a commitment to remediate within six months); - allowing certain risks in low-criticality systems or departments that do not affect core business - perations (e.g. accepting a risk in a test environment); - accepting certain vulnerabilities for a defined period while planning for remediation (e.g. accepting the risk of outdated software for three months until a full upgrade can be completed); - accepting risks where the expected incident impact falls below a predetermined financial threshold (e.g. losses under EUR 50,000 accepted without further action); - accepting risks after informing stakeholders and receiving their agreement, particularly if they understand the trade-offs involved; and - accepting residual risks where existing measures reduce the likelihood or impact to an acceptable level (e.g. using encryption for sensitive data but accepting risks of loss due to user error). - Define risk criteria, that is, how the entity evaluates the significance of the risks that it identifies and makes decisions concerning risks. Risk criteria may include (indicative, non-exhaustive list): - alignment with risk appetite: accepting risks that align with the organization's overall risk appetite, such as delays in internal reporting processes that do not impact customer service or compliance; - regulatory and legal exposure: prioritizing risks based on potential legal or regulatory consequences, such as treating violations of the General Data Protection Regulation (GDPR) involving customer data as high-risk due to potential fines and reputational damage; - reputational impact: escalating risks that could significantly harm the organization's public image, such as incidents likely to attract media attention; - risk velocity: giving higher priority to risks with high velocity, such as zero-day exploits that can be weaponised before patches are available; More information on risk criteria can be found in ISO/IEC 27005:2022, paragraph 6.4. It is important to understand that risk appetite, defined as the amount of risk an entity is willing to pursue or accept, can vary considerably from entity to entity. For instance, factors affecting an entity’s risk appetite include size, complexity and sector. - recovery complexity: treating risks as critical if they involve complex or time-consuming recovery, such as cyber-attacks on legacy systems with limited vendor support; - emerging technology risks: Considering risks involving emerging technologies as higher priority, such as AI systems producing unexplainable or non-compliant decisions due to lack of transparency; - stakeholder sensitivity: re-evaluating risks that concern key stakeholders, such as risks flagged by the board, regulators or major customers, even if the assessed technical risk is low. - Criteria for performing cybersecurity risk assessments refer to consequences, likelihood or level of risk. These may refer to (indicative, non-exhaustive list): - the importance of assets; - the severity of threats; - the vulnerability of network and information systems; - impact analysis; - existing measures; and - stakeholders concerns or requirements. - Make a list of the main risks for the security of network and information systems, taking into account the main threats to the assets in scope. - Make sure that each risk is associated with at least one: - - f the risk treatment options or a combination of them, in line with the results of the risk assessment and in accordance with the entity’s policy on the security of network and information systems (recital 11 of the regulation); and - specific risk treatment measure. - Develop risk-treatment plans to address the elements in points (i) and (j) in point 2.1.2 of the Annex to the regulation. - Assign responsibilities to appropriate individuals or teams for executing these risk treatment plans.",
    "metadata": {
      "id": "ENISA-2.1.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY",
      "category_l2": "RISK MANAGEMENT FRAMEWORK"
    }
  },
  {
    "page_content": "Title: RISK MANAGEMENT FRAMEWORK\nDescription: When identifying and prioritising appropriate risk treatment options and measures, the relevant entities shall take into account the risk assessment results, the results of the procedure to assess the effectiveness of cybersecurity riskmanagement measures, the cost of implementation in relation to the expected benefit, the asset classification referred to in point 12.1 and the business impact analysis referred to in point 4.1.3.\nRationale: N/A\nAudit: N/A\nRemediation: - Make sure that personnel take into account the elements referred to in point 2.1.3 of the Annex to the regulation.",
    "metadata": {
      "id": "ENISA-2.1.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY",
      "category_l2": "RISK MANAGEMENT FRAMEWORK"
    }
  },
  {
    "page_content": "Title: RISK MANAGEMENT FRAMEWORK\nDescription: The relevant entities shall review and, where appropriate, update the risk assessment results and the risk treatment plan at planned intervals and at least annually and when significant changes to operations or risks or significant incidents occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Review risk assessment results and risk treatment at least annually taking into account: - results of audits and previous reviews, - status of implementation of the measures described in the risk treatment plan (see the policy on the assessment of the effectiveness of measures in line with the Annex to Regulation, point 7.1.1); - changes to the information systems; - changes to the environment of operation; - post-incident review findings (section 3.6); and - trends and changes related to threats and vulnerabilities, as they may affect risks.",
    "metadata": {
      "id": "ENISA-2.1.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY",
      "category_l2": "RISK MANAGEMENT FRAMEWORK"
    }
  },
  {
    "page_content": "Title: COMPLIANCE MONITORING\nDescription: The relevant entities shall regularly review the compliance with their policies on network and information system security, topic-specific policies, rules and standards. The management bodies shall be informed of the status of network and information security on the basis of the compliance reviews by means of regular reporting.\nRationale: N/A\nAudit: N/A\nRemediation: - Develop a standardized report format for reporting to management bodies. Consider the following elements (indicative, non-exhaustive list): - key metrics, - compliance status, including policy exceptions, - identified risks and - recommended actions. - Reports are generated and presented to management bodies at least annually.",
    "metadata": {
      "id": "ENISA-2.2.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY",
      "category_l2": "COMPLIANCE MONITORING"
    }
  },
  {
    "page_content": "Title: COMPLIANCE MONITORING\nDescription: The relevant entities shall put in place an effective compliance reporting system which shall be appropriate to their structures, operating environments and threat landscapes. The compliance reporting system shall be capable to provide to the management bodies an informed view of the current state of the relevant entities’ management of risks.\nRationale: N/A\nAudit: N/A\nRemediation: - Set up procedures for compliance monitoring, including (indicative, non-exhaustive list): - - bjectives and a high-level approach to compliance monitoring; - relevant security policies that are subject to compliance monitoring; - the frequency of compliance reviews; - who should carry out compliance reviews (internal or external); and - templates for compliance review reports. - Analyse and evaluate the results of the compliance review.",
    "metadata": {
      "id": "ENISA-2.2.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY",
      "category_l2": "COMPLIANCE MONITORING"
    }
  },
  {
    "page_content": "Title: COMPLIANCE MONITORING\nDescription: The relevant entities shall perform the compliance monitoring at planned intervals and when significant incidents - r significant changes to operations or risks occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Compliance monitoring should take place at least annually, taking into account: - significant incidents, if any; - changes to the environment of operation; - changes to the threat landscape and cybersecurity legal and regulatory requirements; - changes to standards; and - changes to the policy on the security of network and information systems and/or topic-specific policies.",
    "metadata": {
      "id": "ENISA-2.2.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY",
      "category_l2": "COMPLIANCE MONITORING"
    }
  },
  {
    "page_content": "Title: INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY\nDescription: The relevant entities shall review independently their approach to managing network and information system security and its implementation including people, processes and technologies.\nRationale: N/A\nAudit: N/A\nRemediation: - Make sure that the independent review is conducted by a person or persons with the appropriate competences (indicative, non-exhaustive list): - cybersecurity technical knowledge, for example cybersecurity frameworks (ISO/IEC 27001, National Institute of Standards and Technology (NIST) cybersecurity framework, etc.), - industry knowledge, - risk assessment skills, - compliance and regulatory knowledge, for example the NIS2 Directive, the GDPR and the Digital Operational Resilience Act, - good understanding of good practices in auditing and - good understanding of when technical certification and conformance are required and must be documented in the conformance and compliance report, to ensure that global standards are implemented correctly.",
    "metadata": {
      "id": "ENISA-2.3.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY",
      "category_l2": "INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY"
    }
  },
  {
    "page_content": "Title: INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY\nDescription: The relevant entities shall develop and maintain processes to conduct independent reviews which shall be carried - ut by individuals with appropriate audit competence. Where the independent review is conducted by staff members of the relevant entity, the persons conducting the reviews shall not be in the line of authority of the personnel of the area under review. If the size of the relevant entities does not allow such separation of line of authority, the relevant entities shall put in place alternative measures to guarantee the impartiality of the reviews.\nRationale: N/A\nAudit: N/A\nRemediation: - Set up a process for independent review of information and network security, including (indicative and non-exhaustive list): - scope and purpose of the independent reviews (e.g. compliance, risk assessment, policy adherence); - methodology of the reviews (e.g. standardised checklist, standard based, ad hoc, how it addresses processes that will be tested in real time for conformance (e.g. cloud service) or those that will be periodically evaluated); - review committee’s role; - frequency of the independent reviews; - who should carry out independent reviews (internal or external); and - templates for independent review reports. - Maintain independence in line with point 2.3.2 of the Annex to the regulation; - Where appropriate, consider alternative measures to the separation of line of authority (indicative and nonexhaustive list): - review personnel rotation; - set up a review committee with members from different departments; - external third-party review service provider.",
    "metadata": {
      "id": "ENISA-2.3.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY",
      "category_l2": "INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY"
    }
  },
  {
    "page_content": "Title: INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY\nDescription: The results of the independent reviews, including the results from the compliance monitoring pursuant to point 2.2. and the monitoring and measurement pursuant to point 7, shall be reported to the management bodies. Corrective actions shall be taken or residual risk accepted according to the relevant entities’ risk acceptance criteria.\nRationale: N/A\nAudit: N/A\nRemediation: - Analyse and evaluate the results of the independent review. - Report results to management bodies. - Use a standardized report format for reporting to the management bodies. Consider the following elements (indicative, non-exhaustive list): - executive summary, including the scope and key findings, - methodology, - detailed findings, including gaps identified and non-compliance issues, - recommendations and - conclusions. - Reports are generated and presented to management bodies at least annually. - Take corrective actions or justify, accept and document residual risks. - The outcomes of independent reviews should be systematically reflected in the risk assessment results and risk treatment plans (Annex to the regulation, point 2.1). Specifically, when a risk is identified or reassessed through an independent review, the corresponding risk assessment should be updated accordingly. This ensures that the risk profile remains accurate and that any emerging or evolving risks are adequately captured and addressed in the overall risk management framework.",
    "metadata": {
      "id": "ENISA-2.3.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY",
      "category_l2": "INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY"
    }
  },
  {
    "page_content": "Title: INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY\nDescription: The independent reviews shall take place at planned intervals and when significant incidents or significant changes to operations or risks occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Independent reviews should take place at least annually, taking into account: - significant incidents, if any; - changes to the environment of operation; - changes to the threat landscape and cybersecurity legal and regulatory requirements; and - changes to the policy on the security of network and information systems and/or topic-specific policies.",
    "metadata": {
      "id": "ENISA-2.3.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY",
      "category_l2": "INDEPENDENT REVIEW OF INFORMATION AND NETWORK SECURITY"
    }
  },
  {
    "page_content": "Title: INCIDENT HANDLING POLICY\nDescription: For the purpose of Article 21, point (b) of Directive (EU) 2022/2555, the relevant entities shall establish and implement an incident handling policy laying down the roles, responsibilities and procedures for detecting, analysing, containing or responding to, recovering from, documenting and reporting of incidents in a timely manner.\nRationale: N/A\nAudit: N/A\nRemediation: - Define clear objectives for the incident handling policy. - Ensure the policy complies with relevant laws, regulations and industry standards.",
    "metadata": {
      "id": "ENISA-3.1.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "INCIDENT HANDLING POLICY"
    }
  },
  {
    "page_content": "Title: INCIDENT HANDLING POLICY\nDescription: The policy referred to in point 3.1.1 shall be coherent with the business continuity and disaster recovery plan referred to in point 4.1. The policy shall include: (a) a categorisation system for incidents that is consistent with the event assessment and classification carried out pursuant to point 3.4.1; (b) effective communication plans including for escalation and reporting; (c) assignment of roles to detect and appropriately respond to incidents to competent employees; (d) documents to be used in the course of incident detection and response such as incident response manuals, escalation charts, contact lists and templates.\nRationale: N/A\nAudit: N/A\nRemediation: - Align the incident handling policy with the business continuity and disaster recovery plan (Annex to the regulation, point 4.1) by (indicative, non-exhaustive list): - ensuring that they aim to minimise disruptions, protect assets and ensure a swift return to normal - perations; - identifying interfaces between the incident handling policy and business continuity management; - describing workflows which trigger business continuity (Annex to the regulation, points 4.1, 4.2 - r 4.3) during an incident; and - developing scenarios that test the interaction between these processes and describe the result - f this interaction in the incident handling policy. In addition, consider the ‘Incident response recommendations and considerations for cybersecurity risk management’ from NIST, - Set up a categorisation system for incidents, which refers to the scheme that the entity uses to identify the consequences and the priority of an incident, together with the criteria for categorising events as incidents. An indicative, non-exhaustive list of criteria might include one or more of the following: - impact on business operations, - data sensitivity in accordance with risk management, - legal and regulatory impact, including reporting timelines stemming from regulatory framework e.g. GDPR, national regulations, - scope and scale meaning the evaluation of how widespread the event is, - type of attack, - malicious software/vulnerability exploitation, - criticality of the systems affected, - incident containment urgency, - potential of data exfiltration or corruption, such as in the case of ransomware, - likelihood of recovery, - impact on human lives and safety and - - ther criteria on what constitutes a significant incident as per this regulation. - Ensure that the incident handling policy refers to different types of incidents such as (indicative, nonexhaustive list): - system failures and loss of service availability; - malicious code; - denial of service; - errors; - breaches of confidentiality and integrity; and - misuse of network and information systems. - Communicate the incident to relevant stakeholders and personnel according to a communication plan. The communication plan should consider the event reporting mechanism (Annex to the regulation, point 3.3) and may include (indicative, non-exhaustive list) the following: - purpose and scope of the plan, - roles and responsibilities for communication tasks, - list of internal and external stakeholders to be informed, - reporting timelines stemming from regulatory framework, e.g. GDPR, national regulations, - conditions and procedures for escalation of incidents, - channels to be used for communication (e.g. email, intranet, phone calls, social media, press releases), - channels of communication need to be tailored based on the target audience (that is internal, client or general public, etc.), - methods for stakeholders to provide feedback or ask questions and The ISO/IEC 27035 series provides further on incident management: ISO/IEC 27035-1:2023(en) Information technology – Information security incident management – Part 1: Principles and process. For the categorisation of incidents, please also consult the guidelines related to Article 23 summary reporting for the NIS2 Directive or information provided by the national computer security incident response teams (CSIRTs). A cyberattack involves deliberate and malicious attempts to compromise the availability, authenticity, integrity or confidentiality of stored, transmitted or processed data or of the services offered by or accessible via, network and information systems. The attack can be due to insider activity or external perpetrators. - guidelines for when to communicate and the frequency of updates, along with pre-drafted message templates for various scenarios and the core messages to be communicated. - Identify the necessary roles and responsibilities to be assigned for incident handling. The entities can use already established skills frameworks, for example the ECSF, to assist them in identifying the necessary skills and knowledge.",
    "metadata": {
      "id": "ENISA-3.1.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "INCIDENT HANDLING POLICY"
    }
  },
  {
    "page_content": "Title: INCIDENT HANDLING POLICY\nDescription: The roles, responsibilities and procedures laid down in the policy shall be tested and reviewed and, where appropriate, updated at planned intervals and after significant incidents or significant changes to operations or risks.\nRationale: N/A\nAudit: N/A\nRemediation: - Consider one or more of the following to test the entity’s incident handling policy (indicative, nonexhaustive list): - tabletop exercise, - simulation of an incident, preferably based on a selected attack scenario based on identified risks and the current threat landscape, - red team/blue team exercise and - past incident walk-through. - Test the roles, responsibilities and procedures laid down in the policy at least annually. - Review and update roles, responsibilities and procedures laid down in the policy at least annually, taking into account the following, in addition to the elements referred to in point 3.1.3 of the Annex to the regulation: - results from the policy tests, - changes to the threat landscape and cybersecurity legal and regulatory requirements and - changes to the policy on the security of network and information systems and/or topic-specific policies.",
    "metadata": {
      "id": "ENISA-3.1.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "INCIDENT HANDLING POLICY"
    }
  },
  {
    "page_content": "Title: MONITORING AND LOGGING\nDescription: The relevant entities shall lay down procedures and use tools to monitor and log activities on their network and information systems to detect events that could be considered as incidents and respond accordingly to mitigate the impact.\nRationale: N/A\nAudit: N/A\nRemediation: - Identify one or more objectives of monitoring and logging (indicative, non-exhaustive list): - threat detection, - compliance assurance, - incident response support, - performance optimisation, - anomaly detection, - monitor for new vulnerability reports issued for any free and open source software components used by the entity, - data loss prevention, - forensic investigations support and - network health monitoring. - Procedures should describe (indicative, non-exhaustive list): - - bjectives, - data for collection and relevant tools, - description of data algorithms and - mechanisms for notifying the relevant personnel. Most software today builds on the rich foundation of infrastructure that has been provided freely by free and open source software (FOSS) projects and communities. In line with the approach to FOSS in Regulation (EU) 2024/2487, this document includes on the responsible use of free and open source software in relevant sections, for example in sections 5.1 and 6.1. Article 3 of the Cyber Resilience Act. - Select tools that serve the objectives of monitoring and logging according to specific criteria (indicative, non-exhaustive list): - ease of use, - integration with the existing network and information system, including cross-border operations and the associated regulatory, security and performance considerations, - minimisation of manual intervention, - capability of collecting data from various sources, for example networks, systems and applications, - security features offered, for example encryption and access control and - costs and licencing.",
    "metadata": {
      "id": "ENISA-3.2.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "MONITORING AND LOGGING"
    }
  },
  {
    "page_content": "Title: MONITORING AND LOGGING\nDescription: To the extent feasible, monitoring shall be automated and carried out either continuously or in periodic intervals, subject to business capabilities. The relevant entities shall implement their monitoring activities in a way which minimises false positives and false negatives.\nRationale: N/A\nAudit: N/A\nRemediation: - To minimise false positives and false negatives, to the extent feasible, consider one or more of the following (indicative, non-exhaustive list): - establish network traffic patterns; - use analytics and machine learning algorithms; - continuously update the automated monitoring tools to adapt to new threats and changes in the environment; and - fine-tune the parameters and thresholds based on the latest data and feedback. - Where appropriate, ensure that all potential risks are properly covered by relevant use cases, for example use case for access to critical data, use case for data exfiltration or use case for ransomware infection, so that no critical threat goes undetected.",
    "metadata": {
      "id": "ENISA-3.2.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "MONITORING AND LOGGING"
    }
  },
  {
    "page_content": "Title: MONITORING AND LOGGING\nDescription: Based on the procedures referred to in point 3.2.1., the relevant entities shall maintain, document and review logs. The relevant entities shall establish a list of assets to be subject to logging based on the results of the risk assessment carried out pursuant to point 2.1. Where appropriate, logs shall include: (a) relevant outbound and inbound network traffic; (b) creation, modification or deletion of users of the relevant entities’ network and information systems and extension of the permissions; (c) access to systems and applications; (d) authentication-related events; (e) all privileged access to systems and applications and activities performed by administrative accounts; (f) access or changes to critical configuration and backup files; (g) event logs and logs from security tools, such as antivirus, intrusion detection systems or firewalls; (h) use of system resources, as well as their performance; (i) physical access to facilities; (j) access to and use of their network equipment and devices; (k) activation, stopping and pausing of the various logs; (l) environmental events.\nRationale: N/A\nAudit: N/A\nRemediation: - With regard to critical configuration, consider the settings and parameters that are vital for the proper functioning, security and performance of the entity’s network and information system. These configurations are vital because any changes or misconfigurations might have a significant impact, including system - utages, security vulnerabilities or reduced performance of the entity’s network and information system. - Consult the risk assessment results to determine which network traffic needs to be logged. For example, if certain assets are identified as high risk (e.g. due to being potentially vulnerable or crucial to the business - peration) their inbound and outbound traffic should be logged for monitoring and analysis.",
    "metadata": {
      "id": "ENISA-3.2.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "MONITORING AND LOGGING"
    }
  },
  {
    "page_content": "Title: MONITORING AND LOGGING\nDescription: The logs shall be regularly reviewed for any unusual or unwanted trends. Where appropriate, the relevant entities shall lay down appropriate values for alarm thresholds. If the laid down values for alarm threshold are exceeded, an alarm shall be triggered, where appropriate, automatically. The relevant entities shall ensure that, in case of an alarm, a qualified and appropriate response is initiated in a timely manner.\nRationale: N/A\nAudit: N/A\nRemediation: - Consider the use of anomaly detection or adaptive alarm thresholds to complement traditional static rules. - Make sure that procedures are designed to detect network-based attacks based on anomalous inbound and outbound ingress or egress traffic patterns and/or denial of service (DoS) attacks, in a timely manner. - Make sure that alarm thresholds, where appropriate, have been set in alignment with the results of the risk assessment carried out pursuant to point 2.1, covering at least the situations in point 3.2.3 of the Annex to the regulation. An indicative, non-exhaustive list of examples with thresholds follows: - relevant outbound and inbound network traffic: traffic volume spikes exceeding 50% of normal traffic in a 10-minute period on a specific port; - access to systems and applications: three or more account lockouts within 15 minutes; - privileged access: two or more instances of privilege escalation (e.g. normal user to admin) within 24 hours; - antivirus: malware is detected on multiple endpoints within a short timeframe; - use of system resources: installations of unauthorised software within a short timeframe.",
    "metadata": {
      "id": "ENISA-3.2.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "MONITORING AND LOGGING"
    }
  },
  {
    "page_content": "Title: MONITORING AND LOGGING\nDescription: The relevant entities shall maintain and back up logs for a predefined period and shall protect them from unauthorised access or changes.\nRationale: N/A\nAudit: N/A\nRemediation: - Make sure that the log retention period is defined in accordance with business needs, the risk assessment results and legal requirements/obligations. - The backup logs’ maintenance period shouldn’t be shorter than the logs’ review period, referred to in point 3.2.4 of the Annex to the regulation. - The retention period should be in line with what is referred to in point 4.2.2 (f) of the Annex to the regulation. - Delete data when the retention period ends. - Consider mechanisms to protect logs from unauthorised access or changes (indicative, non-exhaustive list): - encryption, - access control, - hashing (section 9.2) and - logging of all access and changes to log files. - The access control should be in line with what is referred to in point 4.2.2 (d) of the Annex to the regulation.",
    "metadata": {
      "id": "ENISA-3.2.5",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "MONITORING AND LOGGING"
    }
  },
  {
    "page_content": "Title: MONITORING AND LOGGING\nDescription: To the extent feasible, the relevant entities shall ensure that all systems have synchronised time sources to be able to correlate logs between systems for event assessment. The relevant entities shall establish and keep a list of all assets that are being logged and ensure that monitoring and logging systems are redundant. The availability of the monitoring and logging systems shall be monitored independent of the systems they are monitoring.\nRationale: N/A\nAudit: N/A\nRemediation: - Consider the following for time synchronisation: - Utilize Network Time Protocol (NTP) servers or Precision Time Protocol (PTP) for accurate and reliable time synchronization. - Use authenticated NTP to prevent malicious entities from tampering with your time synchronization. - Configure a central time server within the entity ( 25). This server should synchronize with a reliable external time source and then distribute the time to all other systems within the network. - Use multiple time sources to avoid a single point of failure. - Plan how time synchronization is handled across on-premises systems (for example servers in a company's own data centre), cloud services, and software-as-a-service (SaaS) platforms - especially if the organization uses a hybrid environment (a mix of on-premises and cloud-based systems). - Assets being logged should be marked as such in the asset inventory, in line with what is referred to in point 12.4 of the Annex to the regulation. - Implement measures to protect log data against loss, including but not limited to redundant storage across multiple locations (e.g. cloud, secondary servers), retention of processed log events in structured systems and preservation of derived security insights (e.g. alerts, metrics) in line with what is referred to in point 4.2 - f the Annex to the regulation. These complementary approaches ensure both data integrity and - perational continuity in security monitoring and incident response. - Deploy separate tools to monitor the capacity and availability of the entity’s primary monitoring and logging systems.",
    "metadata": {
      "id": "ENISA-3.2.6",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "MONITORING AND LOGGING"
    }
  },
  {
    "page_content": "Title: MONITORING AND LOGGING\nDescription: The procedures as well as the list of assets that are being logged shall be reviewed and, where appropriate, updated at regular intervals and after significant incidents.\nRationale: N/A\nAudit: N/A\nRemediation: - Determine the frequency of reviews based on the risk assessment results related to the criticality of the assets, ensuring that reviews are conducted at least annually. - Include the testing of monitoring and logging procedures in security testing (section 6.5). - Review a random sample of logs to verify that all the assets that should be subject to the log are actually considered.",
    "metadata": {
      "id": "ENISA-3.2.7",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "MONITORING AND LOGGING"
    }
  },
  {
    "page_content": "Title: EVENT REPORTING\nDescription: The relevant entities shall put in place a simple mechanism allowing their employees, suppliers and customers to report suspicious events.\nRationale: N/A\nAudit: N/A\nRemediation: - Define what constitutes a suspicious event based on criteria (indicative, non-exhaustive list): - if the confidentiality or the integrity or the availability of the network or the information system has been affected; - persistence, meaning whether the event is ongoing or not; - impact, for example. the number of assets (potentially) affected; and - compliance violation of a regulation or the entity’s policies. - Develop clear and concise guidelines for what information should be included in a report. Align this information with the information that might be submitted to the CSIRT or, where applicable to the competent authority, if the event is notified in accordance with the NIS2 Directive Articles 23 or 30. As good practice, the following should be reported as a minimum (indicative, non-exhaustive list): - date and time of the event, - description of the event, - any relevant screenshots, logs or other evidence, - contact information for follow-up if necessary. - Provide multiple channels for reporting, such as email, a web form, a dedicated phone line or a mobile app. Ensure that these channels are easily accessible and intuitive to use.",
    "metadata": {
      "id": "ENISA-3.3.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "EVENT REPORTING"
    }
  },
  {
    "page_content": "Title: EVENT REPORTING\nDescription: The relevant entities shall, where appropriate, communicate the event reporting mechanism to their suppliers and customers and shall regularly train their employees how to use the mechanism.\nRationale: N/A\nAudit: N/A\nRemediation: - Make appropriate means for reporting available to personnel and the entity’s suppliers and customers. - Consider anonymous reporting to encourage individuals to report security events without fear of reprisal. - Take into account legal obligations to report an incident to the competent authorities (and CSIRTs) in line with the NIS2 Directive Articles 23 and 30, including any obligations about when the incident should be reported. - Regularly remind stakeholders of the reporting mechanism through email newsletters, posters and other communication channels. - Conduct regular exercises or simulations to test the effectiveness of the reporting mechanism.",
    "metadata": {
      "id": "ENISA-3.3.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "EVENT REPORTING"
    }
  },
  {
    "page_content": "Title: EVENT ASSESSMENT AND CLASSIFICATION\nDescription: The relevant entities shall assess suspicious events to determine whether they constitute incidents and, if so, determine their nature and severity.\nRationale: N/A\nAudit: N/A\nRemediation: - Use criteria to assess whether a suspicious event is an incident or not. The in section 3.1.2 provides an indicative, non-exhaustive list of such criteria. - Determine the nature and severity of the event based on a categorisation system referred to in point 3.1.2 (a) of the Annex to the regulation.",
    "metadata": {
      "id": "ENISA-3.4.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "EVENT ASSESSMENT AND CLASSIFICATION"
    }
  },
  {
    "page_content": "Title: EVENT ASSESSMENT AND CLASSIFICATION\nDescription: For the purpose of point 3.4.1, the relevant entities shall act in the following manner: (a) carry out the assessment based on predefined criteria laid down in advance and on a triage to determine prioritisation - f incident containment and eradication; (b) assess the existence of recurring incidents as referred to in Article 4 of this Regulation on a quarterly basis; (c) review the appropriate logs for the purposes of event assessment and classification; (d) put in place a process for log correlation and analysis and (e) reassess and reclassify events in case of new information becoming available or after analysis of previously available information.\nRationale: N/A\nAudit: N/A\nRemediation: - In the procedures defined in points 3.1.1 and 3.1.2 of the Annex to the regulation, include activities for assessing suspicious events to determine their nature and severity. These activities should include steps such as: - gathering relevant information and evidence related to the event. - analysing the potential impact on the entity’s systems, data and operations. - determining the severity of the incident based on predefined criteria. - Implement playbooks or runbooks to guide initial assessment actions for common types of incidents, for example ransomware, phishing, data or device loss, or fire. - Classify events based on their nature, severity and potential impact. Common classifications may include: - low, medium, high or critical severity; - incident types (e.g. malicious software infection or unauthorized access); - regulatory or compliance implications. - Prioritise the event according to specific criteria, as defined in the categorisation system included in the incident handling policy referred to in point 3.1.2 of the Annex to the regulation. - By performing root cause analysis, determine recurring instances of an incident. An example of good practice for such playbooks is the OASIS Collaborative Automated Course of Action Operations (CACAO) Security Playbooks Version Specification, v2.0, More information on information security incident root cause analysis can be found in Forum of Incident Response and Security Teams, ‘FIRST CSIRT services framework’, , ‘6.2.4 Function: Information security incident root cause analysis’, For the criteria on recurring incidents, see Article 4 of Commission Implementing Regulation (EU) 2024/2690 of 17 October 2024. - Consider that the root cause of an incident may be challenging to determine during the early stages of incident handling, so the assessment of the existence of recurring incidents may be delayed. - Review and correlate the logs in line with what is referred to in point 3.2 of the Annex to the regulation. - Assess past events and their classification to improve processes, procedures and thresholds.",
    "metadata": {
      "id": "ENISA-3.4.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "EVENT ASSESSMENT AND CLASSIFICATION"
    }
  },
  {
    "page_content": "Title: INCIDENT RESPONSE\nDescription: The relevant entities shall respond to incidents in accordance with documented procedures and in a timely manner.\nRationale: N/A\nAudit: N/A\nRemediation: - Establish a dedicated incident response team comprising employees with the necessary technical expertise and authority to respond effectively to incidents, where appropriate. - Define roles and responsibilities within the incident response team, such as incident coordinators, analysts and communication liaisons, where appropriate. - Take into account industry-recognised standards when developing the incident response procedures. - Implement playbooks or runbooks to guide incident response actions for common types of incidents.",
    "metadata": {
      "id": "ENISA-3.5.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "INCIDENT RESPONSE"
    }
  },
  {
    "page_content": "Title: INCIDENT RESPONSE\nDescription: The incident response procedures shall include the following stages: (a) incident containment, to prevent the consequences of the incident from spreading; (b) eradication, to prevent the incident from continuing or reappearing, (c) recovery from the incident, where necessary.\nRationale: N/A\nAudit: N/A\nRemediation: - Create incident response procedures outlining the steps referred to in point 3.5.2 of the Annex to the regulation. - Ensure that the handling of cybersecurity incidents takes into account the entity’s priorities and the impact - f the incident. - Recognize and address potential conflicts between the following objectives during incident handling:  forensic activities – preserving and securing evidence for legal, compliance or investigative purposes,  incident response activities – mitigating and removing current threats to prevent further damage and  - perational continuity – minimizing disruption to IT services and maintaining critical - perations. - Where these objectives conflict, establish a clear decision-making process that:  prioritises based on the accepted risk tolerance levels, business impact and legal - bligations, In addition to those mentioned in the mapping table at the end of this section, consider the following: - ISO/IEC 27035-1:2023, Information technology – Information security incident management, Part 1: Principles and process; - ISO/IEC 27035-2:2023, Information technology – Information security incident management, Part 2: Guidelines to plan and prepare for incident response; - NIST SP 800-61 Rev. 2, ‘Computer security incident handling guide’,  involves coordination between cybersecurity, legal/compliance and operational teams and  documents the rationale for prioritisation decisions to ensure transparency and accountability. - Develop incident response playbooks that incorporate decision making and escalation paths for managing trade-offs between evidence preservation, threat containment and operational continuity. - Keep the management bodies informed.",
    "metadata": {
      "id": "ENISA-3.5.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "INCIDENT RESPONSE"
    }
  },
  {
    "page_content": "Title: INCIDENT RESPONSE\nDescription: The relevant entities shall establish communication plans and procedures: (a) with the Computer Security Incident Response Teams (CSIRTs) or, where applicable, the competent authorities, related to incident notification; (b) with relevant internal and external stakeholders.\nRationale: N/A\nAudit: N/A\nRemediation: - Ensure that the communication plan (Annex to the regulation, point 3.1.2) includes procedures for how to communicate the incident to the relevant authorities, the national CSIRT and internal and external stakeholders, including, where applicable, customers, direct suppliers, service providers and, if open source is used, contacts for free and open source software projects. - Include contact information for key personnel, external stakeholders and relevant authorities.",
    "metadata": {
      "id": "ENISA-3.5.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "INCIDENT RESPONSE"
    }
  },
  {
    "page_content": "Title: INCIDENT RESPONSE\nDescription: The relevant entities shall log incident response activities in accordance with the procedures referred to in point\nRationale: N/A\nAudit: N/A\nRemediation:",
    "metadata": {
      "id": "ENISA-3.5.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "INCIDENT RESPONSE"
    }
  },
  {
    "page_content": "Title: MONITORING AND LOGGING\nDescription: and record evidence.\nRationale: N/A\nAudit: N/A\nRemediation: - Log incident response information which contains (indicative, non-exhaustive list): - time of detection, containment and eradication; - when the systems recovered; - indicators of compromise; - root cause; - actions taken during each phase namely, detection, containment and eradication; - assessment of the scope and the level of impact of the incident; - communications when responding to the incident; - post incident lessons learnt and recommendations; and - whether the CSIRT or the competent authority was notified of the incident according to the NIS2 Directive Articles 23 and 30.",
    "metadata": {
      "id": "ENISA-3.2.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "MONITORING AND LOGGING"
    }
  },
  {
    "page_content": "Title: INCIDENT RESPONSE\nDescription: The relevant entities shall test at planned intervals their incident response procedures.\nRationale: N/A\nAudit: N/A\nRemediation: - Test the entity’s incident response procedures at least annually. - Test different types of incidents, for example ransomware, phishing, data breach and DoS. - Ensure that test scenarios involve employees from different departments as well as external stakeholders, for example suppliers and service providers. - Where necessary, include management bodies in the tests so that they understand their role during an incident. - Conduct post-test reviews for possible lessons learnt. - Update the incident response procedures based on the lessons learnt from the test, if applicable.",
    "metadata": {
      "id": "ENISA-3.5.5",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "INCIDENT RESPONSE"
    }
  },
  {
    "page_content": "Title: POST-INCIDENT REVIEWS\nDescription: Where appropriate, the relevant entities shall carry out post-incident reviews after recovery from incidents. The post-incident reviews shall identify, where possible, the root cause of the incident and result in documented lessons learned to reduce the occurrence and consequences of future incidents.\nRationale: N/A\nAudit: N/A\nRemediation: - Conduct root cause analysis and identify the root cause of the incident, where possible. - Identify contributing factors and areas for improvement in incident detection, response and recovery processes. - Investigate significant incidents and write final incident reports, including actions taken and recommendations to mitigate future occurrence of this type of incident. - Document lessons learnt, accompanied by recommendations and their owners, based on logs from incident response referred to in point 3.5.4 of the Annex to the regulation. - Share any relevant findings in the post-incident review with affected stakeholders, for example suppliers, service providers, free and open source component maintainers.",
    "metadata": {
      "id": "ENISA-3.6.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "POST-INCIDENT REVIEWS"
    }
  },
  {
    "page_content": "Title: POST-INCIDENT REVIEWS\nDescription: The relevant entities shall ensure that post-incident reviews contribute to improving their approach to network and information security, to risk treatment measures and to incident handling, detection and response procedures.\nRationale: N/A\nAudit: N/A\nRemediation: - Analyse the post-incident review findings to identify gaps and weaknesses in the entity’s network and information security status. - Make sure that the identified gaps and weaknesses feed back to the risk assessment and risk treatment plan (Annex to the regulation, point 2.1). - Assess whether existing risk treatment measures were effective in preventing or mitigating the incident. - Document the findings and lessons learnt from each post-incident review comprehensively. - Consider whether information security requirements have been met throughout the handling of a cybersecurity incident or whether measures may need to be taken to restore them (e.g. resetting passwords for emergency administrative access).",
    "metadata": {
      "id": "ENISA-3.6.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "POST-INCIDENT REVIEWS"
    }
  },
  {
    "page_content": "Title: POST-INCIDENT REVIEWS\nDescription: The relevant entities shall review at planned intervals if incidents led to post-incident reviews.\nRationale: N/A\nAudit: N/A\nRemediation: - Conduct an annual review or a review after significant incidents, to determine if an incident has led to a post-incident review.",
    "metadata": {
      "id": "ENISA-3.6.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "6 POST-INCIDENT REVIEWS",
      "category_l2": "POST-INCIDENT REVIEWS"
    }
  },
  {
    "page_content": "Title: BUSINESS CONTINUITY AND DISASTER RECOVERY PLAN\nDescription: For the purpose of Article 21, point (c) of Directive (EU) 2022/2555, the relevant entities shall lay down and maintain a business continuity and disaster recovery plan to apply in the case of incidents.\nRationale: N/A\nAudit: N/A\nRemediation: - Take into account industry-recognised standards when developing the business continuity ( 35) and disaster recovery plan. - Create a list of natural disasters (e.g. hurricane, fire, flooding) and other occurrences (e.g. human error) that could affect the services together with a list of disaster recovery capabilities (e.g. backups, tests, recovery objectives, etc.).",
    "metadata": {
      "id": "ENISA-4.1.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "BUSINESS CONTINUITY AND DISASTER RECOVERY PLAN"
    }
  },
  {
    "page_content": "Title: BUSINESS CONTINUITY AND DISASTER RECOVERY PLAN\nDescription: The relevant entities’ operations shall be restored according to the business continuity and disaster recovery plan. The plan shall be based on the results of the risk assessment carried out pursuant to point 2.1 and shall include, where appropriate, the following: (a) purpose, scope and audience; (b) roles and responsibilities; (c) key contacts and (internal and external) communication channels; (d) conditions for plan activation and deactivation; (e) order of recovery for operations; (f) recovery plans for specific operations, including recovery objectives; (g) required resources, including backups and redundancies; (h) restoring and resuming activities from temporary measures.\nRationale: N/A\nAudit: N/A\nRemediation: - Keep logs of activation and execution of the business continuity plan, including: For example, - ISO 22301:2019 - Security and resilience — Business continuity management systems — Requirements, - ISO 22313:2020 - Security and resilience — Business continuity management systems — on the use of ISO 2230 and - NIST SP 800-34 Rev. 1 – Contingency Planning Guide for Federal Information Systems. - decisions taken; - steps followed; and - final recovery time. - Determine the order of recovery based on criteria, including (indicative, non-exhaustive list): - the asset classification level; - the importance of the service for the entity; - dependencies (services or assets that are essential for others are restored first); - recovery objectives (Annex to the regulation, point 4.1.3); - resource availability; and - regulatory requirements. - Conduct capacity planning so that necessary capacity for information processing, telecommunications and environmental support exists after business continuity plan activation. - Consider primary and alternate telecommunications service providers, section 13.1, to properly maintain disaster recovery plans (for the services provided). - For remote work, employees handling critical operations should:  have access to backup internet solutions (e.g. mobile broadband, tethering capabilities) and  participate in regular testing of failover options, including VPN access and voice communications (e.g. VoIP or cloud telephony) over backup networks. - Prepare for recovery and restoration of services after a disaster by identifying measures such as: - failover sites in other regions; - backups of data with high criticality to remote locations; and - tested restore procedures with regular validation cycles. - Make sure that third party services (e.g. hot site) will be available in case of disaster, where appropriate. - Implement advanced measures for disaster recovery capabilities, where appropriate, for example: - full redundancy; - failover mechanisms; and - alternative site.",
    "metadata": {
      "id": "ENISA-4.1.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "BUSINESS CONTINUITY AND DISASTER RECOVERY PLAN"
    }
  },
  {
    "page_content": "Title: BUSINESS CONTINUITY AND DISASTER RECOVERY PLAN\nDescription: The relevant entities shall carry out a business impact analysis to assess the potential impact of severe disruptions to their business operations and shall, based on the results of the business impact analysis, establish continuity requirements for the network and information systems.\nRationale: N/A\nAudit: N/A\nRemediation: - Based on the results of the BIA and risk assessment, the entity should establish appropriate recovery - bjectives, referred to in point 4.1.2 (f) of the Annex to the regulation (indicative, non-exhaustive list): - Recovery time objectives (RTOs) to determine the maximum amount of time allowed for the recovery of business resources and functions (e.g. information and communications technology (ICT) systems and processes, respectively) after a disaster occurs, for example maximum downtime of the entity’s website, enterprise resource planning (ERP) system or email system. - Recovery point objective (RPO) to determine how much data it is acceptable for specific ICT activities or applications to lose. Typically, they are measured in maximum time needed to recover data without causing unacceptable, according to the risk assessment, damage to the entity’s activities, for example maximum recovery time for an e-commerce website, an ERP system or an email server. - Service delivery objective (SDO) to determine the minimum level of performance that needs to be reached by business functions during the alternate processing mode. An indicative and nonexhaustive list of examples includes:  the percentage of inbound calls to be answered by a call centre within a specific timeframe;  the level of availability of ordering and payment systems of an e-commerce website within a specific timeframe;  the restoration time for accessing essential shared folders via a cloud file access system; and  the timeframe within which the full functionality of the remote work infrastructure is restored. - Maximum acceptable outage (MAO) or maximum tolerable period of disruption (MTPD) to determine the time it would take for the potential impacts of not providing a product/service or performing an activity to become unacceptable or significant, in accordance with the risk assessment. Typically they are longer than RTOs. MAOs focus on service availability while RPOs focus on data loss. An indicative and non-exhaustive list of examples:  the period of time beyond which the customer service would be severely impacted and reputation risk increases quickly;  the longest period of time that extended outage of an e-commerce website might result to major loss of sales and customer trust;  the longest period of time that shared access to project files may halt collaboration or decision-making in case that data is stored in cloud; and  the maximum acceptable outage for remote work infrastructure beyond which business functions are significantly impaired and productivity losses begin to escalate. - RTOs, RPOs and SDOs may be used to determine backup and redundancy procedures. Consider the following standards: ISO/TS 22317:2021 and NIST special publication 800-34. For definitions of terms, refer to ISO 22300:2021. - Document disaster recovery plan, taking into account: - the RTOs, RPOs and SDOs; and - compliance with applicable regulations and legislation.",
    "metadata": {
      "id": "ENISA-4.1.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "BUSINESS CONTINUITY AND DISASTER RECOVERY PLAN"
    }
  },
  {
    "page_content": "Title: BUSINESS CONTINUITY AND DISASTER RECOVERY PLAN\nDescription: The business continuity plan and disaster recovery plan shall be tested, reviewed and, where appropriate, updated at planned intervals and following significant incidents or significant changes to operations or risks. The relevant entities shall ensure that the plans incorporate lessons learnt from such tests.\nRationale: N/A\nAudit: N/A\nRemediation: - Test, review and, if necessary, update the business continuity and disaster recovery plans at least annually. - Choose and combine method(s) to test the business continuity and disaster recovery plans, such as: - alternative locations for personnel; - disaster recovery locations – hot sites; - digital twins; - simulations; - table top exercises. - Test business continuity and disaster recovery plans regularly, taking into account: - change logs; - past incidents; and - results of previous tests. - Where appropriate, test the disaster recovery plan at an alternate processing site to: - familiarize related personnel with the facility and available resources; and - evaluate the capabilities of the alternate processing site to support operations. - Test data centre infrastructure for: - availability; - auto failover; - power failover between power providers and/or power provider to backup (for example generators or batteries); and - resilience to maintain service to customers. - Define full recovery and reconstitution of the information system to a known state as part of the disaster recovery plan testing. - Update business continuity and disaster recovery plans and related measures based on: - change logs; - past incidents; - documented results of the continuity of operations test activities; and - records of individual training activities. - Review change logs and documented results from past tests on business continuity and disaster recovery plans to ensure that the plans incorporate lessons learnt from such tests. - Review and, if necessary, update roles and responsibilities. - Review dependent third parties’ disaster recovery plans to ensure that the plans meet entity’s business continuity requirements. - Communicate changes to business continuity and disaster recovery plans to related key personnel.",
    "metadata": {
      "id": "ENISA-4.1.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "BUSINESS CONTINUITY AND DISASTER RECOVERY PLAN"
    }
  },
  {
    "page_content": "Title: BACKUP AND REDUNDANCY MANAGEMENT\nDescription: The relevant entities shall maintain backup copies of data and provide sufficient available resources, including facilities, network and information systems and staff, to ensure an appropriate level of redundancy.\nRationale: N/A\nAudit: N/A\nRemediation: - Consider whether to invest in own redundancy or to engage third parties, for example cloud providers, to provide such redundancy, in alignment with the BIA (Annex to the regulation, point 4.1.3).",
    "metadata": {
      "id": "ENISA-4.2.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "BACKUP AND REDUNDANCY MANAGEMENT"
    }
  },
  {
    "page_content": "Title: BACKUP AND REDUNDANCY MANAGEMENT\nDescription: Based on the results of the risk assessment carried out pursuant to point 2.1 and the business continuity plan, the relevant entities shall lay down backup plans which include the following: (a) recovery times; (b) assurance that backup copies are complete and accurate, including configuration data and data stored in cloud computing service environment; (c) storing backup copies (online or offline) in a safe location or locations, which are not in the same network as the system and are at sufficient distance to escape any damage from a disaster at the main site; (d) appropriate physical and logical access controls to backup copies, in accordance with the asset classification level; (e) restoring data from backup copies; (f) retention periods based on business and regulatory requirements.\nRationale: N/A\nAudit: N/A\nRemediation: - Recovery times should not exceed the recovery objectives referred to in 4.1.2 (f) of the Annex to the regulation. - Concerning retention periods consider what is referred to in point 3.2.5 of the Annex to the regulation. - If an entity engages third parties to ensure an appropriate level of redundancy, it should be clearly decided whether it is the entity's responsibility to compile the backup plans or if the third parties have any involvement in the process.",
    "metadata": {
      "id": "ENISA-4.2.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "BACKUP AND REDUNDANCY MANAGEMENT"
    }
  },
  {
    "page_content": "Title: BACKUP AND REDUNDANCY MANAGEMENT\nDescription: The relevant entities shall perform regular integrity checks on the backup copies.\nRationale: N/A\nAudit: N/A\nRemediation: - Check the integrity of the backup copies. An indicative, non-exhaustive list of good practices is the following: - use checksums or hashing algorithms to verify that the data in your backups matches the original data (section 9.2); - implement automated scripts to run these checks regularly, reducing the risk of human error; - schedule regular tests to restore data from backups to ensure they are complete, functional and validated by business users to confirm the accuracy and usability of the restored data; - test various recovery scenarios, including full system restores and individual file recoveries, to ensure all aspects of your backup system are reliable; and - consider using cloud storage solutions for off-site backups, which often include built-in integrity checks and redundancy.",
    "metadata": {
      "id": "ENISA-4.2.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "BACKUP AND REDUNDANCY MANAGEMENT"
    }
  },
  {
    "page_content": "Title: BACKUP AND REDUNDANCY MANAGEMENT\nDescription: Based on the results of the risk assessment carried out pursuant to point 2.1 and the business continuity plan, the relevant entities shall ensure sufficient availability of resources by at least partial redundancy of the following: (a) network and information systems; (b) assets, including facilities, equipment and supplies; (c) personnel with the necessary responsibility, authority and competence; (d) appropriate communication channels.\nRationale: N/A\nAudit: N/A\nRemediation: - Define minimum resources needed to ensure at least partial redundancy for each of points (a), (b), (c) and (d). These may include the following: - network and information systems: one or more of the following (indicative, non-exhaustive list):  multiple internet service providers,  load balancing,  mirrored servers,  virtualisation,  redundant array of independent disks; - assets: one or more of the following (indicative, non-exhaustive list):  shared workspaces,  backup locations,  spare equipment,  multiple suppliers for the same categories of products; - personnel: one or more of the following (indicative, non-exhaustive list):  job rotation,  backup assignments,  emergency drills; - multiple communication platforms, for example social media, messaging apps and email; and - multiple methods to power a site, either through multiple electrical providers or with a combination - f electrical providers and backup mechanisms, such as generators.",
    "metadata": {
      "id": "ENISA-4.2.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "BACKUP AND REDUNDANCY MANAGEMENT"
    }
  },
  {
    "page_content": "Title: BACKUP AND REDUNDANCY MANAGEMENT\nDescription: Where appropriate, the relevant entities shall ensure that monitoring and adjustment of resources, including facilities, systems and personnel, is duly informed by backup and redundancy requirements.\nRationale: N/A\nAudit: N/A\nRemediation: - Decisions about resource allocation and adjustments should be guided by the need for backups and redundancy. To this end, the entity might consider one or more of the following (indicative, non-exhaustive list): - prioritisation of resources based on the results of the risk analysis; - partial redundancy; - diverse backup locations; and - continuous monitoring of the resources where redundancy is necessary.",
    "metadata": {
      "id": "ENISA-4.2.5",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "BACKUP AND REDUNDANCY MANAGEMENT"
    }
  },
  {
    "page_content": "Title: BACKUP AND REDUNDANCY MANAGEMENT\nDescription: The relevant entities shall carry out regular testing of the recovery of backup copies and redundancies to ensure that, in recovery conditions, they can be relied upon and cover the copies, processes and knowledge to perform an effective recovery. The relevant entities shall document the results of the tests and, where needed, take corrective action.\nRationale: N/A\nAudit: N/A\nRemediation: - Tailor the frequency of the backup checks to the data criticality based on the risk assessment (section 2.1). As an example: - Data with high criticality might be checked on a weekly basis. - Data with moderate and low criticality might be checked on a monthly basis. - Significant changes should be checked immediately after the change. - Make sure that the issues and lessons learnt from exercises are addressed by the responsible people and that the relevant processes and systems are updated accordingly. - Involve suppliers and other third parties, such as business partners or customers in tests.",
    "metadata": {
      "id": "ENISA-4.2.6",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "BACKUP AND REDUNDANCY MANAGEMENT"
    }
  },
  {
    "page_content": "Title: CRISIS MANAGEMENT\nDescription: The relevant entities shall put in place a process for crisis management.\nRationale: N/A\nAudit: N/A\nRemediation: - Take into account industry-recognised standards when developing the crisis management process. - Be aware that each crisis may be different and further analysis may be required on an ad hoc basis. - Consider the various aspects (e.g. technical, operational, communication and remediation) of crisis management, including processes, roles and responsibilities. Additionally, consider: - ISO 22361:2022, Security and resilience – Crisis management – Guidelines; - Best Practices for Cyber Crisis Management, - NIST Special Publication 800-61 Revision 2. - Because the escalation of an incident to crisis status depends on an entity’s risk appetite and incident handling capabilities, the entity should define criteria on when a crisis is declared. This may refer to incidents that cause serious impact, beyond a certain threshold of tolerance. These criteria may include the following (indicative and non-exhaustive list): - the incident poses significant risk to critical assets or operations with high criticality, for example high-severity incidents (e.g. data breaches involving sensitive information); - the incident disrupts business operations significantly, for example prolonged downtime, widespread loss of services or significant impact on customer service; - the breadth of the incident, that is, whether it affects multiple systems, departments or geographic locations, indicating a wider threat; - the potential impact on the entity’s reputation – incidents that could lead to public scrutiny or loss - f customer trust should be escalated; - the potential impact of the cybersecurity incident on the confidentiality, integrity, authenticity and availability of data; - the sophistication and motivations of the threat actors involved. Incidents linked to advanced persistent threats or organised cybercrime may require a higher-level response, beyond the capabilities of the entity; - the potential to escalate further (e.g. if vulnerabilities could be exploited again or if malware is spreading).",
    "metadata": {
      "id": "ENISA-4.3.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "CRISIS MANAGEMENT"
    }
  },
  {
    "page_content": "Title: CRISIS MANAGEMENT\nDescription: The relevant entities shall ensure that the crisis management process addresses at least the following elements: (a) roles and responsibilities for personnel and, where appropriate, suppliers and service providers, specifying the allocation of roles in crisis situations, including specific steps to follow; (b) appropriate communication means between the relevant entities and relevant competent authorities; (c) application of appropriate measures to ensure the maintenance of network and information system security in crisis situations. For the purpose of point (b), the flow of information between the relevant entities and relevant competent authorities shall include both obligatory communications, such as incident reports and related timelines and non-obligatory communications.\nRationale: N/A\nAudit: N/A\nRemediation: - For crisis communication, consider (indicative, non-exhaustive list): - legal obligations for communication, such as timing of communication, in particular referring to requirements for notification; - how information will be disseminated to internal and external stakeholders (employees, customers, direct suppliers and service providers, emergency services, etc.) during a crisis; - templates for communication; - communication channels to be used for each type of stakeholder, considering that: According to ISO 22361, a crisis is an ‘abnormal or extraordinary event or situation which threatens an organisation or community and requires a strategic, adaptive and timely response in order to preserve its viability and integrity’.  internal and external stakeholders may use different communication channels;  normal communication channels might not be safe in crisis mode;  channels used to notify and communicate with competent authorities should also be indicated; - up-to-date contact information for internal and external stakeholders.",
    "metadata": {
      "id": "ENISA-4.3.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "CRISIS MANAGEMENT"
    }
  },
  {
    "page_content": "Title: CRISIS MANAGEMENT\nDescription: The relevant entities shall implement a process for managing and making use of information received from the CSIRTs or, where applicable, the competent authorities, concerning incidents, vulnerabilities, threats or possible mitigation measures.\nRationale: N/A\nAudit: N/A\nRemediation: - Implement a process for managing and making use of information received from the CSIRTs. Consider the following steps (indicative, non-exhaustive list): - designate a point of contact with the CSIRT; - ensure that the point of contact has sufficient knowledge concerning incidents and threat intelligence. - classify incoming information into categories such as incidents, vulnerabilities, threats and mitigation measures. - assign priority levels based on severity and potential impact on the entity, if the information is relevant or applicable - have the CSIRT contact point review the information for relevance and urgency. - validate information against internal logs, threat intelligence feeds and existing security policies. - for vulnerabilities and threats, if applicable, collaborate with relevant teams (IT, security, - perations) to develop a mitigation strategy; - update or create incident response plans based on the nature of the threats or incidents reported in accordance with point 3.5 of the Annex to the regulation. - where appropriate, implement the mitigation measures and communicate with the relevant stakeholders in accordance with point 3.5 of the Annex to the regulation. - share insights and feedback on incidents and mitigations with the CSIRT on a voluntary basis.",
    "metadata": {
      "id": "ENISA-4.3.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "CRISIS MANAGEMENT"
    }
  },
  {
    "page_content": "Title: CRISIS MANAGEMENT\nDescription: The relevant entities shall test, review and, where appropriate, update the crisis management plan on a regular basis or following significant incidents or significant changes to operations or risks.\nRationale: N/A\nAudit: N/A\nRemediation: - Test the crisis management process annually. - Test the crisis management process through, for example, an exercise or simulation, by (indicative, nonexhaustive list): - taking into account past crisis situations; - comparing the results of the tests to the objectives defined, for instance the recovery objectives in point 4.1.2 (f) of the Annex to the regulation (e.g. RTOs, RPOs and SDOs); and - using the results of the comparison to update and improve the crisis management procedure. - Review and update, if necessary, the crisis management process after a test or following significant incidents or significant changes to operations or risks. - Review and update the policy on the security of network and information systems and crisis management - rganisational measures after a test or following significant incidents or significant changes to operations - r risks.",
    "metadata": {
      "id": "ENISA-4.3.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 CRISIS MANAGEMENT",
      "category_l2": "CRISIS MANAGEMENT"
    }
  },
  {
    "page_content": "Title: SUPPLY CHAIN SECURITY POLICY\nDescription: For the purpose of Article 21, point (d) of Directive (EU) 2022/2555, the relevant entities shall establish, implement and apply a supply chain security policy which governs the relations with their direct suppliers and service providers to mitigate the identified risks to the security of network and information systems. In the supply chain security policy, the relevant entities shall identify their role in the supply chain and communicate it to their direct suppliers and service providers.\nRationale: N/A\nAudit: N/A\nRemediation: - Take into account industry-recognised standards or good practices when developing the supply chain policy. - The role of a supplier or service provider might be one or more of the following: - ICT supplier (including software and hardware supplier), - Manufacturer, - managed service provider, - managed security service provider and - cloud computing provider. - In the case of free and open source software (FOSS), communities and projects that openly develop, maintain and distribute software may not be considered direct suppliers or service providers where no contractual relationship exists between the relevant entity and the open source project, beyond adherence to a standardised copyright licence, or where the contractual relationship is with an open source software steward (Regulation 2024/2847, Article 3 ‘provides support on a sustained basis for the development and ensures the viability of those products’).",
    "metadata": {
      "id": "ENISA-5.1.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 DIRECTORY OF SUPPLIERS AND SERVICE PROVIDERS",
      "category_l2": "SUPPLY CHAIN SECURITY POLICY"
    }
  },
  {
    "page_content": "Title: SUPPLY CHAIN SECURITY POLICY\nDescription: As part of the supply chain security policy referred to in point 5.1.1, the relevant entities shall lay down criteria to select and contract suppliers and service providers. Those criteria shall include the following: (a) the cybersecurity practices of the suppliers and service providers, including their secure development procedures; In addition, consider the following: - ISO/IEC 27036-1:2021, Cybersecurity – Supplier relationships Part 1: Overview and concepts; - ISO/IEC 27036-2:2022, Cybersecurity – Supplier relationships Part 2: Requirements; - NIST SP 800-161 Rev. 1, ‘Cybersecurity supply chain risk management practices for systems and organizations’, - , Good Practices for Supply Chain Cybersecurity, The list aligns with the draft EU ICT Supply Chain Toolbox from the NIS Cooperation Group workstream on supply chain, as of February 2025. TECHNICAL IMPLEMENTATION\nRationale: N/A\nAudit: N/A\nRemediation: (b) the ability of the suppliers and service providers to meet cybersecurity specifications set by the relevant entities; (c) the overall quality and resilience of ICT products and ICT services and the cybersecurity risk-management measures embedded in them, including the risks and classification level of the ICT products and ICT services; (d) the ability of the relevant entities to diversify sources of supply and limit vendor lock-in, where applicable. - Consider criteria such as: - the legal jurisdiction of the supplier or service provider, for example whether the supplier is regulated under the NIS2 Directive or the Cyber Resilience Act and in which jurisdiction(s); - if available, compliance statements from the supplier in relation to the NIS2 Directive; - the corporate ownership of the supplier or service provider; - the supplier’s or service provider’s ability to ensure supply (e.g. size, reliance on other suppliers - r service providers and degree of control over its own supply chain); - the cybersecurity practices of the supplier or service provider, and whether adequate prioritisation is given to cybersecurity practices, attested by:  industry standard certifications for cybersecurity;  vendor risk-management software reports or other provider assessment reports (e.g. Standardized Information Gathering, vendor security assessment or consensus assessment initiative questionnaire), if available; - notices or advice issued by national authorities on the selection of suppliers or service providers, if available; - the sensitivity of the use of the products and services acquired; - the supplier or service provider’s history in relation to cybersecurity events and breaches; - the possibility of vendor lock-in, if the supplier or service provider is selected. Parameters to consider are the use of open and interoperable standards, the use of open data formats, existing contracts with the supplier or service provider, the use of proprietary software features, etc.",
    "metadata": {
      "id": "ENISA-5.1.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 DIRECTORY OF SUPPLIERS AND SERVICE PROVIDERS",
      "category_l2": "SUPPLY CHAIN SECURITY POLICY"
    }
  },
  {
    "page_content": "Title: SUPPLY CHAIN SECURITY POLICY\nDescription: When establishing their supply chain security policy, relevant entities shall take into account the results of the coordinated security risk assessments of critical supply chains carried out in accordance with Article 22 of Directive (EU) 2022/2555, where applicable.\nRationale: N/A\nAudit: N/A\nRemediation: - Take into account any recommendations or on supply chain security, published by the NIS Cooperation Group, established by the NIS2 Directive, Article 14 ( 42) and by the national competent authorities. ‘NIS Cooperation Group’,",
    "metadata": {
      "id": "ENISA-5.1.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 DIRECTORY OF SUPPLIERS AND SERVICE PROVIDERS",
      "category_l2": "SUPPLY CHAIN SECURITY POLICY"
    }
  },
  {
    "page_content": "Title: SUPPLY CHAIN SECURITY POLICY\nDescription: Based on the supply chain security policy and taking into account the results of the risk assessment carried out in accordance with point 2.1. of this Annex, the relevant entities shall ensure that their contracts with the suppliers and service providers specify, where appropriate through service level agreements, the following, where appropriate: (a) cybersecurity requirements for the suppliers or service providers, including requirements as regards the security in acquisition of ICT services or ICT products set out in point 6.1.; (b) requirements regarding awareness, skills and training and where appropriate certifications, required from the suppliers’ or service providers’ employees; (c) requirements regarding the verification of the background of the suppliers’ and service providers’ employees; (d) an obligation on suppliers and service providers to notify, without undue delay, the relevant entities of incidents that present a risk to the security of the network and information systems of those entities; (e) the right to audit or right to receive audit reports; (f) an obligation on suppliers and service providers to handle vulnerabilities that present a risk to the security of the network and information systems of the relevant entities; (g) requirements regarding subcontracting and, where the relevant entities allow subcontracting, cybersecurity requirements for subcontractors in accordance with the cybersecurity requirements referred to in point (a); (h) obligations on the suppliers and service providers at the termination of the contract, such as retrieval and disposal - f the information obtained by the suppliers and service providers in the exercise of their tasks.\nRationale: N/A\nAudit: N/A\nRemediation: - Ensure that, in all relevant new and renewed contracts, the requirements from point 5.1.4 of the Annex to the regulation are included. - When dealing with large suppliers and service providers consider one or more of the following measures (indicative, non-exhaustive list): - collective bargaining by teaming up with similar size organisations for purchasing products or services in bulk; - representation by an association of which the entity is a member of; - legal advice for reviewing and negotiating a contract; - negotiating specific clauses such as exit, pricing and SLAs; - suppliers that publicly publish their security, privacy or reliability commitments; - providers with standard certifications (e.g. ISO 27001, SOC 2); - trusted platforms or marketplaces that vet suppliers (e.g. app stores, SaaS directories, partner networks); - contract templates or free legal checklists from small business associations, NGOs or government sites; - tools/services that allow easy data export, monthly payments or no lock-in; - avoiding long-term commitments or vendor lock-in without clear exit strategies; and The entity remains fully accountable for the integrity, availability and confidentiality of services provided by suppliers. SLAs must be clearly defined, actively managed and aligned with the entity’s business continuity, security and compliance obligations. - a short list of alternatives in case the supplier becomes unavailable.",
    "metadata": {
      "id": "ENISA-5.1.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 DIRECTORY OF SUPPLIERS AND SERVICE PROVIDERS",
      "category_l2": "SUPPLY CHAIN SECURITY POLICY"
    }
  },
  {
    "page_content": "Title: SUPPLY CHAIN SECURITY POLICY\nDescription: The relevant entities shall take into account the elements referred to in point 5.1.2 and 5.1.3. as part of the selection process of new suppliers and service providers, as well as part of the procurement process referred to in point 6.1.\nRationale: N/A\nAudit: N/A\nRemediation: - Perform a risk analysis before entering into any agreement with suppliers and service providers related to information security, taking into account the elements referred to in point 5.1.2 and 5.1.3, where appropriate.",
    "metadata": {
      "id": "ENISA-5.1.5",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 DIRECTORY OF SUPPLIERS AND SERVICE PROVIDERS",
      "category_l2": "SUPPLY CHAIN SECURITY POLICY"
    }
  },
  {
    "page_content": "Title: SUPPLY CHAIN SECURITY POLICY\nDescription: The relevant entities shall review the supply chain security policy and monitor, evaluate and, where necessary, act upon changes in the cybersecurity practices of suppliers and service providers, at planned intervals and when significant changes to operations or risks or significant incidents related to the provision of ICT services or having impact - n the security of the ICT products from suppliers and service providers occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Review the supply chain policy at least annually. - Create and maintain a process to monitor suppliers and service providers over the life cycle.",
    "metadata": {
      "id": "ENISA-5.1.6",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 DIRECTORY OF SUPPLIERS AND SERVICE PROVIDERS",
      "category_l2": "SUPPLY CHAIN SECURITY POLICY"
    }
  },
  {
    "page_content": "Title: SUPPLY CHAIN SECURITY POLICY\nDescription: For the purpose of point 5.1.6., the relevant entities shall: (a) regularly monitor reports on the implementation of the service level agreements, where applicable; (b) review incidents related to ICT products and ICT services from suppliers and service providers; (c) assess the need for unscheduled reviews and document the findings in a comprehensible manner; (d) analyse the risks presented by changes related to ICT products and ICT services from suppliers and service providers and, where appropriate, take mitigating measures in a timely manner.\nRationale: N/A\nAudit: N/A\nRemediation: - Set up a regular review (e.g. as part of a regular supplier meeting) and follow up on deviations from the agreed SLAs. - Define and assign responsibilities regarding maintenance, operation and ownership of assets. - Make sure that monitoring encompasses periodic reassessment of supplier and service provider compliance, and monitor supplier and service provider release notes. - Periodically ensure that product configuration is aligned with vendor recommendations, with increasing frequency as products age. - Keep track of security incidents related to or caused by suppliers and service providers as they might trigger an unscheduled review of the suppliers and service providers. Other circumstances for such an unscheduled review include to suppliers and service providers (indicative, non-exhaustive list): - material changes in their operations; - changes in their risk exposure; - failure to meet their contractual obligations; and - emergence of new threats or vulnerabilities affecting the provided ICT products or services. - Monitoring frequency should be aligned with supply chain policy (Annex to the regulation, point 5.1.1) and the review of the secure acquisition of ICT services, systems or products processes (Annex to the regulation, point 6.1.3).",
    "metadata": {
      "id": "ENISA-5.1.7",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 DIRECTORY OF SUPPLIERS AND SERVICE PROVIDERS",
      "category_l2": "SUPPLY CHAIN SECURITY POLICY"
    }
  },
  {
    "page_content": "Title: SECURITY IN ACQUISITION OF ICT SERVICES OR ICT PRODUCTS\nDescription: For the purpose of Article 21, point (e) of Directive (EU) 2022/2555, the relevant entities shall set and implement processes to manage risks stemming from the acquisition of ICT services or ICT products for components that are critical for the relevant entities’ security of network and information systems, based on the risk assessment carried out pursuant to point 2.1, from suppliers or service providers throughout their life cycle.\nRationale: N/A\nAudit: N/A\nRemediation: - Integrate cybersecurity as a permanent component of the purchase process by dedicating a specific section to addressing it. This includes any acquisition processes for selecting FOSS. - Document the process for secure acquisition of ICT services, systems or products and describe relevant procedures that support the process. - Take into account industry-recognised standards when developing the process.",
    "metadata": {
      "id": "ENISA-6.1.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "SECURITY IN ACQUISITION OF ICT SERVICES OR ICT PRODUCTS"
    }
  },
  {
    "page_content": "Title: SECURITY IN ACQUISITION OF ICT SERVICES OR ICT PRODUCTS\nDescription: For the purpose of point 6.1.1., the processes referred to in point 6.1.1. shall include: (a) security requirements to apply to the ICT services or ICT products to be acquired; (b) requirements regarding security updates throughout the entire lifetime of the ICT services or ICT products or replacement after the end of the support period; (c) information describing the hardware and software components used in the ICT services or ICT products; (d) information describing the implemented cybersecurity functions of the ICT services or ICT products and the configuration required for their secure operation; (e) assurance that the ICT services or ICT products comply with the security requirements according to point (a); (f) methods for validating that the delivered ICT services or ICT products are compliant to the stated security requirements, as well as documentation of the results of the validation. See section 5.1 (), for additional\nRationale: N/A\nAudit: N/A\nRemediation: - n the use of free and open source software supply chain. In addition, to those mentioned in the mapping table at the end of this section, consider the following: - services; - Department of the Environment, Climate and Communications, ‘Guidelines on cyber security specifications (ICT procurement for public service bodies)’, - The security requirements must include at least the means to detect, monitor and protect against unauthorized changes of software and information. - Ensure that support contracts cover the system life cycle and obsolescence management requirements, including the date until which the system must be supported and include continuous alerting. - Favour vendors that provide clear end-of-life information and that plan to provide separate critical security fixes. - Make sure that tenders request that suppliers or service providers provide tested solutions for security issues in legacy or new technologies free of charge and as soon as a relevant security issue becomes known. - Consider also the following information describing implemented cybersecurity functions such as (indicative, non-exhaustive list): - the potential risks that could arise from acquiring the specific ICT service, system or product. This might involve penetration testing to identify threats, vulnerabilities and the potential impact on the entity’s operations; - potential security tools that already need to be in place, for example a firewall, an intrusion detection system, a SIEM or a EDR/XDR; - a specific security mechanism that might need to be in place, such as a specific encryption algorithm or a particular access control mechanism (e.g. MFA); - cybersecurity standards for the ICT service, system or product that the entity needs to comply with; - where appropriate, the required assurance level of the ICT product, system or service and the existence of a relevant certificate following the European Cybersecurity Scheme for ICT products based on Common Criteria (EUCC). - Consider evaluating the security of an ICT service, system or product before acquisition. ), for additional",
    "metadata": {
      "id": "ENISA-6.1.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "SECURITY IN ACQUISITION OF ICT SERVICES OR ICT PRODUCTS"
    }
  },
  {
    "page_content": "Title: SECURITY IN ACQUISITION OF ICT SERVICES OR ICT PRODUCTS\nDescription: The relevant entities shall review and, where appropriate, update the processes at planned intervals and when significant incidents occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Review the processes for secure acquisition of ICT services, systems or products, and the procedures based on them, at least annually. - Review logs or records of all changes made to the processes for secure acquisition of ICT services, systems or products, and the procedures based on them, including details of the changes, approvals and implementation dates. - Align the tenders and contracts with the entity’s supply chain security policy (Annex to the regulation, point 5.1). - For ICT services, systems or products that are not provided by a supplier (e.g. open source projects), entities should share relevant results from internal assessments with them.",
    "metadata": {
      "id": "ENISA-6.1.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "SECURITY IN ACQUISITION OF ICT SERVICES OR ICT PRODUCTS"
    }
  },
  {
    "page_content": "Title: SECURE DEVELOPMENT LIFE CYCLE\nDescription: Before developing a network and information system, including software, the relevant entities shall lay down rules for the secure development of network and information systems and apply them when developing network and information systems in-house or when outsourcing the development of network and information systems. The rules shall cover all development phases, including specification, design, development, implementation and testing.\nRationale: N/A\nAudit: N/A\nRemediation: - Take into account the entity’s policies and norms (if available) and industry-recognised standards when developing the rules for the secure development of network and information systems.",
    "metadata": {
      "id": "ENISA-6.2.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "SECURE DEVELOPMENT LIFE CYCLE"
    }
  },
  {
    "page_content": "Title: SECURE DEVELOPMENT LIFE CYCLE\nDescription: For the purpose of point 6.2.1., the relevant entities shall: (a) carry out an analysis of security requirements at the specification and design phases of any development or acquisition project undertaken by the relevant entities or on behalf of those entities; (b) apply principles for engineering secure systems and secure coding principles to any information system development activities such as promoting cybersecurity-by-design, zero-trust architectures; (c) lay down security requirements regarding development environments; In addition, to those mentioned in the mapping table at the end of this section, consider the following: - ‘OWASP ASVS (Application Security Verification Standard)’, , as updated from time to time. - ISO/IEC 27034 family, Information technology - Security techniques - Application security. - NIST SP 800-53, as updated from time to time. TECHNICAL IMPLEMENTATION\nRationale: N/A\nAudit: N/A\nRemediation: (d) establish and implement security testing processes in the development life cycle; (e) appropriately select, protect and manage security test data; (f) sanitise and anonymise testing data according to the risk assessment carried out pursuant to point 2.1. - A secure software development life cycle (SSDLC) process should be implemented by all entities. However, smaller entities can use a less demanding process such as implementing secure-by-design practices and security-testing processes. - Depending on the type of requirement, the rules for the secure development of software and systems should include appropriate software testing methods (e.g. black-box, ad-hoc testing, static versus dynamic application security testing). - Test security by design at various stages of the secure development of the SSDLC prior to go-live, utilising independent tools and a self-service testing platform throughout the SSDLC. - When real production data - or derived variations of it - is used for testing, ensure that such data is properly sanitised or anonymised. An indicative, non-exhaustive list of techniques: - masking or pseudonymization on fields like names, emails, IDs; - deletion or redaction of identifiers (e.g. personal IDs, birth dates, ZIP codes); and - non-irreversible or one-way anonymisation. - When using Free and Open Source Software components, entities should take into account the voluntary nature of open source projects (see of section 5.1). Where possible, entities should assist the - pen source projects that they depend on in adopting secure systems and secure coding principles (such as introducing SSDLC processes suited to the project’s way of working).",
    "metadata": {
      "id": "ENISA-6.2.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "SECURE DEVELOPMENT LIFE CYCLE"
    }
  },
  {
    "page_content": "Title: CONFIGURATION MANAGEMENT\nDescription: The relevant entities shall take the appropriate measures to establish, document, implement and monitor configurations, including security configurations of hardware, software, services and networks.\nRationale: N/A\nAudit: N/A\nRemediation: - Establish documented processes based on best practices and information security standards. - Maintain and document detailed configuration settings for the following operating procedures (indicative, nonexhaustive list): - processing and handling of information, - backup, - scheduling requirements, including interdependencies with other systems, - handling errors or other exceptional conditions, - system restart and recovery procedures, In addition to the standards in the mapping table, consider the following: - ISO/IEC 20000, which is the international standard for IT service management and consists of 17 parts; - Information Technology Infrastructure Library; - Institute of Electrical and Electronics Engineers 828, Standard for configuration management in systems and software engineering. - cryptographic mechanisms and settings, and - audit trail and system log information. - Consider the following security-related parameters for the configuration settings (indicative, non-exhaustive list): - registry settings, - account, file and directory permission settings, and - settings for functions, ports, protocols, services and remote connections. - Employ automated mechanisms to centrally manage, apply and verify configuration settings for software and hardware, including mobile devices and the entity’s connected vehicles. - Where appropriate, implement a configuration management database to catalogue and classify all configuration items (CIs), including their security attributes (e.g. patch level, firewall rules and encryption status) - Ensure that all network, software and system configurations adhere to established security and operational standards for functions, ports, protocols and services. - Monitor and control changes to the configuration settings in accordance with the entity’s policy on the security - f network and information systems and topic-specific policies and procedures. - Identify software not authorised to run on the information systems. - Where appropriate, regularly review and update software configurations. - Where appropriate, identify software programs authorised to run on the information system. - Employ a deny-all, permit-by-exception policy to allow authorised software to run. - Set up procedures for network service usage to restrict access to necessary services or applications only. - Manage a secure baseline configuration for development and test environments separately from the - perational baseline configuration, where appropriate. - Identify, document and approve any deviations from established configuration settings based on defined exceptions on operational requirements.",
    "metadata": {
      "id": "ENISA-6.3.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "CONFIGURATION MANAGEMENT"
    }
  },
  {
    "page_content": "Title: CONFIGURATION MANAGEMENT\nDescription: For the purpose of point 6.3.1., the relevant entities shall: (a) lay down and ensure security in configurations for their hardware, software, services and networks; (b) lay down and implement processes and tools to enforce the laid down secure configurations for hardware, software, services and networks, for newly installed systems as well as for systems in operation over their lifetime.\nRationale: N/A\nAudit: N/A\nRemediation: - Consider hardening guides/best practices and general cybersecurity principles (e.g. least functionality and least privilege) as a basis for deriving the defined security configurations. - Establish, document and maintain configuration settings respecting the access control policy. - Where applicable, test the configuration before implementation. - Employ security safeguards to detect and respond to unauthorised changes to defined configuration settings. - Establish a configuration management plan containing: - roles, responsibilities and configuration management processes and procedures; - a process for identifying CIs throughout the system development life cycle; and - a process for managing the configuration of the CIs throughout their life cycle. - Protect the configuration management plan from unauthorised disclosure and modification. - Implement enhanced controls, including regular vulnerability scanning, strict configuration hardening, isolation where feasible and continuous monitoring to compensate for products which lack official updates after the end - f supplier support.",
    "metadata": {
      "id": "ENISA-6.3.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "CONFIGURATION MANAGEMENT"
    }
  },
  {
    "page_content": "Title: CONFIGURATION MANAGEMENT\nDescription: The relevant entities shall review and, where appropriate, update configurations at planned intervals or when significant incidents or significant changes to operations or risks occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Review and, where appropriate update configurations at least monthly to ensure that patches have been applied, that the backup has been executed according to the plan and that monitoring is in place to identify and alert to fatal server/device/disk errors without delay. - Regularly produce, keep and review change logs regarding the security configuration of information systems. - Review and update the configurations after major changes (e.g. software updates) and past incidents. - Where feasible, obtain baseline configuration files for key systems and devices to compare against current configurations.",
    "metadata": {
      "id": "ENISA-6.3.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "CONFIGURATION MANAGEMENT"
    }
  },
  {
    "page_content": "Title: CHANGE MANAGEMENT, REPAIRS AND MAINTENANCE\nDescription: The relevant entities shall apply change management procedures to control changes of network and information systems. Where applicable, the procedures shall be consistent with the relevant entities’ general policies concerning change management.\nRationale: N/A\nAudit: N/A\nRemediation: - Take into account industry-recognised and national standards when developing the change management procedures. - Consider the following elements for the procedures (indicative, non-exhaustive list): - request for change, - risk assessment, - criteria for categorisation and prioritisation of changes:  associated requirements for the type and scope of the tests to be carried out and  the approvals to be obtained; - requirements for performing rollbacks; and - documentation of the changes and approval of changes. - The change management procedures may allow different workflows depending on the criticality of the system, the scope of the change and the urgency (e.g. put in place an ‘emergency intervention workflow’). - For each change, record the steps of the procedure followed. - Review and approve changes following the change management procedures, prior to implementing them. - Implement and test change management procedures to make sure that changes to networks and information systems are always done in a predefined way. - Where appropriate, establish a change advisory board (CAB) to oversee and approve changes. The CAB should evaluate change requests based on risk, impact, resource requirements and alignment with business - bjectives. In addition to those mentioned in the mapping table at the end of this section, consider the following: - ISO 21500:2021, Project, programme and portfolio management - Context and concepts; - ISO 21502:2020, Project, programme and portfolio management - on project management.",
    "metadata": {
      "id": "ENISA-6.4.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "CHANGE MANAGEMENT, REPAIRS AND MAINTENANCE"
    }
  },
  {
    "page_content": "Title: CHANGE MANAGEMENT, REPAIRS AND MAINTENANCE\nDescription: The procedures referred to in point 6.4.1. shall be applied for releases, modifications and emergency changes of any software and hardware in operation and changes to the configuration. The procedures shall ensure that those changes are documented and, based on the risk assessment carried out pursuant to point 2.1, tested and assessed in view of the potential impact before being implemented.\nRationale: N/A\nAudit: N/A\nRemediation: - Consider a mandatory integrity check before installing and deploying new software. - Ensure, where appropriate, that changes are done in an authenticated, authorised and non-repudiating manner. - Test and validate changes before they are implemented in operational systems, where applicable. Where appropriate, a security impact analysis may be performed in a separate test environment before implementation in an operational environment. - Take all necessary precautions before making changes (back up images, for instance). - Schedule, perform, document and review records of maintenance and repairs on system components in accordance with the supplier’s specifications and/or the entity’s requirements. - Ensure that changes are only allowed with approved tools and that their execution is documented. - Restrict the use of maintenance tools to authorised personnel only.",
    "metadata": {
      "id": "ENISA-6.4.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "CHANGE MANAGEMENT, REPAIRS AND MAINTENANCE"
    }
  },
  {
    "page_content": "Title: CHANGE MANAGEMENT, REPAIRS AND MAINTENANCE\nDescription: In the event that the regular change management procedures could not be followed due to an emergency, the relevant entities shall document the result of the change and the explanation for why the procedures could not be followed.\nRationale: N/A\nAudit: N/A\nRemediation: - Where appropriate, integrate the pullback scenario into the change management procedures. - Assess the risks from legacy systems and upgrade existing legacy systems to include security mitigating measures in case appropriate security cannot be achieved. - Make sure that regular change control procedures that could not be followed due to an emergency change are applied immediately after the emergency change.",
    "metadata": {
      "id": "ENISA-6.4.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "CHANGE MANAGEMENT, REPAIRS AND MAINTENANCE"
    }
  },
  {
    "page_content": "Title: CHANGE MANAGEMENT, REPAIRS AND MAINTENANCE\nDescription: The relevant entities shall review and, where appropriate, update the procedures at planned intervals and when significant incidents or significant changes to operations or risks.\nRationale: N/A\nAudit: N/A\nRemediation: - Review the change management procedures at least once every two years. - Make sure that the management procedures cover planned and unplanned changes and the development phase, when applicable. - Ensure that the process is not bypassed.",
    "metadata": {
      "id": "ENISA-6.4.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "CHANGE MANAGEMENT, REPAIRS AND MAINTENANCE"
    }
  },
  {
    "page_content": "Title: SECURITY TESTING\nDescription: The relevant entities shall establish, implement and apply a policy and procedures for security testing.\nRationale: N/A\nAudit: N/A\nRemediation: - Take into account industry-recognised standards when developing the testing policy. - Establish and maintain a testing programme appropriate to the entity’s size, complexity and maturity.",
    "metadata": {
      "id": "ENISA-6.5.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "SECURITY TESTING"
    }
  },
  {
    "page_content": "Title: SECURITY TESTING\nDescription: The relevant entities shall: (a) establish, based on the risk assessment carried out pursuant to point 2.1, the need, scope, frequency and type of security tests; (b) carry out security tests according to a documented test methodology, covering the components identified as relevant for secure operation in a risk analysis; (c) document the type, scope, time and results of the tests, including assessment of criticality and mitigating actions for each finding; (d) apply mitigating actions in case of critical findings.\nRationale: N/A\nAudit: N/A\nRemediation: - Make sure that network and information systems undergo continuous testing, particularly in environments utilizing continuous integration / continuous deployment practices. Regular testing should be conducted at setup, after significant upgrades or modifications and following maintenance, to maintain robust security and performance. - Consider a range of security tests (e.g. vulnerability assessments, penetration testing, code review, ethical hacking, bug bounty programmes, cyber attack simulations, red teaming, protocol conformance testing or cyber response exercises) and select the most appropriate one (or more) to test the specific procedure, service or tool over time. - Entity-wide scoped tests should be carried out at planned intervals or when significant incidents or changes - ccur. - Conduct internal and/or external audits throughout the entity’s networks, systems and processes in an ad-hoc manner. - Record evidence while testing. The need, scope, frequency, type and results are to be documented in a manner that is comprehensible to an expert third party. - Use criteria to assess the results of the tests similar to the criteria for performing cybersecurity risk assessments ( on point 2.1.2 of the Annex to the regulation). - Assess, follow up and remediate high-criticality findings with respect to the confidentiality, integrity, authenticity - r availability of the service provided. In addition to the standards in the mapping table, consider the following: - ISO/IEC 27034 series of standards on application security. - OWASP Web Security Testing Guide, - Open Source Security Testing Methodology Manual (OSSTMM), CyberFundamentals, ID.RA-1, Centre for Cyber Security Belgium, 01_e_update_2024.pdf. - Document the assessment of criticality and mitigating actions for each finding. Ensure that risk assessment results and risk treatment plans are updated accordingly (Annex to the regulation, point 2.1). - When testing reveals an underlying security issue in a free and open source component, these findings must be shared with the relevant open source project. If a patch is developed to address the issue, the relevant code should also be shared with the relevant open source project, in a manner suitable for integration. - Where appropriate, any automated security tests written by entities for open source components that they use, should be shared with the relevant open source projects.",
    "metadata": {
      "id": "ENISA-6.5.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "SECURITY TESTING"
    }
  },
  {
    "page_content": "Title: SECURITY TESTING\nDescription: The relevant entities shall review and, where appropriate, update their security testing policies at planned intervals.\nRationale: N/A\nAudit: N/A\nRemediation: - Review the security testing policy and procedures at least once every two years.",
    "metadata": {
      "id": "ENISA-6.5.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "SECURITY TESTING"
    }
  },
  {
    "page_content": "Title: SECURITY PATCH MANAGEMENT\nDescription: The relevant entities shall specify and apply procedures, coherent with the change management procedures referred to in point 6.4.1. as well as with vulnerability management, risk management and other relevant management procedures, for ensuring that: (a) security patches are applied within a reasonable time after they become available; (b) security patches are tested before being applied in production systems; (c) security patches come from trusted sources and are checked for integrity; (d) additional measures are implemented and residual risks are accepted in cases where a patch is not available or not applied pursuant to point 6.6.2.\nRationale: N/A\nAudit: N/A\nRemediation: - Take into account well known standards when developing the security patch management procedures. - Actions may vary, depending on the network and information system (e.g. mandatory patching for all exposed systems or internet-connected devices such as firewalls or routers, and limited patching only in specific circumstances, for instance in isolated or legacy systems where regular patching may not be feasible or available). - Establish a process, in combination with the asset inventory, for being informed when a new security patch is published and schedule patch roll-outs accordingly. - Patching should be a standard activity in normal maintenance and outage planning of services. Nonetheless, some failures may require immediate patching depending on their criticality. - Prioritise and apply patches based on risk. Evaluate the severity of the vulnerability, exposure of the affected system and likelihood of exploitation. - Deploy vulnerability management technologies to identify unpatched and misconfigured software. - Define your relevant security information sources considering your assets and continuously monitor them for patch announcements, patch and non-patch remediation, and general threats. - Verify the patch sources through (indicative, non-exhaustive list): - digital certificates to verify the vendor; - digital signatures of the patches - change logs provided by the vendor; and - feedback from the community concerning the reliability of the vendor. - Consider a strategy for applying patches after approval or testing following the change management procedure (indicative, non exhaustive list): NIST SP 800-40 Rev. 4, ‘Guide to enterprise patch management planning: preventive maintenance for technology’, - Blue/green allows the patches to be applied first in an isolated environment identical to the production environment, and then in the production environment. This ensures zero downtime and an immediate rollback option. - Rolling deployment allows gradual updates of parts of the production environment, one set - f servers or instances at a time, rather than deploying a patch all at once. It is ideal for large and distributed environments. - Feature toggles allow new features or patches to be deployed to production but keep them disabled until they are ready to be used. They are suitable for control over new features or patches when they are turned on, making it easy to test and release. - Shadow deployment allows new code or patches to be deployed directly to production but it shadows live traffic by mirroring user requests to both the current and new systems to observe how the new version behaves without affecting the user experience. It is ideal for testing new features in production without affecting users. - Hotfix deployments are used for critical patches that need to be applied immediately to address severe issues. - Where appropriate and to reduce risks related to significant updates in important dependencies, consider performing a trial using release candidates ( 60) of these components, to get an early indication of incompatibilities or breaking changes, so they may be remedied. If any of these components are open source software, offer feedback about any issues found during this trial.",
    "metadata": {
      "id": "ENISA-6.6.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "SECURITY PATCH MANAGEMENT"
    }
  },
  {
    "page_content": "Title: SECURITY PATCH MANAGEMENT\nDescription: By way of derogation from point 6.6.1.(a), the relevant entities may choose not to apply security patches when the disadvantages of applying the security patches outweigh the cybersecurity benefits. The relevant entities shall duly document and substantiate the reasons for any such decision.\nRationale: N/A\nAudit: N/A\nRemediation: - Make an effort, proportionate to the entity’s size and importance, to ensure that security patches do not introduce additional vulnerabilities or instabilities. Examples of information supporting such a decision may include (indicative, non-exhaustive list): - vendor documentation on the patch:  what specific vulnerabilities or bugs are addressed,  whether the patch fixes a security issue, improves performance, adds features or resolves stability concerns,  system requirements or any specific configurations required or changes to system settings,  installation instructions on How to apply the patch and whether it requires a restart or additional configuration; - severity rating - patches that address critical vulnerabilities are more likely to apply; and - security blogs, forums and mailing lists for any known issues or incompatibilities introduced by the patch. - If patching is not feasible, consider alternative measures such as strict configuration hardening, intrusion detection systems, regular vulnerability scanning, network segmentation or isolation where feasible, access control and monitoring.",
    "metadata": {
      "id": "ENISA-6.6.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "SECURITY PATCH MANAGEMENT"
    }
  },
  {
    "page_content": "Title: NETWORK SECURITY\nDescription: The relevant entities shall take the appropriate measures to protect their network and information systems from cyber threats.\nRationale: N/A\nAudit: N/A\nRemediation: - Take into account well-known standards when implementing measures for network security.",
    "metadata": {
      "id": "ENISA-6.7.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "NETWORK SECURITY"
    }
  },
  {
    "page_content": "Title: NETWORK SECURITY\nDescription: For the purpose of point 6.7.1., the relevant entities shall: (a) document the architecture of the network in a comprehensible and up to date manner; (b) determine and apply controls to protect the relevant entities’ internal network domains from unauthorised access; (c) configure controls to prevent accesses and network communication not required for the operation of the relevant entities; (d) determine and apply controls for remote access to network and information systems, including access by service providers; (e) not use systems used for administration of the security policy implementation for other purposes; (f) explicitly forbid or deactivate unneeded connections and services; (g) where appropriate, exclusively allow access to the relevant entities’ network and information systems by devices authorised by those entities; In addition to those mentioned in the mapping table at the end of this section, consider the following: a) NIST Special Publication NIST SP 800-215, Guide to a Secure Enterprise Network Landscape, accessed 7 May 2025. b) ISO/IEC 27033 series of standards on network security. TECHNICAL IMPLEMENTATION\nRationale: N/A\nAudit: N/A\nRemediation: (h) allow connections of service providers only after an authorisation request and for a set time period, such as the duration of a maintenance operation; (i) establish communication between distinct systems only through trusted channels that are isolated using logical, cryptographic or physical separation from other communication channels and provide assured identification of their end points and protection of the channel data from modification or disclosure; (j) adopt an implementation plan for the full transition towards latest generation network layer communication protocols in a secure, appropriate and gradual way and establish measures to accelerate such transition; (k) adopt an implementation plan for the deployment of internationally agreed and interoperable modern e-mail communications standards to secure e-mail communications to mitigate vulnerabilities linked to e-mail-related threats and establish measures to accelerate such deployment; (l) apply best practices for the security of the DNS and for Internet routing security and routing hygiene of traffic - riginating from and destined to the network. - Implement secure-by-design principles by integrating security at every layer of network design including the physical, data link, network, transport and application layers. - Implement secure configurations for wireless networks. - Where appropriate, consider zero-trust network access. - Identify the technical measures for the transition to the latest network layer communication protocols (e.g. transition to Internet Protocol version 6). - Define roles, responsibilities and timelines for the transition to latest-generation network layer communication protocols. - Approve, log and perform remote maintenance of network and information systems in a manner that prevents unauthorised access. - Consider the following for email communications (indicative, non-exhaustive list): - standards such as Start transport layer security (STARTTLS), DNS-based authentication of named entities (DANE), domain-based message authentication, reporting and& conformance (DMARC), DomainKeys identified mail (DKIM) and sender policy framework, - internal spam/scam/virus filtering and - URL rewriting, URL scanning and URL detonation in a sandbox. - Consider DNS security good practices (indicative, non-exhaustive list): - deploying DNS security extensions (DNS SEC), Zero-trust is a security model that assumes no user, device, application or network is trusted by default — even if it's inside the corporate perimeter. It's particularly relevant to remote access, service provider access, network segmentation and device control. Key components to implement zero trust are (indicative, non-exhaustive list): - Identity and access management supported by MFA (11.6.1), role based access control (11.1.3) and just in time access; - Device security supported by a policy which allows only known devices and EDR (6.9.2); - Network microsegmentation supported by logical segmentation (6.8), Next Generation Firewalls and a policy which prevents lateral movement; - Zero trust network access (ZTNA) supported by replacement of VPNs by ZTNA platforms, monitoring off all access requests and a policy which grants access to resources based on the combination of identity/device trust/context; - Application and data protection supported by cloud access security brokers (CASBs), data loss prevention (DLP) and encryption as well as monitoring of user activity; and - Continuous monitoring supported by a SIEM, user and entity behaviour analytics. ‘Secure Domain Name System (DNS) Deployment Guide’, as updated from time to time; Olaf Kolkman, ‘DNSSEC HOWTO, a tutorial in disguise’, as updated from time to time. - deploying protective DNS, wherever technically feasible, to provide additional network-wide security capabilities, - encrypting DNS traffic, both internal and external, wherever feasible, - deploying dedicated DNS servers to reduce attack surface and - following all technical on ensuring that DNS deployments and the DNS protocol are as secure and resilient as possible. - Consider Border Gateway Protocol (BGP) for internet routing.",
    "metadata": {
      "id": "ENISA-6.7.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "NETWORK SECURITY"
    }
  },
  {
    "page_content": "Title: NETWORK SECURITY\nDescription: The relevant entities shall review and, where appropriate, update these measures at planned intervals and when significant incidents or significant changes to operations or risks occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Although the frequency of reviews of network security measures depends on the entity’s risk assessment as a general rule the entity might (indicative, non-exhaustive list): - continuously monitor the networks for real time threats; - perform scans for new vulnerabilities weekly; - review and possibly update the rules of the firewall and other tools monthly; and - thoroughly assess the entire network annually. - Review logs or records of all changes made to the network security rules, including details of the changes, approvals and implementation dates. - Ensure that these reviews are conducted regularly and documented comprehensively. , 7 Steps to shore up the Border Gateway Protocol (BGP),",
    "metadata": {
      "id": "ENISA-6.7.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "NETWORK SECURITY"
    }
  },
  {
    "page_content": "Title: NETWORK SEGMENTATION\nDescription: The relevant entities shall segment systems into networks or zones in accordance with the results of the risk assessment referred to in point 2.1. They shall segment their systems and networks from third parties’ systems and networks.\nRationale: N/A\nAudit: N/A\nRemediation: - Take into account well known standards when segmenting networks. - Integrate the segmentation derived from the risk assessment into the network diagram.",
    "metadata": {
      "id": "ENISA-6.8.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "NETWORK SEGMENTATION"
    }
  },
  {
    "page_content": "Title: NETWORK SEGMENTATION\nDescription: For that purpose, the relevant entities shall: (a) consider the functional, logical and physical relationship, including location, between trustworthy systems and services; (b) grant access to a network or zone based on an assessment of its security requirements; (c) keep systems that are critical to the relevant entities operation or to safety in secured zones; (d) deploy a demilitarised zone within their communication networks to ensure secure communication originating from - r destined to their networks; (e) restrict access and communications between and within zones to those necessary for the operation of the relevant entities or for safety; (f) separate the dedicated network for administration of network and information systems from the relevant entities’ - perational network; (g) segregate network administration channels from other network traffic; (h) separate the production systems for the relevant entities’ services from systems used in development and testing, including backups. GUIDANCE67, 68 - Make sure that the segments are in line with the results of the risk assessment (Annex to the regulation, point 2.1). - Apply a graduated set of measures in different logical network domains to further segregate the network security environments, including: - publicly accessible systems; - internal networks; - OOB connections; and - assets with high criticality. In addition to those mentioned in the mapping table at the end of this section, consider the following: - NIST, ‘Guide to a Secure Enterprise Network Landscape’, NIST SP 800-215, - ISO/IEC 27033 series of standards on network security. - NIST SP 800-215 and 1800-35 propose a zero-trust model, which assumes that no part of the network is trusted. Different organisations use different terminology for the term ‘operational network’, for example ‘enterprise network’, ‘corporate network’, ‘IT network’, ‘OT network’ and ‘administration network’. However, the fundamental concept remains focused on the interconnectedness and functionality of components working together towards common objectives set by the management of the entity. The network for administration of a network and information system, often referred to as network administration, involves managing, monitoring and maintaining an entity’s network infrastructure to ensure its optimal performance and security. TECHNICAL IMPLEMENTATION\nRationale: N/A\nAudit: N/A\nRemediation: - Implement subnetworks for publicly accessible system components that are physically and/or logically separate from internal organisational networks. - Determine the degree of physical separation of system components from physically distinct components: - in separate racks in the same room, - in separate rooms for the components with high criticality and - more significant geographical separation of the components with high criticality. - Implement separate network addresses (that is,, different subnets) to connect to systems in different security domains. - Monitor and control communications at the external boundary of the system as well as at key internal boundaries within the system, including segmentation violations. - Where appropriate, isolate information security tools, mechanisms and support components from other internal information system components, where appropriate, by implementing physically separate subnetworks with managed interfaces to other components of the system. - Route all networked, privileged accesses through a dedicated, managed interface for the purposes of access control and auditing. - Implement a managed interface for each external telecommunication service.",
    "metadata": {
      "id": "ENISA-6.8.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "NETWORK SEGMENTATION"
    }
  },
  {
    "page_content": "Title: NETWORK SEGMENTATION\nDescription: The relevant entities shall review and, where appropriate, update network segmentation at planned intervals and when significant incidents or significant changes to operations or risks.\nRationale: N/A\nAudit: N/A\nRemediation: - Review and, if necessary, update the process for network segmentation rules at least annually.",
    "metadata": {
      "id": "ENISA-6.8.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "NETWORK SEGMENTATION"
    }
  },
  {
    "page_content": "Title: PROTECTION AGAINST MALICIOUS AND UNAUTHORISED SOFTWARE\nDescription: The relevant entities shall protect their network and information systems against malicious and unauthorised software.\nRationale: N/A\nAudit: N/A\nRemediation:",
    "metadata": {
      "id": "ENISA-6.9.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "PROTECTION AGAINST MALICIOUS AND UNAUTHORISED SOFTWARE"
    }
  },
  {
    "page_content": "Title: PROTECTION AGAINST MALICIOUS AND UNAUTHORISED SOFTWARE\nDescription: For that purpose, the relevant entities shall in particular implement measures that detect or prevent the use of malicious or unauthorised software. The relevant entities shall, where appropriate, ensure that their network and information systems are equipped with detection and response software, which is updated regularly in accordance with the risk assessment carried out pursuant to point 2.1 and the contractual agreements with the providers.\nRationale: N/A\nAudit: N/A\nRemediation: - Employ mechanisms for detecting and protecting against malicious and unauthorised software at system entry and exit points and at workstations, servers and mobile computing devices on the network to detect and eradicate malicious code transported by electronic mail, electronic mail attachments, web accesses - r removable media or inserted through the exploitation of system vulnerabilities. - Configure malicious code protection mechanisms to: - be active all the time; - perform periodic scans of the system regularly and real-time scans of files from external sources as the files are downloaded, opened or executed; - generate notifications when suspected malicious and unauthorised software is detected; - disinfect and quarantine infected files; and - restore system settings and ensure that critical settings cannot be disabled or restricted. - Apply application whitelisting and monitor unauthorised activities and system behaviour, where appropriate. - Make sure that the malicious and unauthorised protection mechanisms are centrally managed, where appropriate. - Make sure that there are mechanisms that prevent users from circumventing malicious and unauthorised software protection capabilities. - Make sure that spam protection mechanisms are employed at system entry points such as workstations, servers or mobile computing devices on the network. - Update malicious code protection mechanisms (including signature definitions) whenever new releases are available in accordance with configuration rules and the entity’s patch management procedures. - Address issues related to false positives during malicious code detection and eradication and the resulting potential impact on system availability. - Align rules for monitoring and logging malicious and unauthorised detection and repair software with the entity’s monitoring and logging tools and procedures (Annex to the regulation, point 3.2) and with the entity’s access control (Annex to the regulation, point 11.1) and asset-handling policy.",
    "metadata": {
      "id": "ENISA-6.9.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "PROTECTION AGAINST MALICIOUS AND UNAUTHORISED SOFTWARE"
    }
  },
  {
    "page_content": "Title: VULNERABILITY HANDLING AND DISCLOSURE\nDescription: The relevant entities shall obtain information about technical vulnerabilities in their network and information systems, evaluate their exposure to such vulnerabilities and take appropriate measures to manage the vulnerabilities.\nRationale: N/A\nAudit: N/A\nRemediation: - Adopt a framework for assessing the severity of vulnerabilities based on models (e.g. CVSS, exploit prediction scoring system (EPSS) or SANS vulnerability assessment framework) and supplemented by environmental and threat metrics as appropriate.",
    "metadata": {
      "id": "ENISA-6.10.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "VULNERABILITY HANDLING AND DISCLOSURE"
    }
  },
  {
    "page_content": "Title: VULNERABILITY HANDLING AND DISCLOSURE\nDescription: For the purpose of point 6.10.1., the relevant entities shall: (a) monitor information about vulnerabilities through appropriate channels, such as announcements of CSIRTs, competent authorities or information provided by suppliers or service providers; (b) perform, where appropriate, vulnerability scans and record evidence of the results of the scans, at planned intervals; (c) address, without undue delay, vulnerabilities identified by the relevant entities as critical to their operations; (d) ensure that their vulnerability handling is compatible with their change management, security patch management, risk management and incident management procedures; (e) lay down a procedure for disclosing vulnerabilities in accordance with the applicable national coordinated vulnerability disclosure policy.\nRationale: N/A\nAudit: N/A\nRemediation: - As a minimum, address vulnerabilities assigned to higher classifications (e.g. ‘critical’ and ‘high’ in the CVSS) - r equivalent (e.g. as defined by the national CSIRT) without undue delay. Where possible, accepting the risk - f such vulnerabilities and not addressing them is not advisable. - Share information obtained from technical vulnerability scans with designated personnel throughout the entity and with authorities to help eliminate similar vulnerabilities in other information systems. - Disclose as yet unknown vulnerabilities to designated CSIRTs in accordance with national coordinated vulnerability disclosure (CVD) policies, where applicable. - Identify a single point of contact and channels for communication with suppliers and service providers about issues related to network and information security.",
    "metadata": {
      "id": "ENISA-6.10.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "VULNERABILITY HANDLING AND DISCLOSURE"
    }
  },
  {
    "page_content": "Title: VULNERABILITY HANDLING AND DISCLOSURE\nDescription: When justified by the potential impact of the vulnerability, the relevant entities shall create and implement a plan to mitigate the vulnerability. In other cases, the relevant entities shall document and substantiate the reason why the vulnerability does not require remediation.\nRationale: N/A\nAudit: N/A\nRemediation: - Ensure comprehensive documentation of identified vulnerabilities, the associated risk assessments and any mitigation plans developed. - Define and establish the roles and responsibilities associated with vulnerability management. - Mitigation plans should include clear timelines, assigned responsibilities and follow-up procedures. - All mitigation plans, along with the rationale for non-remediation decisions, should be reviewed and validated by the management body responsible for risk oversight",
    "metadata": {
      "id": "ENISA-6.10.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "VULNERABILITY HANDLING AND DISCLOSURE"
    }
  },
  {
    "page_content": "Title: VULNERABILITY HANDLING AND DISCLOSURE\nDescription: The relevant entities shall review and, where appropriate, update at planned intervals the channels they use for monitoring vulnerability information.\nRationale: N/A\nAudit: N/A\nRemediation: - Review the information from the technical-vulnerability-monitoring channels at least biannually. - Consider inventorying sources likely to report technical vulnerabilities in the identified components and distribute updates (software publisher websites, CERT website and website).",
    "metadata": {
      "id": "ENISA-6.10.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "10 VULNERABILITY HANDLING AND DISCLOSURE",
      "category_l2": "VULNERABILITY HANDLING AND DISCLOSURE"
    }
  },
  {
    "page_content": "Title: AWARENESS RAISING AND BASIC CYBER HYGIENE PRACTICES\nDescription: For the purpose of Article 21, point (g) of Directive (EU) 2022/2555, the relevant entities shall ensure that their employees are aware of risks, are informed of the importance of cybersecurity and apply cyber hygiene practices.\nRationale: N/A\nAudit: N/A\nRemediation: - Implement cybersecurity awareness programmes: - use various formats, such as workshops, webinars and e-learning modules; - use multiple communication channels (emails, newsletters and intranet) to keep employees informed about cybersecurity updates, risks and cyber hygiene practices for users.",
    "metadata": {
      "id": "ENISA-8.1.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 SECURITY TRAINING",
      "category_l2": "AWARENESS RAISING AND BASIC CYBER HYGIENE PRACTICES"
    }
  },
  {
    "page_content": "Title: AWARENESS RAISING AND BASIC CYBER HYGIENE PRACTICES\nDescription: For the purpose of point 8.1.1., the relevant entities shall offer to all employees, including members of management bodies, as well as to direct suppliers and service providers where appropriate in accordance with point 5.1.4, an awareness raising programme, which shall: (a) be scheduled over time, so that the activities are repeated and cover new employees; (b) be established in line with the network and information security policy, topic-specific policies and relevant procedures - n network and information security; (c) cover cybersecurity risk-management measures in place, contact points and resources for additional information and advice on cybersecurity matters, as well as cyber hygiene practices for users.\nRationale: N/A\nAudit: N/A\nRemediation: - Include cyber hygiene practices for relevant users (indicative, non-exhaustive list): - clear desk and screen policy, - use of relevant strong authentication means and methods, multi factor passwords etc, - event reporting, - safe email use and web browsing, - protection from phishing and social engineering, - secure use of mobile devices, - secure use of the entity’s connected-vehicles, - secure connection practices, Refer to recitals 49, 50 and 89 of the NIS2 Directive for clarifications of the term ‘cyber hygiene’. - backup practices, - zero-trust concept, - software updates, - secure device configuration, - network segmentation, - secure teleworking practices. - Include the following in the programme (indicative, non-exhaustive list). - Train personnel on the policy on the security of network and information systems. - Train personnel to recognize social engineering attacks, such as phishing, pre-texting and tailgating. - Train personnel to be aware of causes of unintentional data exposure. Example topics include the erroneous delivery of sensitive data, losing a portable end-user device, providing unauthorized access to an entity’s connected-vehicle and the data stored on it and publishing data to unintended audiences. - Train personnel on the dangers of connecting to and transmitting data via insecure networks for the entity’s activities. If the entity has remote workers, training should include to ensure that all users securely configure their home network infrastructure. - Train personnel in understanding malicious and unauthorised software, on the importance of malicious software detection and on the risks and consequences of using unauthorised software. - Offer employees contact points and resources for additional advice. - To implement the awareness raising programme, consult available sources, such as those from national - r international cybersecurity organisations, ’s AR-in-a-Box ( 78 ) and the Cybersecurity Skills Academy.",
    "metadata": {
      "id": "ENISA-8.1.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 SECURITY TRAINING",
      "category_l2": "AWARENESS RAISING AND BASIC CYBER HYGIENE PRACTICES"
    }
  },
  {
    "page_content": "Title: AWARENESS RAISING AND BASIC CYBER HYGIENE PRACTICES\nDescription: The awareness raising programme shall, where appropriate, be tested in terms of effectiveness. The awareness raising programme shall be updated and offered at planned intervals taking into account changes in cyber hygiene practices, and the current threat landscape and risks posed to the relevant entities.\nRationale: N/A\nAudit: N/A\nRemediation: - Offer cybersecurity awareness raising programmes periodically. Communication from the Commission to the European Parliament and the Council – Closing the cybersecurity talent gap to boost the EU’s competitiveness, growth and resilience ('The Cybersecurity Skills Academy'), COM 207 final, - Test the effectiveness of the awareness raising programme for example by using quizzes or real scenarios. - Consider common KPIs (Annex to the regulation, point 7.2) to measure the effectiveness of the awareness-raising programme. - Review and update the awareness-raising programme at least annually.",
    "metadata": {
      "id": "ENISA-8.1.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 SECURITY TRAINING",
      "category_l2": "AWARENESS RAISING AND BASIC CYBER HYGIENE PRACTICES"
    }
  },
  {
    "page_content": "Title: SECURITY TRAINING\nDescription: The relevant entities shall identify employees, whose roles require security relevant skill sets and expertise and ensure that they receive regular training on network and information system security.\nRationale: N/A\nAudit: N/A\nRemediation: - Assess which roles within the entity require security-relevant skills and expertise. - Offer training that focuses on the specific security skills required by the identified roles. - Consider globally recognized qualifications and certifications, and the ECSF.",
    "metadata": {
      "id": "ENISA-8.2.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 SECURITY TRAINING",
      "category_l2": "SECURITY TRAINING"
    }
  },
  {
    "page_content": "Title: SECURITY TRAINING\nDescription: The relevant entities shall establish, implement and apply a training program in line with the network and information security policy, topic-specific policies and other relevant procedures on network and information security which lays down the training needs for certain roles and positions based on criteria.\nRationale: N/A\nAudit: N/A\nRemediation: - Provide role-specific network and information security training. - Consider various training methods, such as online courses, workshops, hands-on labs and simulations. - Consider various types of training, such as courses, certifications or attending security conferences or webinars, and the maintenance of certifications. - Examples of training may include secure system administration courses for IT professionals, Open Worldwide Application Security Project® awareness and prevention training for web application developers and advanced social engineering awareness training for high-profile roles.",
    "metadata": {
      "id": "ENISA-8.2.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 SECURITY TRAINING",
      "category_l2": "SECURITY TRAINING"
    }
  },
  {
    "page_content": "Title: SECURITY TRAINING\nDescription: The training referred to in point 8.2.1. shall be relevant to the job function of the employee and its effectiveness shall be assessed. Training shall take into consideration security measures in place and cover the following: (a) instructions regarding the secure configuration and operation of the network and information systems, including mobile devices; (b) briefing on known cyber threats; (c) training of the behaviour when security-relevant events occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Topics to include in the programme may include the following (indicative, non-exhaustive list). - Train personnel in authentication best practices, such as MFA, password creation and credential management. - Train personnel in how to identify and properly store, transfer, archive and destroy sensitive data. - Train personnel to recognise a potential incident, such as unusual email attachments, unexpected system behaviour and suspicious network traffic. - Train personnel in how to report events promptly and accurately, including the use of designated communication channels. - Train personnel to understand how to verify and report out-of-date software or any failures in automated processes and tools. Part of this training should include notifying IT personnel of any failures in automated processes and tools. - Train relevant personnel in crisis management and business continuity procedures. Incorporate simulated events ( 82) into crisis management training to facilitate an effective response by personnel in crisis situations. - Train relevant personnel (e.g. system administrators and software developers) in the secure configuration and operation of the network and information systems. Provide regular updates on the latest cyber threats. - Test the security knowledge of employees to make sure that it is sufficient and up to date.",
    "metadata": {
      "id": "ENISA-8.2.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 SECURITY TRAINING",
      "category_l2": "SECURITY TRAINING"
    }
  },
  {
    "page_content": "Title: SECURITY TRAINING\nDescription: The relevant entities shall apply training to staff members who transfer to new positions or roles which require security relevant skill sets and expertise.\nRationale: N/A\nAudit: N/A\nRemediation: - Examine whether the new position or role of an employee requires role-specific network and information security training.",
    "metadata": {
      "id": "ENISA-8.2.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 SECURITY TRAINING",
      "category_l2": "SECURITY TRAINING"
    }
  },
  {
    "page_content": "Title: SECURITY TRAINING\nDescription: The program shall be updated and run periodically taking into account applicable policies and rules, assigned roles, responsibilities, as well as known cyber threats and technological developments.\nRationale: N/A\nAudit: N/A\nRemediation: - Provide cybersecurity training periodically. - Review and update the training programme at least annually.",
    "metadata": {
      "id": "ENISA-8.2.5",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "2 SECURITY TRAINING",
      "category_l2": "SECURITY TRAINING"
    }
  },
  {
    "page_content": "Title: HUMAN RESOURCES SECURITY\nDescription: For the purpose of Article 21, point (i) of Directive (EU) 2022/2555, the relevant entities shall ensure that their employees and direct suppliers and service providers, wherever applicable, understand and commit to their security responsibilities, as appropriate for the offered services and the job and in line with the relevant entities’ policy on the security of network and information systems.\nRationale: N/A\nAudit: N/A\nRemediation: - Define clear security roles and responsibilities for employees, aligned with the entity’s security policies and each employee’s functional role. Define relevant security responsibilities for direct suppliers and service providers, within the scope of contractual obligations, ensuring they are appropriate to the nature - f the services provided and aligned with the entity’s overall security requirements. - Establish onboarding and continuous education programmes that include both security awareness and role-specific cybersecurity training tailored to different risk exposures. - Implement periodic assessments to evaluate understanding of security responsibilities, supported by mandatory refresher training as needed. - Ensure that security responsibilities are formally documented and integrated into job descriptions, contractual agreements and performance review processes. Incorporate relevant security responsibilities into contractual agreements or service-level agreements (SLA), for direct suppliers and service providers with clear language regarding expectations and compliance requirements. - Promote a culture of accountability by requiring formal acknowledgement of security obligations and by linking compliance to incentives and disciplinary measures, where appropriate. - Develop and maintain a centralized repository of training records, acknowledgements, certifications and contractual clauses to demonstrate compliance and facilitate audits. - Require suppliers and service providers to designate responsible contacts for cybersecurity and encourage or mandate participation in relevant security briefings or training programmes provided by the entity.",
    "metadata": {
      "id": "ENISA-10.1.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "4 DISCIPLINARY PROCESS",
      "category_l2": "HUMAN RESOURCES SECURITY"
    }
  },
  {
    "page_content": "Title: HUMAN RESOURCES SECURITY\nDescription: The requirement referred to in point 10.1.1. shall include the following: (a) mechanisms to ensure that all employees, direct suppliers and service providers, wherever applicable, understand and follow the standard cyber hygiene practices that the entities apply pursuant to point 8.1.; (b) mechanisms to ensure that all users with administrative or privileged access are aware of and act in accordance with their roles, responsibilities and authorities; (c) mechanisms to ensure that members of management bodies understand and act in accordance with their role, responsibilities and authorities regarding network and information system security; (d) mechanisms for hiring personnel qualified for the respective roles, such as reference checks, vetting procedures, validation of certifications or written tests.\nRationale: N/A\nAudit: N/A\nRemediation: - Implement regular awareness raising on cyber hygiene practices for users, tailored to different roles and responsibilities (Annex to the regulation, point 8.1). Wherever applicable, require employees of direct suppliers and service providers, to follow similar awareness raising on cyber hygiene via contractual clauses. - Communicate clear and concise cyber hygiene practices for users to all employees, suppliers and service providers. Require acknowledgement of receipt and understanding (Annex to the regulation, point 8.1). - Consider specialised training for users with administrative or privileged access, focusing on their specific responsibilities (Annex to the regulation, point 8.2). - Establish performance metrics related to security responsibilities and include them in management evaluations. - Hold regular briefings for members of management bodies on the importance of network and information system security, their specific responsibilities and the potential impact of incidents (section 8.2). - Conduct thorough reference checks, where appropriate, to verify the candidate’s previous experience and performance in similar roles. - Consider vetting procedures, including background checks (section 10.2), to ensure the candidate’s suitability for the role. - Validate any relevant certifications claimed by the candidate, to ensure they are current and legitimate. - Use written tests or practical assessments to evaluate the candidate’s knowledge and skills related to network and information system security. - Use interview panels, where appropriate, that also include security experts, to assess the candidate’s technical and behavioural competencies.",
    "metadata": {
      "id": "ENISA-10.1.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "4 DISCIPLINARY PROCESS",
      "category_l2": "HUMAN RESOURCES SECURITY"
    }
  },
  {
    "page_content": "Title: HUMAN RESOURCES SECURITY\nDescription: The relevant entities shall review the assignment of personnel to specific roles as referred to in point 1.2., as well as their commitment of human resources in that regard, at planned intervals and at least annually. They shall update the assignment where necessary.\nRationale: N/A\nAudit: N/A\nRemediation: - Set up a formal schedule for reviewing personnel assignments and resource commitments. This should - ccur at least annually.",
    "metadata": {
      "id": "ENISA-10.1.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "4 DISCIPLINARY PROCESS",
      "category_l2": "HUMAN RESOURCES SECURITY"
    }
  },
  {
    "page_content": "Title: VERIFICATION OF BACKGROUND\nDescription: The relevant entities shall ensure to the extent feasible verification of the background of their employees and where applicable of direct suppliers and service providers in accordance with point 5.1.4, if necessary for their role, responsibilities and authorisations.\nRationale: N/A\nAudit: N/A\nRemediation: - Identify which roles, responsibilities and authorities require verification of background, based on the criteria in point 10.2.2 (a) of the Annex to the regulation. - Perform background verification on employees and, where applicable, direct suppliers and service providers in accordance with point 5.1.4 (c) of the Annex to the regulation.",
    "metadata": {
      "id": "ENISA-10.2.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "4 DISCIPLINARY PROCESS",
      "category_l2": "VERIFICATION OF BACKGROUND"
    }
  },
  {
    "page_content": "Title: VERIFICATION OF BACKGROUND\nDescription: For the purpose of point 10.2.1., the relevant entities shall: (a) put in place criteria, which set out which roles, responsibilities and authorities shall only be exercised by persons whose background has been verified; (b) ensure that verification referred to in point 10.2.1 is performed on these persons before they start exercising these roles, responsibilities and authorities, which shall take into consideration the applicable laws, regulations and ethics in proportion to the business requirements, the asset classification as referred to in point 12.1. and the network and information systems to be accessed and the perceived risks.\nRationale: N/A\nAudit: N/A\nRemediation: - Where applicable, define criteria for roles, responsibilities and authorities that will be exercised only by persons who have undergone background verification. An indicative, non-exhaustive list is the following: - executives and senior management, - roles with access to sensitive information, - roles with financial responsibilities, - roles involving procurement and vendor management, - roles that grant access to physical assets or are responsible for physical security. - Define criteria and limitations for background verification (e.g. who is eligible to screen people, and how, when and why verification reviews are carried out). - For background verification, consider checking the criminal records of the person concerned with regard to offences that would be relevant to a specific position. - Ensure that checks of criminal records align with legal and regulatory requirements (e.g. national (labour) laws and the GDPR). - Collect and handle information on job candidates, taking into consideration any applicable laws, regulations and ethics, including the protection of personal data. This may include collecting professional references. - Consider screening requirements in the contractual agreements between the entity and the direct suppliers and service providers in cases of personnel contracted with an external supplier. - Periodically repeat verification to confirm the ongoing suitability of personnel, depending on the criticality - f a person’s role, responsibilities and authorities. - Entities should be permitted to rely on background checks of contractors employed by a third-party talent agency with which the entity covered has contracts for performing services.",
    "metadata": {
      "id": "ENISA-10.2.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "4 DISCIPLINARY PROCESS",
      "category_l2": "VERIFICATION OF BACKGROUND"
    }
  },
  {
    "page_content": "Title: VERIFICATION OF BACKGROUND\nDescription: The relevant entities shall review and, where appropriate, update the policy at planned intervals and update it where necessary.\nRationale: N/A\nAudit: N/A\nRemediation: - Where necessary, review and update background verification procedure at least annually.",
    "metadata": {
      "id": "ENISA-10.2.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "4 DISCIPLINARY PROCESS",
      "category_l2": "VERIFICATION OF BACKGROUND"
    }
  },
  {
    "page_content": "Title: TERMINATION OR CHANGE OF EMPLOYMENT PROCEDURES\nDescription: The relevant entities shall ensure that network and information system security responsibilities and duties that remain valid after termination or change of employment of their employees are contractually defined and enforced.\nRationale: N/A\nAudit: N/A\nRemediation: - Include specific clauses in employment contracts that outline the ongoing security responsibilities and duties of employees after their employment ends or their role changes.",
    "metadata": {
      "id": "ENISA-10.3.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "4 DISCIPLINARY PROCESS",
      "category_l2": "TERMINATION OR CHANGE OF EMPLOYMENT PROCEDURES"
    }
  },
  {
    "page_content": "Title: TERMINATION OR CHANGE OF EMPLOYMENT PROCEDURES\nDescription: For the purpose of point 10.3.1., the relevant entities shall include in the individual’s terms and conditions of employment, contract or agreement the responsibilities and duties that are still valid after termination of employment or contract, such as confidentiality clauses.\nRationale: N/A\nAudit: N/A\nRemediation: - Ensure these clauses cover the protection of confidential information, return of company property and restrictions on accessing the entity’s network and information systems. - Revoke access to network and information systems in a timely manner upon termination or role change. - Identify and document all assets to be returned upon termination or change of employment. - After a change of employment, brief and inform personnel on the procedures in place.",
    "metadata": {
      "id": "ENISA-10.3.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "4 DISCIPLINARY PROCESS",
      "category_l2": "TERMINATION OR CHANGE OF EMPLOYMENT PROCEDURES"
    }
  },
  {
    "page_content": "Title: DISCIPLINARY PROCESS\nDescription: The relevant entities shall establish, communicate and maintain a disciplinary process for handling violations of network and information system security policies. The process shall take into consideration relevant legal, statutory, contractual and business requirements.\nRationale: N/A\nAudit: N/A\nRemediation: - Make sure that the process holds employees accountable for violations of the network and information system security policies. - Involve human resources in implementing the disciplinary process, ensuring it aligns with legal and regulatory requirements (e.g. national labour laws and the GDPR). - Communicate and raise awareness of the process among employees. - Protect the identity of individuals subject to disciplinary action, where possible, in line with applicable requirements.",
    "metadata": {
      "id": "ENISA-10.4.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "4 DISCIPLINARY PROCESS",
      "category_l2": "DISCIPLINARY PROCESS"
    }
  },
  {
    "page_content": "Title: DISCIPLINARY PROCESS\nDescription: The relevant entities shall review and, where appropriate, update the disciplinary process at planned intervals and when necessary due to legal changes or significant changes to operations or risks.\nRationale: N/A\nAudit: N/A\nRemediation: - Regularly review and update the disciplinary process at planned intervals and promptly when legal changes or significant operational or risk changes occur.",
    "metadata": {
      "id": "ENISA-10.4.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "4 DISCIPLINARY PROCESS",
      "category_l2": "DISCIPLINARY PROCESS"
    }
  },
  {
    "page_content": "Title: ACCESS CONTROL POLICY\nDescription: For the purpose of Article 21, point (i) of Directive (EU) 2022/2555, the relevant entities shall establish, document and implement logical and physical access control policies for the access to their network and information systems, based on business requirements as well as network and information system security requirements.\nRationale: N/A\nAudit: N/A\nRemediation: - Implement and maintain logical and physical access restrictions to network and information system based on access-control policies that take into account industry good practices. - Ensure that these policies are documented, communicated to all relevant stakeholders and include clear guidelines on the appropriate use of access privileges.",
    "metadata": {
      "id": "ENISA-11.1.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "ACCESS CONTROL POLICY"
    }
  },
  {
    "page_content": "Title: ACCESS CONTROL POLICY\nDescription: The policies referred to in point 11.1.1. shall: (a) address access by persons, including staff, visitors and external entities such as suppliers and service providers; (b) address access by network and information system processes; (c) ensure that access is only granted to users that have been adequately authenticated.\nRationale: N/A\nAudit: N/A\nRemediation: - Implement access control rules by defining and mapping appropriate access rights and restrictions to human users or network and information system processes (e.g. a machine, device or a service). To simplify access control management, assign specific roles to groups. - Access control rules can be implemented in different granularities, ranging from covering whole networks or systems to specific data fields and can also consider properties, such as user location or the type of network connection that is used for access. - Use business requirements and risk assessment results to define which access control rules are applied and which granularity is required. - Take into account the following when defining and implementing access control rules: - consistency between access rights and asset classification; - consistency between access rights and physical perimeter security needs and requirements; - consideration of all types of available connections in distributed environments so entities are only provided with access to associated assets, including networks and network services, that they are authorized to use; - consideration of how elements or factors relevant to dynamic access control can be reflected. - Develop documented procedures and defined responsibilities to support the access control rules.",
    "metadata": {
      "id": "ENISA-11.1.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "ACCESS CONTROL POLICY"
    }
  },
  {
    "page_content": "Title: ACCESS CONTROL POLICY\nDescription: The relevant entities shall review and, where appropriate, update the policies at planned intervals and when significant incidents or significant changes to operations or risks occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Review the policies at least annually.",
    "metadata": {
      "id": "ENISA-11.1.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "ACCESS CONTROL POLICY"
    }
  },
  {
    "page_content": "Title: MANAGEMENT OF ACCESS RIGHTS\nDescription: The relevant entities shall provide, modify, remove and document access rights to network and information systems in accordance with the access control policy referred to in point 11.1.\nRationale: N/A\nAudit: N/A\nRemediation:",
    "metadata": {
      "id": "ENISA-11.2.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "MANAGEMENT OF ACCESS RIGHTS"
    }
  },
  {
    "page_content": "Title: MANAGEMENT OF ACCESS RIGHTS\nDescription: The relevant entities shall: (a) assign and revoke access rights based on the principles of need-to-know, least privilege and separation of duties; (b) ensure that access rights are modified accordingly upon termination or change of employment; (c) ensure that access to network and information systems is authorised by the relevant persons; (d) ensure that access rights appropriately address third-party access, such as visitors, suppliers and service providers, in particular by limiting access rights in scope and in duration; (e) maintain a register of access rights granted; (f) apply logging to the management of access rights.\nRationale: N/A\nAudit: N/A\nRemediation: - Ensure each user only has access to information necessary for their role (‘need-to-know’). - Restrict user permissions to the minimum necessary for their duties (‘least privilege’). Regularly review and adjust access rights as needed. - Determine which duties and areas of responsibility need to be segregated. Establish and follow a process for requesting and approving access, preferably automated. The process should: - cover granting access rights to assets upon the new hire or role change of a user; - - btain authorization from the owner of the asset, separate approval for access rights by management bodies can also be appropriate; - ensure that access rights are activated (e.g. by service providers) only after authorization procedures are successfully completed; - consider the business requirements and the entity’s access control policy; - consider segregation of duties, including segregating the roles of approval and implementation - f the access rights and separation of conflicting roles; - verify that the level of access granted is in accordance with the access control policy and is consistent with other information security requirements such as segregation of duties; - consider giving temporary access rights for a time and revoking them at the expiry date, in particular for temporary personnel or temporary access required by personnel. - Establish and follow a process, preferably automated, for revoking access to assets. The process should: - timely disable accounts upon the termination, rights revocation or role change of a user, as needed; disabling accounts, instead of deleting accounts, may be necessary to preserve audit trails; - modify the access rights of users who have changed roles or jobs; - remove or adjust access rights, which can be done by removing, revoking or replacing keys, authentication information, identification cards or subscriptions. - where feasible, enable different components or services to share information (signals) about access revocation in a timely manner. - Limit third-party access based on need and duration. Use temporary access accounts with expiry dates and regularly review third-party access rights. - Ensure third parties acknowledge their access responsibilities and obligations. - Where appropriate, keep a detailed and up-to-date central record (register or database) of all granted access rights, including user names, roles, permissions and dates of access changes. - Establish and maintain an inventory of the authentication and authorization systems, including those hosted on-site or with a remote service provider. - Implement logging for all access rights management activities. Logs should include details of who granted - r modified access, when and what changes were made. - Minimise the use of generic and shared accounts and ensure users can always be identified for their actions within ICT systems.",
    "metadata": {
      "id": "ENISA-11.2.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "MANAGEMENT OF ACCESS RIGHTS"
    }
  },
  {
    "page_content": "Title: MANAGEMENT OF ACCESS RIGHTS\nDescription: The relevant entities shall review access rights at planned intervals and shall modify them based on - rganisational changes. The relevant entities shall document the results of the review including the necessary changes - f access rights.\nRationale: N/A\nAudit: N/A\nRemediation: - Regularly review physical and logical access rights, taking into account: - users’ access rights after termination or change of employment; - authorisations for privileged access rights. - Review and update the inventory of the authentication and authorization systems regularly. - Perform access control reviews of assets to verify that all privileges are authorised on a recurring schedule at least annually.",
    "metadata": {
      "id": "ENISA-11.2.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "MANAGEMENT OF ACCESS RIGHTS"
    }
  },
  {
    "page_content": "Title: PRIVILEGED ACCOUNTS AND SYSTEM ADMINISTRATION ACCOUNTS\nDescription: The relevant entities shall maintain policies for management of privileged accounts and system administration accounts as part of the access control policy referred to in point 11.1.\nRationale: N/A\nAudit: N/A\nRemediation: - Allocate privileged access rights to users as needed and, on an event-by-event basis in line with the access control policy referred to in point 11.1 of the Annex to the regulation (that is, only to individuals with the necessary authority to carry out activities that require privileged access and based on the minimum requirement for their functional roles). - Identify users who need privileged access ( 91) to a network and information system (e.g. operating systems, database management systems and applications). This should include any privileged physical access to, e.g. cryptographic codes, keys or devices and in line with point 13.3 of the Annex to the regulation. - Where appropriate, maintain an authorization process and a record of all allocated privileged access rights, consistent with the process for granting and revoking access rights (Annex to the regulation, point 11.2.2).",
    "metadata": {
      "id": "ENISA-11.3.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "PRIVILEGED ACCOUNTS AND SYSTEM ADMINISTRATION ACCOUNTS"
    }
  },
  {
    "page_content": "Title: PRIVILEGED ACCOUNTS AND SYSTEM ADMINISTRATION ACCOUNTS\nDescription: The policies referred to in point 11.3.1. shall: (a) establish strong identification, authentication such as multi-factor authentication and authorisation procedures for privileged accounts and system administration accounts; (b) set up specific accounts to be used for system administration operations exclusively, such as installation, configuration, management or maintenance; (c) individualise and restrict system administration privileges to the highest extent possible, (d) provide that system administration accounts are only used to connect to system administration systems.\nRationale: N/A\nAudit: N/A\nRemediation: - Introduce higher authentication requirements for privileged access rights, such as re-authentication or authentication step-up before using privileged access rights. - Define and implement expiry requirements for privileged access rights, where appropriate. - In the absence of a system that allows all uses to be attributed to an individual with certainty, establish specific rules to avoid the use of generic administration user IDs (e.g. ‘root’) and manage and protect the authentication information of such identities. - Grant temporary privileged access only for the time necessary to implement approved changes or activities (e.g. for maintenance activities), rather than permanently granting privileged access rights. 91 “Privileged access rights are access rights provided to an identity, a role or a process that allows the performance of activities that typical users or processes cannot perform. System administrator roles typically require privileged access rights.” ISO/IEC 27002, 8.2. Privileged access rights. - Consider the frequency of system administration operations: daily tasks (e.g. backups and email routing) versus weekly or monthly tasks (e.g. reviewing memory and disk space). - Log all privileged access for audit purposes; - Assign separate identities with privileged access rights to individual users, rather than sharing or linking identities. Group identities for easier management if needed. - Use identities with privileged access rights exclusively for administrative tasks, not for day-to-day general tasks such as checking email or accessing the web. Where feasible, separate privileged identities should be assigned for administrative tasks. - Ensure users are aware of their privileged access rights or when they are in privileged access mode, for example using specific user identities, user interface settings or equipment.",
    "metadata": {
      "id": "ENISA-11.3.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "PRIVILEGED ACCOUNTS AND SYSTEM ADMINISTRATION ACCOUNTS"
    }
  },
  {
    "page_content": "Title: PRIVILEGED ACCOUNTS AND SYSTEM ADMINISTRATION ACCOUNTS\nDescription: The relevant entities shall review access rights of privileged accounts and system administration accounts at planned intervals and be modified based on organisational changes and shall document the results of the review, including the necessary changes of access rights.\nRationale: N/A\nAudit: N/A\nRemediation: - Verify whether the duties, roles, responsibilities and competences of system administrators still qualify them for working with privileged access rights.",
    "metadata": {
      "id": "ENISA-11.3.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "PRIVILEGED ACCOUNTS AND SYSTEM ADMINISTRATION ACCOUNTS"
    }
  },
  {
    "page_content": "Title: ADMINISTRATION SYSTEMS\nDescription: The relevant entities shall restrict and control the use of system administration systems in accordance with the access control policy referred to in point 11.1.\nRationale: N/A\nAudit: N/A\nRemediation: - Access to system administration systems must be strictly controlled in line with the access control policy. Only authorized personnel should be granted such access and all activity must be logged and regularly reviewed. - Measures should be in place to detect unauthorized access and ensure accountability through audit trails and periodic security assessments. - Access logs from system administration systems should be integrated into the entity's centralized log management or SIEM solution. Automated alerts must be configured to detect and notify of any suspicious - r unauthorized access attempts, ensuring a timely response and ongoing compliance with security policies. - The retention period for logs must be clearly defined based on business needs, legal requirements and network and information security objectives. - Logs should capture relevant events necessary for security monitoring, incident detection and forensic analysis, such as access attempts, administrative actions and system changes.",
    "metadata": {
      "id": "ENISA-11.4.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "ADMINISTRATION SYSTEMS"
    }
  },
  {
    "page_content": "Title: ADMINISTRATION SYSTEMS\nDescription: For that purpose, the relevant entities shall: (a) only use system administration systems for system administration purposes and not for any other operations; (b) separate logically such systems from application software not used for system administrative purposes, (c) protect access to system administration systems through authentication and encryption.\nRationale: N/A\nAudit: N/A\nRemediation: - Implement strict access controls to ensure that administrative systems are used exclusively for their intended purpose. For instance, only allow authorised personnel with specific roles (e.g. system administrators and IT staff) access to system administration systems. - Physically or logically isolate administrative systems from other application servers, for example use network segmentation to create separate zones for system administration systems and other systems, such as application servers. If applicable, physically inspect server racks to ensure separation. - Require strong authentication mechanisms such as MFA for accessing system administration systems. - Encrypt communication channels (e.g. secure shell protocol, hypertext transfer protocol secure) to protect data in transit to and from system administration systems. - Encrypt sensitive configuration files and credentials stored on system administration systems. Administration systems refer to the tools and processes used to manage, monitor and maintain the hardware, software and network components of an entity’s IT infrastructure. Typical key functions of administration systems include (indicative, non-exhaustive list): system monitoring, configuration management, security management, user management and back-up and recovery. - Ensure that application protocols are securely implemented. In addition, verify that any SSO or federation protocols are correctly implemented and conform to their specifications.",
    "metadata": {
      "id": "ENISA-11.4.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "ADMINISTRATION SYSTEMS"
    }
  },
  {
    "page_content": "Title: IDENTIFICATION\nDescription: The relevant entities shall manage the full life cycle of identities of network and information systems and their users.\nRationale: N/A\nAudit: N/A\nRemediation: - Establish and maintain an inventory of all identities managed in the entity. - The inventory should include both user and privileged or system administrator identities. The inventory should contain, as a minimum, the person’s name, username, start/stop dates and the level of privileges for each identity. - The inventory should also include all service identities and have these identity records as a minimum including department owner, review date, purpose and the level of privileges for each service identity.",
    "metadata": {
      "id": "ENISA-11.5.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "IDENTIFICATION"
    }
  },
  {
    "page_content": "Title: IDENTIFICATION\nDescription: For that purpose, the relevant entities shall: (a) set up unique identities for network and information systems and their users; (b) link the identity of users to a single person; (c) ensure oversight of identities of network and information systems; (d) apply logging to the management of identities.\nRationale: N/A\nAudit: N/A\nRemediation: - Consider that providing or revoking access to assets is usually a multi-step procedure: - confirming the business requirements for an identity to be established; - verifying the identity of an entity before allocating them a logical identity; - establishing an identity; - configuring and activating the identity, which also includes configuration and initial setup of related authentication services; and - providing or revoking the identity’s specific access rights, based on appropriate authorization or entitlement decisions (section 11.2). - Make sure that identities assigned to network and information systems (non-human users) are subject to appropriately segregated approval and independent ongoing oversight. - Apply logging to the management of identities in cooperation with human resource security (section 10.1) where possible.",
    "metadata": {
      "id": "ENISA-11.5.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "IDENTIFICATION"
    }
  },
  {
    "page_content": "Title: IDENTIFICATION\nDescription: The relevant entities shall only permit identities assigned to multiple persons, such as shared identities, where they are necessary for business or operational reasons and are subject to an explicit approval process and documentation. The relevant entities shall take identities assigned to multiple persons into account in the cybersecurity risk management framework referred to in point 2.1.\nRationale: N/A\nAudit: N/A\nRemediation: - Shared identities should be avoided unless strictly necessary for business or operational reasons. In such cases, their use must be formally justified, explicitly approved and properly documented. Examples - f technical, procedural and governance controls to enhance their protection include (indicative, nonexhaustive list): - MFA enforcement; - Least privilege concept enforcement; - Time-bound or just-in-time access; Wherever possible, the organization shall implement Role-Based Access Control (RBAC) to assign privileges to individual identities based on defined business or operational functions. RBAC must be used to avoid the creation of shared accounts unless a technical or operational constraint makes their use unavoidable. - Checking out the shared credentials through a tool which logs who accessed the identity and when. If check-out is not possible, consider using privileged session recording or proxy-based access auditing; - Session attribution techniques to link shared identity use back to individual users; - Logging; - Credential vaulting with auto-rotation; - Prohibition of storing shared credentials in personal files, emails or messaging platforms; - Network segmentation so that shared account use is limited to isolated network segments or virtual environments; and - Mandatory training on acceptable use and accountability. - These identities should be clearly recorded in the cybersecurity risk management framework, with appropriate controls in place to mitigate associated risks, including enhanced monitoring and accountability measures.",
    "metadata": {
      "id": "ENISA-11.5.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "IDENTIFICATION"
    }
  },
  {
    "page_content": "Title: IDENTIFICATION\nDescription: The relevant entities shall regularly review the identities for network and information systems and their users and, if no longer needed, deactivate them without delay.\nRationale: N/A\nAudit: N/A\nRemediation: - Verify that all active identities are reviewed. This can be done on a recurring schedule, as a minimum quarterly, or more frequently. However, for micro-sized entities, this can be done annually. - Disable or remove, in a timely fashion, identities that they are no longer required, for example delete or disable any dormant identities after a predefined period of days of inactivity, where supported.",
    "metadata": {
      "id": "ENISA-11.5.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "IDENTIFICATION"
    }
  },
  {
    "page_content": "Title: AUTHENTICATION\nDescription: The relevant entities shall implement secure authentication procedures and technologies based on access restrictions and the policy on access control.\nRationale: N/A\nAudit: N/A\nRemediation: - Authentication technologies are methods used to verify the identity of users, devices or systems before granting access to resources. Here are some common authentication technologies (indicative, non-exhaustive list): - password-based authentication, - passkeys, - two-factor authentication, - MFA, - biometric authentication, - token-based authentication, such as a one-time passcode (OTP), - smart cards, - Fast Identity Online 2 security keys, - certificate-based authentication, - SSO, - OpenID Connect.",
    "metadata": {
      "id": "ENISA-11.6.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "AUTHENTICATION"
    }
  },
  {
    "page_content": "Title: AUTHENTICATION\nDescription: For that purpose, the relevant entities shall: (a) ensure the strength of authentication is appropriate to the classification of the asset to be accessed; (b) control the allocation to users and management of secret authentication information by a process that ensures the confidentiality of the information, including advising personnel on appropriate handling of authentication information; (c) require the change of authentication credentials initially, at predefined intervals and upon suspicion that the credentials were compromised; (d) require the reset of authentication credentials and the blocking of users after a predefined number of unsuccessful log-in attempts; (e) terminate inactive sessions after a predefined period of inactivity; and (f) require separate credentials to access privileged access or administrative accounts. When implementing, the entity should take into account MFA fatigue, which can occur when users are overwhelmed when they receive numerous authentication prompts. Consider techniques to mitigate this, such as adaptive MFA, passkeys, MFA combined with SSO and short session timeouts. TECHNICAL IMPLEMENTATION\nRationale: N/A\nAudit: N/A\nRemediation: - Use unique authentication credentials for all the entity’s assets. Best-practice implementation includes, as a minimum, an 8-character password for accounts using MFA and a 14-character password for accounts not using MFA. - Consider that the allocation and management process for authentication information should ensure that: - passwords or PINs generated automatically during enrolment processes as temporary secret authentication information are non-guessable and unique for each user; and that users are required to change them after the first use; - procedures are established to verify the identity of a user prior to providing new, replacement or temporary authentication information; - authentication information, including temporary authentication information, is transmitted to users in a secure manner (e.g. via an authenticated and protected channel), and the use of unprotected (clear text) electronic mail messages is avoided; - users acknowledge receipt of authentication information; - default authentication information as predefined or provided by suppliers is changed immediately following installation of systems or software; - records of significant events concerning allocation and management of authentication information are kept and their confidentiality granted, and that the record keeping method is approved (e.g. using an approved password vault tool). - When passwords are used as authentication information, the password management system should: - allow users to select and change their own passwords and include a confirmation procedure to address input errors; - enforce strong passwords; - force users to change their passwords at first login, if relevant; - enforce password changes as necessary, for example after a security incident or upon termination or change of employment when a user has known passwords for identities that remain active (e.g. shared identities); - prevent the use of commonly used passwords, and compromised combinations of usernames and password from hacked systems; - not display passwords on the screen when they are being entered; and - store and transmit passwords in protected form. - The use of phishing-resistant MFA is recommended. Below is a list of currently available solutions ordered from strongest to weakest. - ‘Strong’:  phishing-resistant: - no shared secrets, not vulnerable to attacker-in-the-middle; - protected cryptographic private key that can be securely registered to: - a domain, in accordance with Fast Identity Online (FIDO) and W3C WebAuthn standards; Password complexity can be a good cybersecurity practice, but it is not the only factor to consider. Recent guidelines, such as those from NIST, emphasise password length over complexity; see line 725. - a trust provider, following public key infrastructure and International Telecommunication Union X.509 standards. - ‘Medium’ MFA, for example:  push notification, number matching or application based. - ‘Last resort’ MFA, for example:  text message or email OTP. - Perform password encryption and hashing in accordance with approved cryptographic techniques for passwords (section 9.2). - Generate an alert when a potential attempted or successful breach of login controls is detected.",
    "metadata": {
      "id": "ENISA-11.6.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "AUTHENTICATION"
    }
  },
  {
    "page_content": "Title: AUTHENTICATION\nDescription: The relevant entities shall to the extent feasible use state-of-the-art authentication methods, in accordance with the associated assessed risk and the classification of the asset to be accessed and unique authentication information.\nRationale: N/A\nAudit: N/A\nRemediation: - Adjust authentication methods based on the associated assessed risk. For example, require additional authentication for high-risk transactions or access to assets of higher criticality. - Use more stringent authentication methods for assets of higher criticality. - Ensure each user has unique credentials. Avoid shared accounts and implement strict policies for credential management.",
    "metadata": {
      "id": "ENISA-11.6.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "AUTHENTICATION"
    }
  },
  {
    "page_content": "Title: AUTHENTICATION\nDescription: The relevant entities shall regularly review the authentication procedures and technologies at planned intervals.\nRationale: N/A\nAudit: N/A\nRemediation: - Conduct periodic audits of authentication procedures and technologies to ensure they remain up to date, where appropriate and effective against emerging threats. - Stay up to date on advancements in authentication technology and integrate new methods as they become available.",
    "metadata": {
      "id": "ENISA-11.6.4",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "AUTHENTICATION"
    }
  },
  {
    "page_content": "Title: MULTI-FACTOR AUTHENTICATION\nDescription: The relevant entities shall ensure that users are authenticated by multiple authentication factors or continuous authentication mechanisms for accessing the entities’ network and information systems, where appropriate, in accordance with the classification of the asset to be accessed.\nRationale: N/A\nAudit: N/A\nRemediation: - Select appropriate MFA ( 97) methods and continuous authentication mechanisms based on the entity’s security needs and depending on the classification of the asset. It is also good practice to consider user convenience when selecting and implementing a solution: - test-message-based OTP: simple but less secure due to risks such as SIM swapping; - authenticator apps: generate time-based OTPs; - push notifications: send an approval request to a user’s device; - hardware tokens: for example physical devices generating OTPs, smart cards; - passkeys; - Fast Identity Online 2 security keys; - biometrics: fingerprints, facial recognition, etc. Some types of MFA are vulnerable to phishing attacks, and the relevant entities should select MFA that can stand up to these attacks. For more information (indicative), see and - Consider continuous authentication for avoiding specific threats such as session hijacking, credential theft and insider threats.",
    "metadata": {
      "id": "ENISA-11.7.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "MULTI-FACTOR AUTHENTICATION"
    }
  },
  {
    "page_content": "Title: MULTI-FACTOR AUTHENTICATION\nDescription: The relevant entities shall ensure that the strength of authentication is appropriate for the classification of the asset to be accessed.\nRationale: N/A\nAudit: N/A\nRemediation: - Determine which network and information systems require the use of MFA protection based on the classification of the asset to be accessed. Wherever possible, use phishing-resistant MFA. - Analyse user roles and the level of access required by each role to determine appropriate MFA methods. - Consider MFA, in particular when accessing systems from a remote location, accessing system administration systems, access to sensitive information, etc. - Enforce MFA on internet-facing systems, such as email, remote desktop and VPNs. - Define when and how MFA is required (e.g. every login, once per session or for high-risk actions).",
    "metadata": {
      "id": "ENISA-11.7.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "7 MULTI-FACTOR AUTHENTICATION",
      "category_l2": "MULTI-FACTOR AUTHENTICATION"
    }
  },
  {
    "page_content": "Title: ASSET CLASSIFICATION\nDescription: For the purpose of Article 21, point (i) of Directive (EU) 2022/2555, the relevant entities shall lay down classification levels of all assets, including information, in scope of their network and information systems for the level - f protection required.\nRationale: N/A\nAudit: N/A\nRemediation: - Create and document classification levels for the assets, including conventions for classification.",
    "metadata": {
      "id": "ENISA-12.1.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "ASSET CLASSIFICATION"
    }
  },
  {
    "page_content": "Title: ASSET CLASSIFICATION\nDescription: For the purpose of point 12.1.1., the relevant entities shall: (a) lay down a system of classification levels for assets; (b) associate all assets with a classification level, based on confidentiality, integrity, authenticity and availability requirements, to indicate the protection required according to their sensitivity, criticality, risk and business value; (c) align the availability requirements of the assets with the delivery and recovery objectives set out in their business continuity and disaster recovery plans.\nRationale: N/A\nAudit: N/A\nRemediation: - Ensure that classifications and associated protective measures for assets consider business needs, including: - sharing or restricting information; - protecting the integrity and authenticity of information; - ensuring availability; and - complying with legal requirements concerning the confidentiality, integrity or availability of the information. - Define and communicate a classification for sensitive information, such as (indicative example): - public - freely accessible to all, even externally; - internal - accessible only to members of the entity; - confidential - accessible only to those whose duties require access. - Use classifications derived from national law, international agreements or internationally accepted strategies for sharing information, such as the traffic light protocol. - Align the classification with the access control policy (section 11.1). - Classify assets in accordance with the identified classification levels. - Classify assets other than information in accordance with the classification of the information they store, process, handle or protect. For example, the entity could assess the direct replacement cost associated with an asset and, where possible, the known indirect cost of total loss.",
    "metadata": {
      "id": "ENISA-12.1.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "ASSET CLASSIFICATION"
    }
  },
  {
    "page_content": "Title: ASSET CLASSIFICATION\nDescription: The relevant entities shall conduct periodic reviews of the classification levels of assets and update them, where appropriate.\nRationale: N/A\nAudit: N/A\nRemediation: - Define criteria for reviewing the classification over time. - Review the classification at least annually, taking into account: - regulatory changes; and - changes in the value, sensitivity and criticality of the assets throughout their life cycle.",
    "metadata": {
      "id": "ENISA-12.1.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "ASSET CLASSIFICATION"
    }
  },
  {
    "page_content": "Title: HANDLING OF ASSETS\nDescription: The relevant entities shall establish, implement and apply a policy for the proper handling of assets, including information, in accordance with their network and information security policy and shall communicate the policy on proper handling of assets to anyone who uses or handles assets.\nRationale: N/A\nAudit: N/A\nRemediation: - Ensure that employees, direct suppliers, service providers and any other third parties who use or handle the entity’s assets are aware of the policy. - Consider mobile devices, such as smartphones and tablets, and determine a strategy for mobile device management, including Bring-Your-Own-Device (BYOD).",
    "metadata": {
      "id": "ENISA-12.2.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "HANDLING OF ASSETS"
    }
  },
  {
    "page_content": "Title: HANDLING OF ASSETS\nDescription: The policy shall: (a) cover the entire life cycle of the assets, including acquisition, use, storage, transportation and disposal; (b) provide instructions on the safe use, safe storage, safe transport and the irretrievable deletion and destruction of the assets; (c) provide that the transfer shall take place in a secure manner, in accordance with the type of asset or information to be transferred.\nRationale: N/A\nAudit: N/A\nRemediation: - Identify, document and implement a policy for handling assets throughout their life cycle (acquisition, use, storage, transportation and disposal). - Ensure that the policy includes at least safe storage, safe transport; and irretrievable deletion and destruction. For example: - create user manuals and training materials on the correct and secure use of assets; - establish guidelines for secure storage, taking into account backup management (section 4.2); - define protocols for secure transfer, including consider secure migration processes, when transferring data to a cloud service; - - utline methods for data wiping and physical destruction, ensuring complete and irretrievable deletion. - Ensure that the policy covers the proper usage of all in-scope assets, both on-premises and off-premises (e.g. mobile devices, data in the cloud, transient data or sensitive information). - Ensure that assets may be transferred to external premises only after approval by authorized management bodies, in accordance with the policy. - Link the asset handling policy with the asset classification by providing handling details for each classification level.",
    "metadata": {
      "id": "ENISA-12.2.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "HANDLING OF ASSETS"
    }
  },
  {
    "page_content": "Title: HANDLING OF ASSETS\nDescription: The relevant entities shall review and, where appropriate, update the policy at planned intervals and when significant incidents or significant changes to operations or risks occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Review and update the policy for asset handling at least annually. Vehicles that can store data locally on the vehicle and/or share data externally by means of telematics are included. Data that moves between systems, users, or devices, often temporarily or for processing purposes.",
    "metadata": {
      "id": "ENISA-12.2.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "HANDLING OF ASSETS"
    }
  },
  {
    "page_content": "Title: REMOVABLE MEDIA POLICY\nDescription: The relevant entities shall establish, implement and apply a policy on the management of removable storage media and communicate it to their employees and third parties who handle removable storage media at the relevant entities’ premises or other locations where the removable media is connected to the relevant entities’ network and information systems.\nRationale: N/A\nAudit: N/A\nRemediation: - Define, document and implement a policy on the management of removable media. - Communicate the policy to employees and third parties who handle removable storage media to ensure that they are aware of the policy.",
    "metadata": {
      "id": "ENISA-12.3.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "REMOVABLE MEDIA POLICY"
    }
  },
  {
    "page_content": "Title: REMOVABLE MEDIA POLICY\nDescription: The policy shall: (a) provide for a technical prohibition of the connection of removable media unless there is an organisational reason for their use; (b) provide for disabling self-execution from such media and scanning the media for malicious code before they are used on the relevant entities’ systems; (c) provide measures for controlling and protecting portable storage devices containing data while in transit and in storage; (d) where appropriate, provide measures for the use of cryptographic techniques to protect data on removable storage media.\nRationale: N/A\nAudit: N/A\nRemediation: - Align the policy with the asset classification (section 12.1) and include at least the following: - definitions and scope of removable media, - authorization requirements, - usage guidelines, Including ‘bring your own device’, if personal devices are used to store corporate data. Vehicles that can store data locally on a vehicle and/or share data externally by means of telematics are also included. - measures for control and protection of removable media while in storage and in transit;, - techniques to protect information on removable storage media and - incident response procedures for lost or compromised media. - Configure network and information systems to disable the autorun feature for all removable media, to prevent the automatic execution of potentially malicious software. - If connection of removable media is not prohibited for an organisational (business) reason, removable media should be scanned for malicious code, where appropriate, with up-to-date software against malicious code before being connected to the entity’s network and information systems and/or in real time. - Encrypt sensitive data stored on removable media using strong cryptographic algorithms to protect against unauthorized access - Use encryption to protect data stored on portable storage devices, ensuring that unauthorized users cannot access the data if the device is lost or stolen. - Implement physical security measures, where appropriate, such as secure storage locations and tracking logs for portable storage devices.",
    "metadata": {
      "id": "ENISA-12.3.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "REMOVABLE MEDIA POLICY"
    }
  },
  {
    "page_content": "Title: REMOVABLE MEDIA POLICY\nDescription: The relevant entities shall review and, where appropriate, update the policy at planned intervals and when significant incidents or significant changes to operations or risks occur.\nRationale: N/A\nAudit: N/A\nRemediation: - Regularly monitor and audit the use of removable media to ensure compliance with the policy.",
    "metadata": {
      "id": "ENISA-12.3.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "REMOVABLE MEDIA POLICY"
    }
  },
  {
    "page_content": "Title: ASSET INVENTORY\nDescription: The relevant entities shall develop and maintain a complete, accurate, up-to-date and consistent inventory of their assets. They shall record changes to the entries in the inventory in a traceable manner.\nRationale: N/A\nAudit: N/A\nRemediation: - Ensure that all assets, including hardware, software, data and services, are listed in the inventory. - Regularly verify the accuracy of the inventory entries. - Update the inventory promptly to reflect any changes, such as new assets, decommissioned assets or changes in asset status (section 6.4) - Use standardised naming conventions and categorization methods to maintain consistency across the inventory. - Make sure that inventory entries contain the data in the below (sampling). - Implement validation rules within the inventory to ensure data entered is complete and consistent.",
    "metadata": {
      "id": "ENISA-12.4.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "ASSET INVENTORY"
    }
  },
  {
    "page_content": "Title: ASSET INVENTORY\nDescription: The granularity of the inventory of the assets shall be at a level appropriate for the needs of the relevant entities. The inventory shall include the following: (a) the list of operations and services and their description, (b) the list of network and information systems and other associated assets supporting the relevant entities’ operations and services.\nRationale: N/A\nAudit: N/A\nRemediation: - Consider adding one or more of the following to the inventory (indicative, non-exhaustive list): - asset unique ID, - asset type, for example software including virtual machines (version), hardware (operating system / firmware), services, supporting utilities, facilities, heating, ventilation and air conditioning (HVAC) systems, personnel and physical records, - asset owner and contact information, - - perational unit responsible for the asset, either internal department name or external provider name, - asset description, - asset location, - date of asset’s last update/patch, - asset classification consistent with the risk assessment, - type of information and its classification processed in the basset, - asset end of life, where applicable, - relation to other assets and - logging requirements.",
    "metadata": {
      "id": "ENISA-12.4.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "ASSET INVENTORY"
    }
  },
  {
    "page_content": "Title: ASSET INVENTORY\nDescription: The relevant entities shall regularly review and update the inventory and their assets and document the history - f changes.\nRationale: N/A\nAudit: N/A\nRemediation: - Conduct regular reviews to verify the accuracy and completeness of the inventory. - Maintain history of changes. In the case of external provider(s), a reference to the SLA covering this relation will also be useful.",
    "metadata": {
      "id": "ENISA-12.4.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "5 DEPOSIT, RETURN OR DELETION OF ASSETS UPON TERMINATION OF EMPLOYMENT",
      "category_l2": "ASSET INVENTORY"
    }
  },
  {
    "page_content": "Title: SUPPORTING UTILITIES\nDescription: For the purpose of Article 21(c) of Directive (EU) 2022/2555, the relevant entities shall prevent loss, damage - r compromise of network and information systems or interruption to their operations due to the failure and disruption - f supporting utilities.\nRationale: N/A\nAudit: N/A\nRemediation: - Consider supporting utilities, where relevant, that ensure the continuous operation of network and information systems, such as (indicative, non-exhaustive list): - power supply – electricity to keep systems running; - water for cooling and other operational needs; - gas for heating or backup power generation; - HVAC to maintain optimal operating conditions; - telecommunications – internet and network connectivity. - Include the potential failure and disruption of supporting utilities in the risk assessment.",
    "metadata": {
      "id": "ENISA-13.1.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 PERIMETER AND PHYSICAL ACCESS CONTROL",
      "category_l2": "SUPPORTING UTILITIES"
    }
  },
  {
    "page_content": "Title: SUPPORTING UTILITIES\nDescription: For that purpose, the relevant entities shall, where appropriate: (a) protect facilities from power failures and other disruptions caused by failures in supporting utilities such as electricity, telecommunications, water supply, gas, sewage, ventilation and air conditioning; (b) consider the use of redundancy in utilities services; (c) protect utility services for electricity and telecommunications, which transport data or supply network and information systems, against interception and damage; (d) monitor the utility services referred to in point (c) and report to the competent internal or external personnel events - utside the minimum and maximum control thresholds referred to in point 13.2.2(b) affecting the utility services; (e) conclude contracts for the emergency supply with corresponding services, such as for the fuel for emergency power supply; (f) ensure continuous effectiveness, monitor, maintain and test the supply of the network and information systems necessary for the operation of the service offered, in particular the electricity, temperature and humidity control, telecommunications and Internet connection. In cases where an entity operates with a fully remote workforce and does not maintain any on-premises servers or infrastructure, the requirement for supporting utility services at a centralized location may be rendered unnecessary. Remote work inherently introduces geographical and infrastructural diversification, thereby reducing the overall utility-related risk. By distributing operations across various locations, the organization benefits from a decentralized utility dependency, which enhances resilience against localized disruptions. TECHNICAL IMPLEMENTATION\nRationale: N/A\nAudit: N/A\nRemediation: - Consider the availability of supporting utilities in the business continuity plan (section 4.1). - Consider the availability of supporting utilities, when implementing backup management (section 4.2). - Consider implementing measures for the protection of supporting utilities, such as (indicative, nonexhaustive list): - active/passive cooling; - automatic restart after power interruption; - battery backup power; - diesel generators; - backup fuel; - uninterruptable power supply, hot standby power generators; - sufficient fuel delivery SLA; - delivery companies; - redundant cooling; - spare parts for components of network and information systems; and - power backup systems.",
    "metadata": {
      "id": "ENISA-13.1.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 PERIMETER AND PHYSICAL ACCESS CONTROL",
      "category_l2": "SUPPORTING UTILITIES"
    }
  },
  {
    "page_content": "Title: SUPPORTING UTILITIES\nDescription: The relevant entities shall test, review and, where appropriate, update the protection measures on a regular basis or following significant incidents or significant changes to operations or risks.\nRationale: N/A\nAudit: N/A\nRemediation: - Conduct routine tests of protection measures. - Set up periodic reviews to evaluate the effectiveness of current protection measures.",
    "metadata": {
      "id": "ENISA-13.1.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 PERIMETER AND PHYSICAL ACCESS CONTROL",
      "category_l2": "SUPPORTING UTILITIES"
    }
  },
  {
    "page_content": "Title: PROTECTION AGAINST PHYSICAL AND ENVIRONMENTAL THREATS\nDescription: For the purpose of Article 21(e) of Directive (EU) 2022/2555, the relevant entities shall prevent or reduce the consequences of events originating from physical and environmental threats, such as natural disasters and other intentional or unintentional threats, based on the results of the risk assessment carried out pursuant to point 2.1.\nRationale: N/A\nAudit: N/A\nRemediation: - Consider risks associated with current and forecasted physical and environmental threats to the network and information systems, where relevant. - Include in the assessment the (physical) locations of the entity’s facilities. - Based on the results of the risk assessment determine the assets that need to be protected from physical and environmental threats.",
    "metadata": {
      "id": "ENISA-13.2.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 PERIMETER AND PHYSICAL ACCESS CONTROL",
      "category_l2": "PROTECTION AGAINST PHYSICAL AND ENVIRONMENTAL THREATS"
    }
  },
  {
    "page_content": "Title: PROTECTION AGAINST PHYSICAL AND ENVIRONMENTAL THREATS\nDescription: For that purpose, the relevant entities shall, where appropriate: (a) design and implement protection measures against physical and environmental threats; (b) determine minimum and maximum control thresholds for physical and environmental threats; (c) monitor environmental parameters and report to the competent internal or external personnel events outside the minimum and maximum control thresholds referred to in point (b).\nRationale: N/A\nAudit: N/A\nRemediation: - Implement measures against physical and environmental threats. Parameters to consider are (indicative, non-exhaustive list): - purpose and scope; - network and information systems in scope; - description of facilities; - roles and responsibilities; - management commitment; - coordination among organisational units; - compliance with national and EU law, including personal data protection. Where a company operates with a fully remote workforce and lacks centralized on-premises infrastructure, traditional physical and environmental threat protections at a single location may be less critical. The distributed nature of remote work inherently provides resilience by diversifying exposure to localized physical and environmental risks. Consequently organizations should focus on ensuring that remote employees’ home work environments meet minimum security and safety standards and consider leveraging cloud service providers’ robust physical security controls. This distributed operational model reduces dependency on any single physical site, thereby mitigating the impact of localized environmental or physical incidents. - Consider potential physical and environmental threats relevant to the context, location and operational environment. The following list offers examples (indicative and non-exhaustive) to support risk-based planning: - fire, flood or natural events (e.g. earthquakes, storms), - public disturbances or unauthorized access, theft or vandalism, - hazardous material incidents (e.g. chemical spills), - long-term environmental changes (e.g. climate trends, air quality). - Consider measures against physical and environmental threats such as (indicative, non-exhaustive list): - physical access control measures (e.g. IDs, badges, logs; visitor management system and physical barriers); - surveillance systems (e.g. CCTV, entry points, exits, locking mechanisms and security personnel); - climate control (e.g. temperature and humidity controls and HVAC systems); - fire prevention and response measures (e.g. fire alarms, smoke detectors, sprinkler systems and fire extinguishers); - Consider enhanced (maximum) measures to be activated during heightened threat levels or specific scenarios. Examples of such measures include (indicative, non-exhaustive list): - Increased security personnel, advanced biometric access controls and lockdown procedures. - Enhanced monitoring systems, redundant power supplies and advanced environmental sensors.",
    "metadata": {
      "id": "ENISA-13.2.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 PERIMETER AND PHYSICAL ACCESS CONTROL",
      "category_l2": "PROTECTION AGAINST PHYSICAL AND ENVIRONMENTAL THREATS"
    }
  },
  {
    "page_content": "Title: PROTECTION AGAINST PHYSICAL AND ENVIRONMENTAL THREATS\nDescription: The relevant entities shall test, review and, where appropriate, update the protection measures against physical and environmental threats on a regular basis or following significant incidents or significant changes to operations or risks.\nRationale: N/A\nAudit: N/A\nRemediation: - Schedule and perform regular tests, such as quarterly fire drills and annual assessments of physical security measures. - Conduct both announced and unannounced tests",
    "metadata": {
      "id": "ENISA-13.2.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 PERIMETER AND PHYSICAL ACCESS CONTROL",
      "category_l2": "PROTECTION AGAINST PHYSICAL AND ENVIRONMENTAL THREATS"
    }
  },
  {
    "page_content": "Title: PERIMETER AND PHYSICAL ACCESS CONTROL\nDescription: For the purpose of Article 21(i) of Directive (EU) 2022/2555, the relevant entities shall prevent and monitor unauthorised physical access, damage and interference to their network and information systems.\nRationale: N/A\nAudit: N/A\nRemediation: - Implement perimeter physical access control, where relevant, taking into account the measures for protection against physical and environmental threats (section 13.2). - Ensure that physical access control is integrated with logical and network access control, in line with human resources security procedures (section 10.1) to support the detection of irregular activities and enhance overall organisational security.",
    "metadata": {
      "id": "ENISA-13.3.1",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 PERIMETER AND PHYSICAL ACCESS CONTROL",
      "category_l2": "PERIMETER AND PHYSICAL ACCESS CONTROL"
    }
  },
  {
    "page_content": "Title: PERIMETER AND PHYSICAL ACCESS CONTROL\nDescription: For that purpose, the relevant entities shall: (a) on the basis of the risk assessment carried out pursuant to point 2.1, lay down and use security perimeters to protect areas where network and information systems and other associated assets are located; (b) protect the areas referred to in point (a) by appropriate entry controls and access points; (c) design and implement physical security for offices, rooms and facilities, (d) continuously monitor their premises for unauthorised physical access.\nRationale: N/A\nAudit: N/A\nRemediation: - In the risk assessment, consider risks associated with unauthorised physical access to, damage to and interference with network and information systems. In a fully remote operating model where the organization does not maintain centralized office spaces or on-premises infrastructure, traditional perimeter and physical access control measures (e.g. badge systems, mantraps, on-site security personnel) may not be applicable. Instead, the focus should shift to ensuring that access to corporate resources is governed through strong logical access controls, such as multi-factor authentication (MFA), endpoint compliance checks and secure connectivity (e.g. VPN or Zero Trust Network Access). For personnel working from home organizations should provide on securing home workspaces—such as restricting unauthorized physical access to work devices and using locked rooms or cabinets when necessary. Where third-party cloud or co-location facilities are used, physical access controls should be reviewed and enforced contractually through SLAs and verified via audit reports (e.g. ISO 27001, SOC 2). - Based on the results of the risk assessment, determine high-criticality assets and the impact of their being compromised. This will help in identifying the perimeter for such assets. - Prevent unauthorised physical access to facilities and set up adequate measures. - Physical access control measures designed to protect the entity as a whole will also protect individual assets. - Consider introducing further specific access control measures for specific assets or facilities. - Consider physical security measures (indicative, non-exhaustive list): - physical access controls such as key cards, biometric scanners, locks and security personnel to restrict access to high-criticality areas, - electronic control of entry, with an audit trail, - segmentation of spaces or creation of zones according to authorization levels and their contents, - CCTV cameras and monitoring systems to continuously observe sensitive areas, - fencing, barriers and security patrols for securing physical perimeters, - guards and/or alarms to monitor every physical access point to the facility where the information system resides, 24 hours per day, seven days per week. - Develop and enforce procedures for granting, reviewing and revoking physical access rights (section 11.2). - Identify a designated official within the entity to review and approve the list of personnel with authorized physical access. - Maintain a list of personnel with authorized access to facilities, and their authorization levels.",
    "metadata": {
      "id": "ENISA-13.3.2",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 PERIMETER AND PHYSICAL ACCESS CONTROL",
      "category_l2": "PERIMETER AND PHYSICAL ACCESS CONTROL"
    }
  },
  {
    "page_content": "Title: PERIMETER AND PHYSICAL ACCESS CONTROL\nDescription: The relevant entities shall test, review and, where appropriate, update the physical access control measures on a regular basis or following significant incidents or significant changes to operations or risks.\nRationale: N/A\nAudit: N/A\nRemediation: - Review physical access lists. - Employ intrusion tests that include, where applicable, unannounced attempts to bypass or circumvent measures associated with physical access points to the facility. - At the physical boundary of the facility or network and information system, perform security checks for unauthorised exfiltration of information or removal of information system components.",
    "metadata": {
      "id": "ENISA-13.3.3",
      "source": "ENISA_Technical_implementation_guidance_on_cybersecurity_risk_management_measures_version_1.0.pdf",
      "category_l1": "3 PERIMETER AND PHYSICAL ACCESS CONTROL",
      "category_l2": "PERIMETER AND PHYSICAL ACCESS CONTROL"
    }
  }
]