import os
import json
import re
from collections import Counter
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import AIMessage, HumanMessage

from llm_handler import get_llm
from db_handler_es import get_trivy_and_rag_analysis
from utils.diff_handler import apply_diff, save_temp_patch, save_temp_yaml, parse_line_suggestions

LLM = get_llm()

def get_prompt_chain(mode: str = "user"):
    """ëª¨ë“œë³„ í”„ë¡¬í”„íŠ¸ ì²´ì¸ ìƒì„±"""
    template_file = (
        "prompt_template_expert.md" if mode == "expert" else "prompt_template.md"
    )
    try:
        with open(template_file, "r", encoding="utf-8") as f:
            prompt_text = f.read()
        prompt = ChatPromptTemplate.from_template(prompt_text)
        chain = RunnablePassthrough() | prompt | LLM | StrOutputParser()
        print(f"[INIT] âœ… LLM ì²´ì¸ ì´ˆê¸°í™” ì„±ê³µ ({mode} mode, {template_file})")
        return chain
    except Exception as e:
        print(f"[INIT] âŒ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ({template_file}): {e}")
        raise e


def get_chat_chain(mode: str = "user"):
    """ëª¨ë“œë³„ ì±„íŒ… ì²´ì¸ ìƒì„±"""
    if mode == "expert":
        system_prompt = """ë‹¹ì‹ ì€ K-SEC Copilot ì „ë¬¸ê°€ ëª¨ë“œì…ë‹ˆë‹¤.
        ì´ë¯¸ ì‚¬ìš©ìì™€ ì´ˆê¸° ë¶„ì„ì— ëŒ€í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì—ˆìŠµë‹ˆë‹¤.
        ì œê³µëœ [ëŒ€í™” ê¸°ë¡]ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ [ìƒˆë¡œìš´ ì§ˆë¬¸]ì— ëŒ€í•´ ë‹µë³€í•˜ì„¸ìš”.
        
        **ì¤‘ìš”: ì „ë¬¸ê°€ ëª¨ë“œ ë‹µë³€ ê·œì¹™**
        - ì½”ë“œ ìˆ˜ì •ì´ í•„ìš”í•œ ê²½ìš° Diff í˜•ì‹ ì‚¬ìš© ê¶Œì¥
        - ê¸°ìˆ ì ìœ¼ë¡œ ìƒì„¸í•˜ê³  ì •í™•í•˜ê²Œ ì„¤ëª…
        - ë³´ì•ˆ ì˜í–¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„
        
        [ì´ˆê¸° ë¶„ì„ ê²°ê³¼]ëŠ” ëŒ€í™”ì˜ ì „ì²´ ë§¥ë½ì´ë‹ˆ ì°¸ê³ í•˜ì„¸ìš”."""
    else:
        system_prompt = """ë‹¹ì‹ ì€ K-SEC Copilot, ì¿ ë²„ë„¤í‹°ìŠ¤ ë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì´ë¯¸ ì‚¬ìš©ìì™€ ì´ˆê¸° ë¶„ì„ì— ëŒ€í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì—ˆìŠµë‹ˆë‹¤.
        ì œê³µëœ [ëŒ€í™” ê¸°ë¡]ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ [ìƒˆë¡œìš´ ì§ˆë¬¸]ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
        [ì´ˆê¸° ë¶„ì„ ê²°ê³¼]ëŠ” ëŒ€í™”ì˜ ì „ì²´ ë§¥ë½ì´ë‹ˆ ì°¸ê³ í•˜ì„¸ìš”."""
    
    chat_prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", "[ì´ˆê¸° ë¶„ì„ ê²°ê³¼]\n{initial_analysis}"),
        MessagesPlaceholder(variable_name="chat_history"),
        ("user", "[ìƒˆë¡œìš´ ì§ˆë¬¸]\n{new_question}"),
    ])
    
    return chat_prompt | LLM | StrOutputParser()


print(" -> [System] ì´ˆê¸° ë¶„ì„ ë° ì±„íŒ… ì²´ì¸ êµ¬ì„± ì¤€ë¹„ ì™„ë£Œ.")


def format_analysis_results(analysis_results: list) -> str:
    """
    RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ [i]/[METADATA]/[CONTENT] ë¸”ë¡ í¬ë§·ìœ¼ë¡œ ì§ë ¬í™”.
    """
    if not analysis_results:
        return "ê´€ë ¨ëœ ë³´ì•ˆ ì§€ì¹¨ì´ë‚˜ ë²¤ì¹˜ë§ˆí¬ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    lines = []
    for i, result in enumerate(analysis_results, start=1):
        doc = result.get('source_document', {}) or {}
        header = f"[{i}]"

        es_hit = doc.get('metadata', {}) or {}
        source_field = doc.get('_source', {}) or {}
        metadata = source_field.get('metadata') or {}
        content = source_field.get('content', 'ë‚´ìš© ì—†ìŒ')

        metadata_lines = []
        for key, value in metadata.items():
            metadata_lines.append(f"  - {key}: {value}")
        metadata_str = "\n".join(metadata_lines)

        content = doc.get('content', 'ë‚´ìš© ì—†ìŒ')
        full_doc_str = f"{header}\n[METADATA]\n{metadata_str}\n[CONTENT]\n{content}"
        lines.append(full_doc_str)
    return "\n\n" + "="*20 + "\n\n".join(lines)


def debug_source_counts(analysis_results: list):
    """
    retrieved_contextì— í¬í•¨ëœ ì¶œì²˜ ë¹„ìœ¨ í™•ì¸(í¸í–¥ ì§„ë‹¨ìš© ë¡œê·¸).
    """
    if not analysis_results:
        print("[RAG] source counts: {} (no results)")
        return
    c = Counter()
    for r in analysis_results:
        doc = r.get('source_document', {}) or {}
        es_hit = doc.get('metadata', {}) or {}
        source_field = doc.get('_source', {}) or {}

        meta = source_field.get('metadata') or {}
        src = meta.get('source') or 'UNKNOWN'
        c[src] += 1
    print("[RAG] source counts:", dict(c))


def format_references(analysis_results: list) -> str:
    """
    RAG ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì°¸ê³  ìë£Œ ë¦¬ìŠ¤íŠ¸ë¥¼ [n]: source (ID: id) í˜•íƒœë¡œ ìƒì„±.
    """
    if not analysis_results:
        return "ì°¸ê³  ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    lines = []
    for i, result in enumerate(analysis_results, start=1):
        doc = result.get('source_document', {}) or {}
        
        es_hit = doc.get('metadata', {}) or {}
        source_field = es_hit.get('_source', {}) or {}
        metadata = source_field.get('metadata') or {}
        
        source_file = metadata.get('source', 'UNKNOWN_SOURCE')
        doc_id = metadata.get('id', 'UNKNOWN_ID') 
        
        lines.append(f"{i}. {source_file} (ID: {doc_id})")
        
    return "\n".join(lines)


# ê¸ˆì§€/êµì • íŒ¨í„´: í‹€ë¦° ê²°ë¡  ë‚˜ì˜¤ë©´ 1íšŒ ì¬ì‹œë„ íŠ¸ë¦¬ê±°
FORBIDDEN_PATTERNS = [
    r"localhostProfile:\s*docker/default",
    r"type\s*:\s*docker\s*/\s*default",
    r"RuntimeDefault[^.\n]*ì·¨ì•½",
    r"\b1024\s*ì´ìƒ\b[^.\n]*NET[_-]?BIND[_-]?SERVICE"
]


def needs_retry(text: str) -> bool:
    return any(re.search(p, text, flags=re.IGNORECASE) for p in FORBIDDEN_PATTERNS)


def sanitize_output(text: str) -> str:
    """
    ìµœì¢… ì¶œë ¥ì—ì„œ ë‚¨ì„ ìˆ˜ ìˆëŠ” ê²½ë¯¸í•œ í‘œí˜„ ì˜¤ë¥˜ë¥¼ ì•ˆì „í•˜ê²Œ êµì •.
    """
    text = re.sub(
        r"(seccompProfile:\s*\n(?:[^\n]*\n)*?\btype\s*:\s*)docker\s*/\s*default",
        r"\1RuntimeDefault", text, flags=re.IGNORECASE
    )
    text = re.sub(r"\b1024\s*ì´ìƒ\b", "1024 ë¯¸ë§Œ(â‰¤1023)", text)
    return text


def post_validate(text: str, mode: str = "user") -> str:
    """
    í•µì‹¬ ê¸°ìˆ  ì˜¤ë¥˜ë§Œ ê²€ì¦ (ì›ë³¸ ë°©ì‹ - ëª¨ë“œë³„ ê²€ì¦ ì œê±°)
    """
    problems = []
    
    # ê³µí†µ ê²€ì¦: ì¹˜ëª…ì  ê¸°ìˆ  ì˜¤ë¥˜ë§Œ
    if re.search(r"type\s*:\s*docker\s*/\s*default", text, re.IGNORECASE):
        problems.append("ì˜ëª»ëœ seccomp type ì œì•ˆ: docker/default")
    if re.search(r"RuntimeDefault[^.\n]*ì·¨ì•½", text):
        problems.append("RuntimeDefaultë¥¼ ì·¨ì•½ìœ¼ë¡œ ë¶„ë¥˜")
    if re.search(r"\b1024\s*ì´ìƒ\b[^.\n]*NET[_-]?BIND", text):
        problems.append("NET_BIND_SERVICE í¬íŠ¸ ë²”ìœ„ ì˜¤í‘œê¸°")
    
    # ëª¨ë“œë³„ ê²€ì¦ ì œê±° (ê³¼ë„í•œ ê°„ì„­ ë°©ì§€)

    if problems:
        banner = "âš ï¸ ì¶œë ¥ ìë™ ì ê²€ì—ì„œ ë‹¤ìŒì„ êµì •/ê²½ê³ í–ˆìŠµë‹ˆë‹¤:\n- " + "\n- ".join(problems) + "\n\n"
        return banner + text
    return text


def prepare_analysis(yaml_content: str, mode: str = "user") -> dict:
    """[ì‚¬ì „ ì²˜ë¦¬] YAML íŒŒì¼ì„ ë°›ì•„ Trivy ìŠ¤ìº” ë° RAG ê²€ìƒ‰ì„ ë¯¸ë¦¬ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        analysis_data = get_trivy_and_rag_analysis(yaml_content)

        if analysis_data == 0:
            return {"status": "no_issues", "prepared_data": None}
        if 'error' in analysis_data:
            return {"error": f"db_handler ì˜¤ë¥˜: {analysis_data['error']}"}

        analysis_results = analysis_data.get("analysis_results", [])
        debug_source_counts(analysis_results)

        formatted_context = format_analysis_results(analysis_data.get("analysis_results", []))
        formatted_references = format_references(analysis_results)

        ctx_lower = formatted_context.lower()
        has_seccomp = ("seccomp" in ctx_lower) or ("runtimedefault" in ctx_lower)
        has_netbind = ("net_bind_service" in ctx_lower) or ("cap_net_bind_service" in ctx_lower)

        policy_facts = (
            "- seccompProfile.type: RuntimeDefault ëŠ” ê¶Œì¥(OK)ì´ë©° ì·¨ì•½ ì•„ë‹˜.\n"
            "- Localhost ì œì•ˆì€ ì‹¤ì œ ì»¤ìŠ¤í…€ í”„ë¡œíŒŒì¼ íŒŒì¼ ê²½ë¡œ/ì´ë¦„ì´ ê·¼ê±°/ì…ë ¥ì— ìˆì„ ë•Œë§Œ.\n"
            "- NET_BIND_SERVICE ëŠ” 80/443 ì§ì ‘ ë°”ì¸ë”© í•„ìš” ì—†ìœ¼ë©´ ì œê±° ê¶Œì¥, "
            "í•„ìš”í•˜ë©´ ìœ ì§€ + (ê³ í¬íŠ¸â†’Service/Ingress ë§¤í•‘) ëŒ€ì•ˆ ë³‘ê¸°.\n"
            "- NET_BIND_SERVICE ëŠ” 1024 ë¯¸ë§Œ(â‰¤1023) í¬íŠ¸ ë°”ì¸ë”© ê¶Œí•œ.\n"
            f"- ì»¨í…ìŠ¤íŠ¸ì— seccomp ê·¼ê±° ì¡´ì¬: {has_seccomp}.\n"
            f"- ì»¨í…ìŠ¤íŠ¸ì— NET_BIND_SERVICE ê·¼ê±° ì¡´ì¬: {has_netbind}."
        )

        prepared_data = {
            "retrieved_context": formatted_context,
            "yaml_content": analysis_data.get("analyzed_yaml_content", ""),
            "policy_facts": policy_facts,
            "formatted_references": formatted_references,
        }
        return {"status": "success", "prepared_data": prepared_data}
    except Exception as e:
        return {"error": f"ë¶„ì„ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}


def generate_analysis_answer(prepared_data: dict, question: str, mode: str = "user") -> dict:
    """[ì‹¤ì‹œê°„ ë‹µë³€] ë¯¸ë¦¬ ì¤€ë¹„ëœ ë°ì´í„°ì™€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ìœ¼ë¡œ LLM ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        chain = get_prompt_chain(mode)
        input_data = prepared_data.copy()
        input_data["question"] = question

        response = chain.invoke(input_data)

        # âœ… ì „ë¬¸ê°€ ëª¨ë“œì¸ ê²½ìš° ë¼ì¸ë³„ ìˆ˜ì • ì œì•ˆ íŒŒì‹± ì‹œë„
        if mode == "expert":
            print("[RAG] ğŸ” ì „ë¬¸ê°€ ëª¨ë“œ ê°ì§€ â€” ë¼ì¸ë³„ ìˆ˜ì • ì œì•ˆ íŒŒì‹± ì‹œë„")
            
            # 1. LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ 'ìˆ˜ì • ì œì•ˆ ë¦¬ìŠ¤íŠ¸' íŒŒì‹± (utilsì—ì„œ importí•œ í•¨ìˆ˜ ì‚¬ìš©)
            parsed_suggestions = parse_line_suggestions(response)
            
            # 2. ì›ë³¸ YAML ê°€ì ¸ì˜¤ê¸°
            original_yaml = prepared_data.get("yaml_content", "")

            # 3. í”„ë¡ íŠ¸ì—”ë“œ(app.py)ë¡œ ì „ë‹¬í•  ê²°ê³¼ ê°ì²´ ìƒì„±
            return {
                "llm_full_response": response,     # LLMì˜ ì „ì²´ ì‘ë‹µ (ì„¤ëª… í¬í•¨)
                "line_suggestions": parsed_suggestions, # íŒŒì‹±ëœ ì œì•ˆ ëª©ë¡ (JSON ë¦¬ìŠ¤íŠ¸)
                "original_yaml": original_yaml,   # ì›ë³¸ YAML
            }

        if needs_retry(response):
            correction_hint = (
                "\n[êµì • íŒíŠ¸]\n"
                "- RuntimeDefaultëŠ” ê¶Œì¥(OK)ì´ë©° ì·¨ì•½ ì•„ë‹˜.\n"
                "- Localhost ì œì•ˆì€ ì‹¤ì œ ì»¤ìŠ¤í…€ í”„ë¡œíŒŒì¼ íŒŒì¼ ê²½ë¡œê°€ ê·¼ê±°/ì…ë ¥ì— ìˆì„ ë•Œë§Œ.\n"
                "- NET_BIND_SERVICEëŠ” 1024 ë¯¸ë§Œ(â‰¤1023) í¬íŠ¸ ê¶Œí•œ.\n"
                "ìœ„ ì‚¬ì‹¤ì— ë°˜í•˜ëŠ” ì§„ìˆ ì„ ì œê±°/ìˆ˜ì •í•˜ì—¬ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”."
            )
            input_data["question"] = f"{question}\n{correction_hint}"
            response = chain.invoke(input_data)

        response = sanitize_output(response)
        response = post_validate(response, mode)
        return {"result": response}
    except Exception as e:
        return {"error": f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}


def continue_chat(initial_analysis: str, chat_history: list, new_question: str, mode: str = "user") -> dict:
    """ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ í›„ì† ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤ (ëª¨ë“œ ì§€ì›)."""
    try:
        chat_chain = get_chat_chain(mode)
        
        if not chat_chain:
            return {"error": "ì±„íŒ… ì²´ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        processed_history = []
        for msg in chat_history:
            if msg["role"] == "user":
                processed_history.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                processed_history.append(AIMessage(content=msg["content"]))

        response = chat_chain.invoke({
            "initial_analysis": initial_analysis,
            "chat_history": processed_history,
            "new_question": new_question,
        })
        
        # ì±„íŒ… ì‘ë‹µë„ ê²€ì¦
        response = post_validate(response, mode)
        return {"result": response}
    except Exception as e:
        return {"error": f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}